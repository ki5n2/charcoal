{
  
    
        "post0": {
            "title": "DS 8. $x \to \hat{y}$ 가 되는 과정 그리기, Layer의 개념, Keras를 이용한 풀이, 여러가지 회귀모형의 적합과 학습과정의 모니터링",
            "content": ". Data Science . lenture: Data Science_6nd week of lectures. | lenture date: 2022-04-11 | lecturer: Guebin choi | study date: 2022-04-12, 2022-04-13 | author: Kione kim | . . import numpy as np import matplotlib.pyplot as plt import tensorflow as tf import tensorflow.experimental.numpy as tnp . tnp.experimental_enable_numpy_behavior() . import graphviz def gv(s): return graphviz.Source(&#39;digraph G{ rankdir=&quot;LR&quot;&#39;+s + &#39;; }&#39;) . $x to hat{y}$ &#44032; &#46104;&#45716; &#44284;&#51221;&#51012; &#44536;&#47548;&#51004;&#47196; &#44536;&#47532;&#44592; . - 단순회귀분석의 예시 . $ hat{y}_i = hat{ beta}_0 + hat{ beta}_1 x_i, quad i=1,2, dots,n$ | . (표현1) . gv(&#39;&#39;&#39; &quot;1&quot; -&gt; &quot;β̂₀ + xₙ*β̂₁, bias=False&quot;[label=&quot;* β̂₀&quot;] &quot;xₙ&quot; -&gt; &quot;β̂₀ + xₙ*β̂₁, bias=False&quot;[label=&quot;* β̂₁&quot;] &quot;β̂₀ + xₙ*β̂₁, bias=False&quot; -&gt; &quot;ŷₙ&quot;[label=&quot;identity&quot;] &quot;.&quot; -&gt; &quot;....................................&quot;[label=&quot;* β̂₀&quot;] &quot;..&quot; -&gt; &quot;....................................&quot;[label=&quot;* β̂₁&quot;] &quot;....................................&quot; -&gt; &quot;...&quot;[label=&quot; &quot;] &quot;1 &quot; -&gt; &quot;β̂₀ + x₂*β̂₁, bias=False&quot;[label=&quot;* β̂₀&quot;] &quot;x₂&quot; -&gt; &quot;β̂₀ + x₂*β̂₁, bias=False&quot;[label=&quot;* β̂₁&quot;] &quot;β̂₀ + x₂*β̂₁, bias=False&quot; -&gt; &quot;ŷ₂&quot;[label=&quot;identity&quot;] &quot;1 &quot; -&gt; &quot;β̂₀ + x₁*β̂₁, bias=False&quot;[label=&quot;* β̂₀&quot;] &quot;x₁&quot; -&gt; &quot;β̂₀ + x₁*β̂₁, bias=False&quot;[label=&quot;* β̂₁&quot;] &quot;β̂₀ + x₁*β̂₁, bias=False&quot; -&gt; &quot;ŷ₁&quot;[label=&quot;identity&quot;] &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G 1 1 β̂₀ + xₙ*β̂₁, &#160;&#160;&#160;bias=False β̂₀ + xₙ*β̂₁, &#160;&#160;&#160;bias=False 1&#45;&gt;β̂₀ + xₙ*β̂₁, &#160;&#160;&#160;bias=False * β̂₀ ŷₙ ŷₙ β̂₀ + xₙ*β̂₁, &#160;&#160;&#160;bias=False&#45;&gt;ŷₙ identity xₙ xₙ xₙ&#45;&gt;β̂₀ + xₙ*β̂₁, &#160;&#160;&#160;bias=False * β̂₁ . . .................................... .................................... .&#45;&gt;.................................... * β̂₀ ... ... ....................................&#45;&gt;... .. .. ..&#45;&gt;.................................... * β̂₁ 1 1 β̂₀ + x₂*β̂₁, &#160;&#160;&#160;bias=False β̂₀ + x₂*β̂₁, &#160;&#160;&#160;bias=False 1 &#45;&gt;β̂₀ + x₂*β̂₁, &#160;&#160;&#160;bias=False * β̂₀ ŷ₂ ŷ₂ β̂₀ + x₂*β̂₁, &#160;&#160;&#160;bias=False&#45;&gt;ŷ₂ identity x₂ x₂ x₂&#45;&gt;β̂₀ + x₂*β̂₁, &#160;&#160;&#160;bias=False * β̂₁ 1 &#160; 1 &#160; β̂₀ + x₁*β̂₁, &#160;&#160;&#160;bias=False β̂₀ + x₁*β̂₁, &#160;&#160;&#160;bias=False 1 &#160;&#45;&gt;β̂₀ + x₁*β̂₁, &#160;&#160;&#160;bias=False * β̂₀ ŷ₁ ŷ₁ β̂₀ + x₁*β̂₁, &#160;&#160;&#160;bias=False&#45;&gt;ŷ₁ identity x₁ x₁ x₁&#45;&gt;β̂₀ + x₁*β̂₁, &#160;&#160;&#160;bias=False * β̂₁ - 표현1 소감: . 다 똑같은 그림의 반복이 아닌가? | . (표현2) . - 그냥 아래와 같이 그리고 &quot;모든 $i=1,2,3, dots,n$에 대하여 $ hat{y}_i$을 아래의 그림과 같이 그린다&quot;고 하면 될것 같다. . gv(&#39;&#39;&#39; &quot;1&quot; -&gt; &quot;β̂₀ + xᵢ*β̂₁, bias=False&quot;[label=&quot;* β̂₀&quot;] &quot;xᵢ&quot; -&gt; &quot;β̂₀ + xᵢ*β̂₁, bias=False&quot;[label=&quot;* β̂₁&quot;] &quot;β̂₀ + xᵢ*β̂₁, bias=False&quot; -&gt; &quot;ŷᵢ&quot;[label=&quot;identity&quot;] &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G 1 1 β̂₀ + xᵢ*β̂₁, &#160;&#160;&#160;bias=False β̂₀ + xᵢ*β̂₁, &#160;&#160;&#160;bias=False 1&#45;&gt;β̂₀ + xᵢ*β̂₁, &#160;&#160;&#160;bias=False * β̂₀ ŷᵢ ŷᵢ β̂₀ + xᵢ*β̂₁, &#160;&#160;&#160;bias=False&#45;&gt;ŷᵢ identity xᵢ xᵢ xᵢ&#45;&gt;β̂₀ + xᵢ*β̂₁, &#160;&#160;&#160;bias=False * β̂₁ (표현3) . - 그런데 &quot;모든 $i=1,2,3, dots,n$에 대하여 $ hat{y}_i$을 아래의 그림과 같이 그린다&quot; 라는 언급자체도 반복할 필요가 없을 것 같다. 단순히 아래와 같이 그려도 무방할듯 하다. . gv(&#39;&#39;&#39; &quot;1&quot; -&gt; &quot;β̂₀ + x*β̂₁, bias=False&quot;[label=&quot;* β̂₀&quot;] &quot;x&quot; -&gt; &quot;β̂₀ + x*β̂₁, bias=False&quot;[label=&quot;* β̂₁&quot;] &quot;β̂₀ + x*β̂₁, bias=False&quot; -&gt; &quot;ŷ&quot;[label=&quot;identity&quot;] &#39;&#39;&#39;) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G 1 1 β̂₀ + x*β̂₁, &#160;&#160;&#160;bias=False β̂₀ + x*β̂₁, &#160;&#160;&#160;bias=False 1&#45;&gt;β̂₀ + x*β̂₁, &#160;&#160;&#160;bias=False * β̂₀ ŷ ŷ β̂₀ + x*β̂₁, &#160;&#160;&#160;bias=False&#45;&gt;ŷ identity x x x&#45;&gt;β̂₀ + x*β̂₁, &#160;&#160;&#160;bias=False * β̂₁ (표현4) . - 위의 모델은 아래와 같이 쓸 수 있다. ($ beta_0$를 바이어스로 표현) . gv(&#39;&#39;&#39; &quot;x&quot; -&gt; &quot;x*β̂₁, bias=True&quot;[label=&quot;*β̂₁&quot;] ; &quot;x*β̂₁, bias=True&quot; -&gt; &quot;ŷ&quot;[label=&quot;indentity&quot;] &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G x x x*β̂₁, &#160;&#160;&#160;bias=True x*β̂₁, &#160;&#160;&#160;bias=True x&#45;&gt;x*β̂₁, &#160;&#160;&#160;bias=True *β̂₁ ŷ ŷ x*β̂₁, &#160;&#160;&#160;bias=True&#45;&gt;ŷ indentity 실제로는 이 표현을 많이 사용함 | . (표현5) . - 벡터버전으로 표현하면 아래와 같다. 이 경우에는 ${ bf X}=[1,x]$에 포함된 1이 bias의 역할을 해주므로 bias = False 임. . gv(&#39;&#39;&#39; &quot;X&quot; -&gt; &quot;X@β̂, bias=False&quot;[label=&quot;@β̂&quot;] ; &quot;X@β̂, bias=False&quot; -&gt; &quot;ŷ&quot;[label=&quot;indentity&quot;] &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G X X X@β̂, &#160;&#160;&#160;bias=False X@β̂, &#160;&#160;&#160;bias=False X&#45;&gt;X@β̂, &#160;&#160;&#160;bias=False @β̂ ŷ ŷ X@β̂, &#160;&#160;&#160;bias=False&#45;&gt;ŷ indentity (표현5)&#39; . - 딥러닝에서는 $ hat{ boldsymbol{ beta}}$ 대신에 $ hat$을 라고 표현한다. . gv(&#39;&#39;&#39; &quot;X&quot; -&gt; &quot;X@Ŵ, bias=False&quot;[label=&quot;@Ŵ&quot;] ; &quot;X@Ŵ, bias=False&quot; -&gt; &quot;ŷ&quot;[label=&quot;identity&quot;] &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G X X X@Ŵ, &#160;&#160;&#160;bias=False X@Ŵ, &#160;&#160;&#160;bias=False X&#45;&gt;X@Ŵ, &#160;&#160;&#160;bias=False @Ŵ ŷ ŷ X@Ŵ, &#160;&#160;&#160;bias=False&#45;&gt;ŷ identity - 실제로는 표현4~6를 잘 사용한다. . Layer&#51032; &#44060;&#45392; . - (표현4~6)의 그림은 레이어로 설명할 수 있다. . - 레이어는 항상 아래와 같은 규칙을 가진다. . 첫 동그라미는 레이어의 입력이다. | 첫번째 화살표는 선형변환을 의미한다. | 두번째 동그라미는 선형변환의 결과이다. (이때 bias가 false인지 true인지에 따라서 실제 수식이 조금 다름) | 두번째 화살표는 두번째 동그라미에 어떠한 함수 $f$를 취하는 과정을 의미한다. (우리의 그림에서는 $f(x)=x$) | 세번째 동그라미는 레이어의 최종출력이다. | . - 꽤 복잡한데, 결국 레이어를 만들때 위의 그림들을 의미하도록 하려면 아래의 4개의 요소만 필요하다. . 1. 레이어의 입력차원 . 2. 선형변환의 결과로 얻어지는 차원 . 3. 선형변환에서 바이어스의 사용유무 . 4. 함수 $f$ . - 중요1: 1,2가 결정되면 자동으로 $ hat$의 차원이 결정된다. . (예시) . 레이어의 입력차원=2, 선형변환의 결과로 얻어지는 차원=1: $ hat{ bf W}$는 (2,1) 매트릭스 | 레이어의 입력차원=20, 선형변환의 결과로 얻어지는 차원=5: $ hat{ bf W}$는 (20,5) 매트릭스 | 레이어의 입력차원=2, 선형변환의 결과로 얻어지는 차원=50: $ hat{ bf W}$는 (2,50) 매트릭스 | . - 중요2: 이중에서 절대 생략불가능 것은 &quot;2. 선형변환의 결과로 얻어지는 차원&quot; 이다. . 레이어의 입력차원: 실제 레이어에 데이터가 들어올 때 데이터의 입력차원을 컴퓨터 스스로 체크하여 $ hat{ bf W}$의 차원을 결정할 수 있음. | 바이어스의 사용유무는 기본적으로 사용한다고 가정한다. | 함수 $f$: 기본적으로 항등함수를 가정하면 된다. | . &#52992;&#46972;&#49828;&#47484; &#51060;&#50857;&#54620; &#54400;&#51060; . 기본뼈대: 1.net생성 2.add(layer) 3.compile(opt,loss) 4.fit(data,epochs) 2. layer를 생성: x에서 y_hat을 만드는 방법을 정의하는 것을 의미 3. compile(opt,loss)의 의미: 손실함수를 정의하고 손실함수를 최소화시키는 반복 알고리즘을 결정할 옵티마이저를 정하는 것을 의미 4. fit(): 반복 학습 . - 데이터 . $${ bf y} approx 2.5 +4*x$$ . tnp.random.seed(50000) N=200 x=tnp.linspace(0,1,N) epsilon=tnp.random.randn(N)*0.5 y=2.5+4*x+epsilon . X=tf.stack([tf.ones(N,dtype=&#39;float64&#39;),x],axis=1) . &#54400;&#51060;1: &#49828;&#52860;&#46972; . - 데이터 정리 . y=y.reshape(-1) x.shape,y.shape . (TensorShape([200]), TensorShape([200])) . 1. net 생성 . net=tf.keras.Sequential() . 2. net.add(layer) . layer=tf.keras.layers.Dense(1) . Dense(n): 선형변환의 결과로 얻어지는 n차원, 여기서는 1차원이기에 Dense(1) | 숨겨진 의미: 레이어의 입력차원= 데이터를 넣어보고 결정, 바이어스= 디폴트 값을 따름(디폴트:use_bias=true), 함수= 디폴트 값을 따름(디폴트:f(x)=x) | . net.add(layer) . 3. net.compile(opt,loss_fn) . net.compile(tf.keras.optimizers.SGD(0.1),tf.keras.losses.MSE) . optimizer와 loss_fn을 바로 선언해주었음 | . 4. net.fit(x,y,epochs) . net.fit(x,y,epochs=1000,verbose=0,batch_size=N) . ValueError Traceback (most recent call last) Input In [17], in &lt;cell line: 1&gt;() -&gt; 1 net.fit(x,y,epochs=1000,verbose=0,batch_size=N) File ~ anaconda3 envs ds2022 lib site-packages keras utils traceback_utils.py:67, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 65 except Exception as e: # pylint: disable=broad-except 66 filtered_tb = _process_traceback_frames(e.__traceback__) &gt; 67 raise e.with_traceback(filtered_tb) from None 68 finally: 69 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework func_graph.py:1147, in func_graph_from_py_func.&lt;locals&gt;.autograph_handler(*args, **kwargs) 1145 except Exception as e: # pylint:disable=broad-except 1146 if hasattr(e, &#34;ag_error_metadata&#34;): -&gt; 1147 raise e.ag_error_metadata.to_exception(e) 1148 else: 1149 raise ValueError: in user code: File &#34;C: Users kko anaconda3 envs ds2022 lib site-packages keras engine training.py&#34;, line 1021, in train_function * return step_function(self, iterator) File &#34;C: Users kko anaconda3 envs ds2022 lib site-packages keras engine training.py&#34;, line 1010, in step_function ** outputs = model.distribute_strategy.run(run_step, args=(data,)) File &#34;C: Users kko anaconda3 envs ds2022 lib site-packages keras engine training.py&#34;, line 1000, in run_step ** outputs = model.train_step(data) File &#34;C: Users kko anaconda3 envs ds2022 lib site-packages keras engine training.py&#34;, line 859, in train_step y_pred = self(x, training=True) File &#34;C: Users kko anaconda3 envs ds2022 lib site-packages keras utils traceback_utils.py&#34;, line 67, in error_handler raise e.with_traceback(filtered_tb) from None File &#34;C: Users kko anaconda3 envs ds2022 lib site-packages keras engine input_spec.py&#34;, line 228, in assert_input_compatibility raise ValueError(f&#39;Input {input_index} of layer &#34;{layer_name}&#34; &#39; ValueError: Exception encountered when calling layer &#34;sequential&#34; (type Sequential). Input 0 of layer &#34;dense&#34; is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (200,) Call arguments received: • inputs=tf.Tensor(shape=(200,), dtype=float64) • training=True • mask=None . 오류가 남..! | 이는 x,y의 shape 에러인데, 아래와 같이 선언해주어야 한다. 지난 풀이와 다른 점인..! | . x=x.reshape(N,1) y=y.reshape(N,1) x.shape,y.shape . (TensorShape([200, 1]), TensorShape([200, 1])) . x와 y의 shape를 (n,1)로 설정해주어야 한다! | . net=tf.keras.Sequential() . layer=tf.keras.layers.Dense(1) net.add(layer) . net.compile(tf.keras.optimizers.SGD(0.1),tf.keras.losses.MSE) . net.fit(x,y,epochs=1000,verbose=0,batch_size=N) . &lt;keras.callbacks.History at 0x296949f8df0&gt; . batch_size = N 일 경우에 경사하강법이 적용되고 batch_size != N 일 경우에 확률적 경사하강법이 적용된다 | 추후에는 확률적 경사하강법을 사용할 것임 | . net.weights . [&lt;tf.Variable &#39;dense_1/kernel:0&#39; shape=(1, 1) dtype=float32, numpy=array([[4.1002874]], dtype=float32)&gt;, &lt;tf.Variable &#39;dense_1/bias:0&#39; shape=(1,) dtype=float32, numpy=array([2.4904754], dtype=float32)&gt;] . 비슷한 값이 나왔다. | . &#54400;&#51060;2: &#48289;&#53552; . - 데이터 . tnp.random.seed(50000) N=200 x=tnp.linspace(0,1,N) epsilon=tnp.random.randn(N)*0.5 y=2.5+4*x+epsilon . - 선언 . X=tf.stack([tf.ones(N,dtype=&#39;float64&#39;),x],axis=1) y=y.reshape(N,1) X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . net=tf.keras.Sequential() . layer=tf.keras.layers.Dense(1,use_bias=False) net.add(layer) . net.compile(tf.keras.optimizers.SGD(0.1),tf.keras.losses.MSE) . net.fit(X,y,epochs=1000,verbose=0,batch_size=N) . &lt;keras.callbacks.History at 0x29694aefd90&gt; . net.weights . [&lt;tf.Variable &#39;dense_2/kernel:0&#39; shape=(2, 1) dtype=float32, numpy= array([[2.4904754], [4.1002874]], dtype=float32)&gt;] . 비슷한 결과가 나왔다 | . - 비슷하지만 디폴트로 바이어스=true 설정한 코드 . tnp.random.seed(50000) N=200 x=tnp.linspace(0,1,N) epsilon=tnp.random.randn(N)*0.5 y=2.5+4*x+epsilon . X=tf.stack([tf.ones(N,dtype=&#39;float64&#39;),x],axis=1) y=y.reshape(N,1) X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . net=tf.keras.Sequential() . layer=tf.keras.layers.Dense(1) net.add(layer) . net.compile(tf.keras.optimizers.SGD(0.1),tf.keras.losses.MSE) . net.fit(X,y,epochs=1000,verbose=0,batch_size=N) . &lt;keras.callbacks.History at 0x29695b3c040&gt; . net.weights . [&lt;tf.Variable &#39;dense_3/kernel:0&#39; shape=(2, 1) dtype=float32, numpy= array([[1.3234154], [4.10029 ]], dtype=float32)&gt;, &lt;tf.Variable &#39;dense_3/bias:0&#39; shape=(1,) dtype=float32, numpy=array([1.1670585], dtype=float32)&gt;] . 결과값을 보면 $β_1$은 잘 추론했지만, $β_0$는 $β_0 + alpha$로 나뉘어서 추정되었다. $β_0 = 1.3234154, alpha = 1.1670585$로 합하면 $2.5$에 근사한다. | 이는 layer를 설정할 때 바이어스를 False로 바꿔주지 않았기 때문이다.(바이어스는 디폴트가 True이기 때문에 바이어스를 쓰지 않을 경우에 False로 바꿔주어야 한다. | . &#47928;&#48277;&#51221;&#47532; . - tf.keras.layers.Dense()를 통해 layer를 만드는 코드를 살펴보자. . (1) 아래는 모두 같은 코드이다. . 1. tf.keras.layers.Dense(1) . 2. tf.keras.layers.Dense(units=1) . - Dense()에 activation을 입력해주지 않으면(activatiion=None) 디폴트 값인 activation=&#39;linear&#39;로 반환해준다. . 3. tf.keras.layers.Dense(units=1,activation=&#39;linear&#39;), 여기서 activation=&#39;linear&#39;은 항등함수이다. . 4. tf.keras.layers.Dense(units=1,activation=&#39;linear&#39;,use_bias=True), bias에 관한 디폴트 값은 True이다. . (2) 아래의 코드5,6는 위의 코드들과 살짝 다른코드이다. (코드5와 코드6은 같은코드) . 5. tf.keras.layers.Dense(1,input_dim=2) . 6. tf.keras.layers.Dense(1,input_shape=(2,)) . (3) 아래는 사용불가능한 코드이다. . 7. tf.keras.layers.Dense(1,input_dim=(2,)) . 8. tf.keras.layers.Dense(1,input_shape=2) . np.array([1,2]).shape . (2,) . 왜 input_dim을 사용해야하지? 불편한데,,?! | . net1=tf.keras.Sequential() net1.add(tf.keras.layers.Dense(1,use_bias=False)) . net2=tf.keras.Sequential() net2.add(tf.keras.layers.Dense(1,use_bias=False,input_dim=2)) . net1.weights . ValueError Traceback (most recent call last) Input In [41], in &lt;cell line: 1&gt;() -&gt; 1 net1.weights File ~ anaconda3 envs ds2022 lib site-packages keras engine training.py:2735, in Model.weights(self) 2725 @property 2726 def weights(self): 2727 &#34;&#34;&#34;Returns the list of all layer variables/weights. 2728 2729 Note: This will not track the weights of nested `tf.Modules` that are not (...) 2733 A list of variables. 2734 &#34;&#34;&#34; -&gt; 2735 return self._dedup_weights(self._undeduplicated_weights) File ~ anaconda3 envs ds2022 lib site-packages keras engine training.py:2740, in Model._undeduplicated_weights(self) 2737 @property 2738 def _undeduplicated_weights(self): 2739 &#34;&#34;&#34;Returns the undeduplicated list of all layer variables/weights.&#34;&#34;&#34; -&gt; 2740 self._assert_weights_created() 2741 weights = [] 2742 for layer in self._self_tracked_trackables: File ~ anaconda3 envs ds2022 lib site-packages keras engine sequential.py:472, in Sequential._assert_weights_created(self) 469 return 470 # When the graph has not been initialized, use the Model&#39;s implementation to 471 # to check if the weights has been created. --&gt; 472 super(functional.Functional, self)._assert_weights_created() File ~ anaconda3 envs ds2022 lib site-packages keras engine training.py:2933, in Model._assert_weights_created(self) 2925 return 2927 if (&#39;build&#39; in self.__class__.__dict__ and 2928 self.__class__ != Model and 2929 not self.built): 2930 # For any model that has customized build() method but hasn&#39;t 2931 # been invoked yet, this will cover both sequential and subclass model. 2932 # Also make sure to exclude Model class itself which has build() defined. -&gt; 2933 raise ValueError(f&#39;Weights for model {self.name} have not yet been &#39; 2934 &#39;created. &#39; 2935 &#39;Weights are created when the Model is first called on &#39; 2936 &#39;inputs or `build()` is called with an `input_shape`.&#39;) ValueError: Weights for model sequential_4 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`. . net2.weights . [&lt;tf.Variable &#39;dense_5/kernel:0&#39; shape=(2, 1) dtype=float32, numpy= array([[-0.3167504], [-1.2892997]], dtype=float32)&gt;] . net1의 weight를 구하고자 하면 입력차원이 입력되지 않아(입력차원을 모르기 때문에) 에러가 난다. | net2의 weight는 입력차원이 입력되어 그 시점에서의 weight가 나타난다. | . net1.summary() . ValueError Traceback (most recent call last) Input In [43], in &lt;cell line: 1&gt;() -&gt; 1 net1.summary() File ~ anaconda3 envs ds2022 lib site-packages keras engine training.py:2775, in Model.summary(self, line_length, positions, print_fn, expand_nested, show_trainable) 2753 &#34;&#34;&#34;Prints a string summary of the network. 2754 2755 Args: (...) 2772 ValueError: if `summary()` is called before the model is built. 2773 &#34;&#34;&#34; 2774 if not self.built: -&gt; 2775 raise ValueError( 2776 &#39;This model has not yet been built. &#39; 2777 &#39;Build the model first by calling `build()` or by calling &#39; 2778 &#39;the model on a batch of data.&#39;) 2779 layer_utils.print_summary( 2780 self, 2781 line_length=line_length, (...) 2784 expand_nested=expand_nested, 2785 show_trainable=show_trainable) ValueError: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data. . net2.summary() . Model: &#34;sequential_5&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_5 (Dense) (None, 1) 2 ================================================================= Total params: 2 Trainable params: 2 Non-trainable params: 0 _________________________________________________________________ . summary()도 마찬가지로, net1의 경우 입력차원이 정의되지 않아(입력차원을 모르기 때문에) 에러가 난다. | net2의 경우 입력차원이 정의되어 net2에 대한 정보가 나타난다. | . &#54400;&#51060;3: &#49828;&#52860;&#46972;, &#51076;&#51032;&#51032; &#52488;&#44592;&#44050; &#49444;&#51221; . step0: 데이터 정리 . y=y.reshape(N,1) x=x.reshape(N,1) x.shape,y.shape . (TensorShape([200, 1]), TensorShape([200, 1])) . step1: net 생성 . net=tf.keras.Sequential() . step2: net.add(layer) . layer=tf.keras.layers.Dense(1,input_dim=1) #바이어스가 필요하기 때문에 바이어스는 디폴트(bias=True)로 설정 net.add(layer) . . - 임의의 초기값을 설정하는 방법(조금 복잡..!) . net.weights . [&lt;tf.Variable &#39;dense_6/kernel:0&#39; shape=(1, 1) dtype=float32, numpy=array([[1.4751679]], dtype=float32)&gt;, &lt;tf.Variable &#39;dense_6/bias:0&#39; shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)&gt;] . 입력차원을 설정해주었기 때문에 weight가 출력됨! | . net.get_weights() . [array([[1.4751679]], dtype=float32), array([0.], dtype=float32)] . net.get_weights()라는 함수가 있음 | 이는 1.4751679, 0을 리턴했음 | 1.4751679는 위 net.weights의 첫 번째 값과 같고, 0은 net.weights의 두번째 값과 같음을 알 수 있음 | net.weights의 두번째 값에 dense_11/bias:0가 리턴된 것으로 보아 이는 바이어스 값으로 보임 | 그렇다면 net.weights의 첫번째 값은 $ beta_1$일 것 같음 | 즉, weight, bias 순으로 출력됨 | . net.set_weights . &lt;bound method Layer.set_weights of &lt;keras.engine.sequential.Sequential object at 0x00000296966357C0&gt;&gt; . net.set_weights()라는 함수가 있음 | 이는 초기값을 설정하는 함수임 | 도움말을 참조하면 layer_b.set_weights(layer_a.get_weights()) 와 같은 방식으로 사용하는 것을 알 수 있음 | . - 한 번 사용해보자! . _w = net.get_weights() . _w? . Type: list String form: [array([[1.4751679]], dtype=float32), array([0.], dtype=float32)] Length: 2 Docstring: Built-in mutable sequence. If no argument is given, the constructor creates a new empty list. The argument must be an iterable if specified. . 길이가 2인 리스트임 | . _w[0] . array([[1.4751679]], dtype=float32) . type(_w[0]) . numpy.ndarray . 각 원소는 넘파이 array이 임 | . np.array([[1.4751679]], dtype=np.float32) . array([[1.4751679]], dtype=float32) . 이는 위의 _w[0] 값과 같음 | . np.array([[0.]], dtype=np.float32) . array([[0.]], dtype=float32) . 이는 위의 _w[1] 값과 같음 | . - 그렇다면 다음과 같이 할 수 있음 . net.set_weights( [np.array([[1.4751679]], dtype=np.float32), np.array([0.0], dtype=np.float32)] ) . net.get_weights() . [array([[1.4751679]], dtype=float32), array([0.], dtype=float32)] . - 초기값을 $ beta_1=10$, $ beta_0=-5$로 설정 . net.set_weights( [np.array([[10.0]], dtype=np.float32), np.array([-5.0], dtype=np.float32)] ) . net.get_weights() . [array([[10.]], dtype=float32), array([-5.], dtype=float32)] . . step3: net.compile() . net.compile(tf.keras.optimizers.SGD(0.1),tf.losses.MSE) . step4: net.fit . net.fit(x,y,epochs=1000,verbose=0,batch_size=N) . &lt;keras.callbacks.History at 0x29696667970&gt; . net.weights . [&lt;tf.Variable &#39;dense_6/kernel:0&#39; shape=(1, 1) dtype=float32, numpy=array([[4.100321]], dtype=float32)&gt;, &lt;tf.Variable &#39;dense_6/bias:0&#39; shape=(1,) dtype=float32, numpy=array([2.4904578], dtype=float32)&gt;] . 같은 값이 나왔음 | . &#54400;&#51060;4: &#48289;&#53552;, &#51076;&#51032;&#51032; &#52488;&#44592;&#44050; &#49444;&#51221; . step0: 데이터 정리 . X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . step1: net 생성 . net=tf.keras.Sequential() . step2: net.add(layer) . layer=tf.keras.layers.Dense(1,use_bias=False,input_dim=2) . net.add(layer) . step3: net.compile() . net.get_weights() . [array([[0.0854876 ], [0.77367294]], dtype=float32)] . net.set_weights( [np.array([[10.0],[-5.0]], dtype=np.float32)] ) . net.get_weights() . [array([[10.], [-5.]], dtype=float32)] . net.compile(tf.keras.optimizers.SGD(0.1), tf.keras.losses.MSE) . step4: net.fit . net.fit(X,y,epochs=1000,verbose=0,batch_size=N) . &lt;keras.callbacks.History at 0x2969666b880&gt; . net.get_weights() . [array([[2.4904754], [4.1002874]], dtype=float32)] . 같은 값이 나왔음 | . &#54400;&#51060;5: &#48289;&#53552;, &#49324;&#50857;&#51088;&#51221;&#51032; &#49552;&#49892;&#54632;&#49688; . step0: 데이터 정리 . X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . step1: net 생성 . net=tf.keras.Sequential() . step2: net.add(layer) . layer=tf.keras.layers.Dense(1,use_bias=False) . net.add(layer) . step3: net.compile() . loss_fn = lambda y, yhat : (y-yhat).T @ (y-yhat) / N . net.compile(tf.keras.optimizers.SGD(0.1), loss_fn) . step4: net.fit . net.fit(X,y,epochs=1000,verbose=0,batch_size=N) . &lt;keras.callbacks.History at 0x29696734f40&gt; . net.weights . [&lt;tf.Variable &#39;dense_8/kernel:0&#39; shape=(2, 1) dtype=float32, numpy= array([[2.4904754], [4.1002874]], dtype=float32)&gt;] . 값이 잘 나왔음 | . &#54400;&#51060;6: &#48289;&#53552;, net.compile&#51032; &#50741;&#49496;&#51004;&#47196; &#49552;&#49892;&#54632;&#49688; &#51648;&#51221; . step0: 데이터 정리 . X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . step1: net 생성 . net=tf.keras.Sequential() . step2: net.add(layer) . net.add(tf.keras.layers.Dense(1,use_bias=False)) . step3: net.compile() . net.compile(tf.keras.optimizers.SGD(0.1), loss=&#39;mse&#39;) . 손실함수를 지정할 때, loss= &#39;mse&#39;라고 입력하면 내장되어 있는 &#39;mse&#39;를 찾아서 compile 해준다! | . step4: net.fit . net.fit(X,y,epochs=1000,verbose=0,batch_size=N) . &lt;keras.callbacks.History at 0x29696672700&gt; . net.weights . [&lt;tf.Variable &#39;dense_9/kernel:0&#39; shape=(2, 1) dtype=float32, numpy= array([[2.4904754], [4.1002874]], dtype=float32)&gt;] . &#54400;&#51060;7: &#48289;&#53552;, net.compile&#51032; &#50741;&#49496;&#51004;&#47196; &#49552;&#49892;&#54632;&#49688; &#51648;&#51221; + &#50741;&#54000;&#47560;&#51060;&#51200; &#51648;&#51221; . step0: 데이터 정리 . X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . step1: net 생성 . net=tf.keras.Sequential() . step2: net.add(layer) . net.add(tf.keras.layers.Dense(1,use_bias=False)) . step3: net.compile() . net.compile(optimizer=&#39;sgd&#39;, loss=&#39;mse&#39;) . 옵티마이저를 지정할 때 위에서 손실함수를 지정한 것처럼 optimizer=&#39;sgd&#39;라고 입력하면 내장되어 있는 &#39;sgd&#39;를 찾아서 compile 해준다! | . step4: net.fit . net.fit(X,y,epochs=1000,verbose=0,batch_size=N) . &lt;keras.callbacks.History at 0x296977fc790&gt; . net.weights . [&lt;tf.Variable &#39;dense_10/kernel:0&#39; shape=(2, 1) dtype=float32, numpy= array([[2.6574974], [3.7884219]], dtype=float32)&gt;] . 다른 결과가 나타났음...! | 이는 내장되어 있는 &#39;sgd&#39;에 학습율이 0.01로 설정되어있기 때문 | 이를 해결하기 위해선, 학습율을 바꿔주거나 epoc을 늘려주면 됨 | . . - 학습률 확인 . net.optimizer.learning_rate . &lt;tf.Variable &#39;SGD/learning_rate:0&#39; shape=() dtype=float32, numpy=0.01&gt; . 설정된 학습률이 0.01임 | . net.optimizer.lr = tf.Variable(0.1,dtype=tf.float32) . net.optimizer.lr . &lt;tf.Variable &#39;SGD/learning_rate:0&#39; shape=() dtype=float32, numpy=0.1&gt; . 학습률이 0.1로 바뀌었음! | . net.optimizer.lr = tf.Variable(0.2) . net.optimizer.lr . &lt;tf.Variable &#39;SGD/learning_rate:0&#39; shape=() dtype=float32, numpy=0.2&gt; . dtype은 설정해주지 않아도 되는 것으로 보임 | . net.optimizer.lr = 0.1 . net.optimizer.lr . &lt;tf.Variable &#39;SGD/learning_rate:0&#39; shape=() dtype=float32, numpy=0.1&gt; . 0.1만 입력해주어도 됨! | . . - 다시 . X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . net=tf.keras.Sequential() . net.add(tf.keras.layers.Dense(1,use_bias=False)) . net.compile(optimizer=&#39;sgd&#39;, loss=&#39;mse&#39;) . net.optimizer.lr = tf.Variable(0.1, dtype=tf.float32) . net.optimizer.lr . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=0.1&gt; . net.fit(X,y,epochs=1000,verbose=0,batch_size=N) . &lt;keras.callbacks.History at 0x29697773910&gt; . net.weights . [&lt;tf.Variable &#39;dense_11/kernel:0&#39; shape=(2, 1) dtype=float32, numpy= array([[2.4904754], [4.1002874]], dtype=float32)&gt;] . 학습이 잘 됨! | . - optimizer=&#39;SGD&#39;라고 입력해주어도 실행될까? . X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . net=tf.keras.Sequential() . net.add(tf.keras.layers.Dense(1,use_bias=False)) . net.compile(optimizer=&#39;SGD&#39;, loss=&#39;mse&#39;) . net.optimizer.lr = tf.Variable(0.1, dtype=tf.float32) . net.optimizer.lr . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=0.1&gt; . net.fit(X,y,epochs=1000,verbose=0,batch_size=N) . &lt;keras.callbacks.History at 0x296978f8ee0&gt; . net.weights . [&lt;tf.Variable &#39;dense_12/kernel:0&#39; shape=(2, 1) dtype=float32, numpy= array([[2.4904754], [4.1002874]], dtype=float32)&gt;] . 잘 된다! | . - 학습률을 변경하지 않고 epoc를 늘려보자 . X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . net=tf.keras.Sequential() . net.add(tf.keras.layers.Dense(1,use_bias=False)) . net.compile(optimizer=&#39;sgd&#39;, loss=&#39;MSE&#39;) . net.fit(X,y,epochs=5000,verbose=0,batch_size=N) . &lt;keras.callbacks.History at 0x29697868550&gt; . net.weights . [&lt;tf.Variable &#39;dense_13/kernel:0&#39; shape=(2, 1) dtype=float32, numpy= array([[2.4917016], [4.0980015]], dtype=float32)&gt;] . 값은 잘 나왔음! | 그런데 epoc를 늘리면 실행시간이 길어짐,,, | . &#50668;&#47084;&#44032;&#51648; &#54924;&#44480;&#47784;&#54805;&#51032; &#51201;&#54633;&#44284; &#54617;&#49845;&#44284;&#51221; &#47784;&#45768;&#53552;&#47553; . from matplotlib import animation plt.rcParams[&quot;animation.html&quot;] = &quot;jshtml&quot; . &#50696;&#51228;1 . $y_i approx beta_0 + beta_1 x_i$ . np.random.seed(50000) n=100 x=np.random.randn(N) epsilon=np.random.randn(N)*0.5 y=2.5+4*x+epsilon . X=np.stack([np.ones(N),x],axis=1) y=y.reshape(N,1) . beta_hat=np.array([-3,-2]).reshape(2,1) beta_hat . array([[-3], [-2]]) . yhat=X@beta_hat . plt.plot(x,y,&#39;o&#39;) plt.plot(x,yhat.reshape(-1),&#39;-&#39;) . [&lt;matplotlib.lines.Line2D at 0x29698a5ad90&gt;] . 현재 상황 | 최적의 적합선을 찾아보자! | . - slope 설정 &amp; 업데이트 . slope= (2*X.T @ yhat - 2*X.T @ y)/ N beta_hat2 = beta_hat - 0.1*slope yhat2= X @ beta_hat2 . plt.plot(x,y,&#39;o&#39;) plt.plot(x,yhat.reshape(-1),&#39;-&#39;) plt.plot(x,yhat2.reshape(-1),&#39;-&#39;) . [&lt;matplotlib.lines.Line2D at 0x2969ab340a0&gt;] . 한 번 업데이트 한 상황! | 이를 반복해보자! | . beta_hat=np.array([-3.0,-2.0]).reshape(2,1) # beta_hat 초기값 beta_hat . array([[-3.], [-2.]]) . beta_hats = beta_hat.copy() # beta_hat 업데이트를 기록 for i in range(1,3): # 30번 반복해보자! yhat = X @ beta_hat slope = (2*X.T @ yhat - 2*X.T @ y) / N # 기울기 beta_hat = beta_hat - 0.1*slope # beta_hat 업데이트 beta_hats = np.concatenate([beta_hats,beta_hat],axis=1) # 업데이트를 기록 . beta_hats . array([[-3. , -1.68472716, -0.68022307], [-2. , -0.61702185, 0.44554171]]) . np.concatenate([beta_hats,beta_hat],axis=1)는 새로운 열에 업데이트된 값을 입력해준다! | . beta_hats = beta_hat.copy() # beta_hat 업데이트를 기록 for i in range(1,30): # 30번 반복해보자! yhat = X @ beta_hat slope = (2*X.T @ yhat - 2*X.T @ y) / N # 기울기 beta_hat = beta_hat - 0.1*slope # beta_hat 업데이트 beta_hats = np.concatenate([beta_hats,beta_hat],axis=1) # 업데이트를 기록 . beta_hats . array([[-0.68022307, 0.08672067, 0.67210238, 1.11875026, 1.45941495, 1.7191367 , 1.91705714, 2.06780597, 2.18256204, 2.26986537, 2.33623832, 2.38666093, 2.42493439, 2.45395915, 2.47594752, 2.49258623, 2.50516069, 2.51465004, 2.52179967, 2.52717669, 2.53121228, 2.53423404, 2.53649063, 2.53817069, 2.53941709, 2.54033799, 2.54101514, 2.54151022, 2.54186973, 2.54212864], [ 0.44554171, 1.26213417, 1.88986849, 2.37256745, 2.74386105, 3.02956128, 3.24948292, 3.41883973, 3.54931514, 3.64988338, 3.72743931, 3.78728156, 3.8334832 , 3.86917613, 3.89676933, 3.91811638, 3.93464404, 3.94745097, 3.95738356, 3.96509417, 3.97108583, 3.97574668, 3.97937637, 3.98220635, 3.98441557, 3.98614243, 3.98749409, 3.98855359, 3.98938529, 3.9900392 ]]) . 베타값을 잘 추정했음! | . - 추정치를 구분해서 저장해보자 . beta_hats[0] . array([-0.68022307, 0.08672067, 0.67210238, 1.11875026, 1.45941495, 1.7191367 , 1.91705714, 2.06780597, 2.18256204, 2.26986537, 2.33623832, 2.38666093, 2.42493439, 2.45395915, 2.47594752, 2.49258623, 2.50516069, 2.51465004, 2.52179967, 2.52717669, 2.53121228, 2.53423404, 2.53649063, 2.53817069, 2.53941709, 2.54033799, 2.54101514, 2.54151022, 2.54186973, 2.54212864]) . . b0hats=beta_hats[0].tolist() b1hats=beta_hats[1].tolist() . - fig 설정 . fig = plt.figure(); fig.set_figheight(5); fig.set_figwidth(12) . &lt;Figure size 864x360 with 0 Axes&gt; . np.linalg.inv(X.T@X) @ X.T @ y . array([[2.54261954], [3.99254326]]) . 최적의 β값 | . - 목표: . 왼쪽 그림: 초기의 β값에서의 적합선 -&gt; 최적의 β값에서의 적합선으로 가는 과정 | 오른쪽 그림: (loss 함수에서) 초기의 β값 -&gt; 최적의 β값으로 찾아가는 과정 | . ax1= fig.add_subplot(1,2,1) ax2= fig.add_subplot(1,2,2,projection=&#39;3d&#39;) # ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,b0hats[0] + b1hats[0]*x) # ax2: 오른쪽그림 β0,β1 = np.meshgrid(np.arange(-6,11,0.25),np.arange(-6,11,0.25),indexing=&#39;ij&#39;) β0=β0.reshape(-1) β1=β1.reshape(-1) loss_fn = lambda b0,b1: np.sum((y-b0-b1*x)**2) loss = list(map(loss_fn, β0,β1)) ax2.scatter(β0,β1,loss,alpha=0.02) ax2.scatter(2.5451404,3.94818596,loss_fn(2.5451404,3.94818596),s=200,marker=&#39;*&#39;) def animate(i): line.set_ydata(b0hats[i] + b1hats[i]*x) ax2.scatter(b0hats[i],b1hats[i],loss_fn(b0hats[i],b1hats[i]),color=&quot;grey&quot;) ani = animation.FuncAnimation(fig,animate,frames=30) ani . &lt;/input&gt; Once Loop Reflect - $α$를 어떻게 잡는지가 중요! . $α = 0.1$은 적당한 것으로 보임! | $α = 0.3$은 다소 빠른감이 있음 | $α = 0.5$는 너무 빠름 | $α = 0.9$는 수렴하기는 하지만 위험해보임 | $α = 1.0$은 수렴하지 않음..! | $α = 1.2$는 터짐..! : 너무 큰 $α$를 잡으면 수렴되지 않을 수 있다! 천천히 가더라도 적당한 $α$를 잡아서 학습하자! | . . &#47928;&#48277;&#51221;&#47532; . 1. np.meshgrid(): (이 예제에서) (0,4) (0,5) (0,6) (1,4) (1,5) (1,6) (2,4) (2,5) (2,6) . np.meshgrid(np.array([0,1,2]),np.array([4,5,6])) . [array([[0, 1, 2], [0, 1, 2], [0, 1, 2]]), array([[4, 4, 4], [5, 5, 5], [6, 6, 6]])] . np.meshgrid(np.array([0,1,2]),np.array([4,5,6]),indexing=&#39;ij&#39;) . [array([[0, 0, 0], [1, 1, 1], [2, 2, 2]]), array([[4, 5, 6], [4, 5, 6], [4, 5, 6]])] . β0, β1 = np.meshgrid(np.array([0,1,2]),np.array([4,5,6]),indexing=&#39;ij&#39;) . β0 . array([[0, 0, 0], [1, 1, 1], [2, 2, 2]]) . β0, β1 . (array([[0, 0, 0], [1, 1, 1], [2, 2, 2]]), array([[4, 5, 6], [4, 5, 6], [4, 5, 6]])) . β0.reshape(-1), β1.reshape(-1) . (array([0, 0, 0, 1, 1, 1, 2, 2, 2]), array([4, 5, 6, 4, 5, 6, 4, 5, 6])) . β0 = β0.reshape(-1) β1 = β1.reshape(-1) . β0, β1 . (array([0, 0, 0, 1, 1, 1, 2, 2, 2]), array([4, 5, 6, 4, 5, 6, 4, 5, 6])) . 2. map(lambda :) lambda 함수에 입력값을 넣어 계산 . lambda x,y : x+y # 입력 : 출력 . &lt;function __main__.&lt;lambda&gt;(x, y)&gt; . map(lambda x,y: x+y, β0,β1) . &lt;map at 0x296949e7100&gt; . 이를 실행한 순간 계산이 된 것! | 계산결과는..? | . list(map(lambda x,y: x+y, β0,β1)) . [4, 5, 6, 5, 6, 7, 6, 7, 8] . 리스트화 시켜주면 결과가 나옴 | . - β0, β1에 대한 loss를 계산 . list(map(lambda b0,b1: np.sum(y-b0-b1*x)**2, β0,β1)) . [10333399168.5941, 8978154095.43275, 7718134723.006397, 3801132899.035396, 2997904349.4963017, 2289901500.692204, 468866629.47669226, 217654603.55985174, 61668278.37801162] . - β0, β1 값을 변경해서 계산 . β0, β1 = np.meshgrid(np.arange(-6,11,0.25),np.arange(-6,11,0.25),indexing=&#39;ij&#39;) β0 = β0.reshape(-1) β1 = β1.reshape(-1) . β0, β1 . (array([-6. , -6. , -6. , ..., 10.75, 10.75, 10.75]), array([-6. , -5.75, -5.5 , ..., 10.25, 10.5 , 10.75])) . . . &#50696;&#51228;2 . $y_i approx beta_0 + beta_1 e^{-x_i}$ . - 데이터 . np.random.seed(50000) N= 100 x= np.linspace(-1,1,N) epsilon = np.random.randn(N)*0.5 y= 2.5+4*np.exp(-x)+epsilon . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x296949f8910&gt;] . - 데이터 정리 . X= np.stack([np.ones(N),np.exp(-x)],axis=1) y= y.reshape(N,1) . beta_hat = np.array([-3,-2]).reshape(2,1) beta_hats = beta_hat.copy() # shallow copy, deep copy for i in range(1,30): yhat = X@beta_hat slope = (2*X.T@X@beta_hat - 2*X.T@y) /N beta_hat = beta_hat - 0.05*slope # 학습율을 0.05로 설정 beta_hats = np.concatenate([beta_hats,beta_hat],axis=1) # column에 업데이트 기록 . beta_hats # 업데이트된 β추정치 . array([[-3. , -1.73502832, -0.80429684, -0.11871764, 0.38703886, 0.76088009, 1.03793772, 1.24397484, 1.39788447, 1.5135218 , 1.60104769, 1.66791393, 1.71958573, 1.76007149, 1.79231134, 1.81846199, 1.84010569, 1.8584034 , 1.87420715, 1.88814241, 1.90066848, 1.91212283, 1.92275358, 1.93274328, 1.94222643, 1.95130225, 1.9600441 , 1.96850638, 1.97672954, 1.9847438 ], [-2. , -0.23785241, 1.05213499, 1.99592103, 2.68587152, 3.18971828, 3.55712888, 3.8245243 , 4.01861169, 4.15897501, 4.25997474, 4.33214099, 4.38319501, 4.4187983 , 4.44310199, 4.4591496 , 4.46917247, 4.47480637, 4.47725033, 4.47738314, 4.47584875, 4.47311891, 4.46953912, 4.46536229, 4.46077343, 4.45590779, 4.45086414, 4.44571448, 4.4405112 , 4.43529232]]) . b0hats=beta_hats[0].tolist() b1hats=beta_hats[1].tolist() . np.linalg.inv(X.T@X)@X.T@y . array([[2.44692071], [4.10965865]]) . 최적의 추정치 | . - fig 설정 . fig = plt.figure(); fig.set_figheight(5); fig.set_figwidth(12) . &lt;Figure size 864x360 with 0 Axes&gt; . - 애니메이션 . ax1= fig.add_subplot(1,2,1) ax2= fig.add_subplot(1,2,2,projection=&#39;3d&#39;) # ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,b0hats[0] + b1hats[0]*np.exp(-x)) # 예제 1 코드에서 x대신 np.exp(-x) # ax2: 오른쪽그림 β0,β1 = np.meshgrid(np.arange(-6,11,0.25),np.arange(-6,11,0.25),indexing=&#39;ij&#39;) β0=β0.reshape(-1) β1=β1.reshape(-1) loss_fn = lambda b0,b1: np.sum((y-b0-b1*np.exp(-x))**2) # 예제 1 코드에서 x대신 np.exp(-x) loss = list(map(loss_fn, β0,β1)) ax2.scatter(β0,β1,loss,alpha=0.02) ax2.scatter(2.46307644,3.99681332,loss_fn(2.46307644,3.99681332),s=200,marker=&#39;*&#39;) def animate(i): line.set_ydata(b0hats[i] + b1hats[i]*np.exp(-x)) # b0hats[i] + b1hats[i]*np.exp(-x) -&gt; yhat # 예제 1 코드에서 x대신 np.exp(-x) ax2.scatter(b0hats[i],b1hats[i],loss_fn(b0hats[i],b1hats[i]),color=&quot;grey&quot;) ani = animation.FuncAnimation(fig,animate,frames=30) ani . &lt;/input&gt; Once Loop Reflect &#50696;&#51228;3 . $y_i approx beta_0 + beta_1 e^{-x_i} + beta_2 cos(5x_i)$ . - 데이터 . np.random.seed(50000) N= 100 x= np.linspace(-1,1,N) epsilon = np.random.randn(N)*0.5 y= 2.5+4*np.exp(-x) + 5*np.cos(5*x) + epsilon . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x2969becf580&gt;] . - 데이터 정리 . X=np.stack([np.ones(N),np.exp(-x),np.cos(5*x)],axis=1) y=y.reshape(N,1) . beta_hat = np.array([-3,-2,-1]).reshape(3,1) beta_hats = beta_hat.copy() for i in range(1,30): yhat = X@beta_hat slope = (2*X.T@X@beta_hat -2*X.T@y) /N beta_hat = beta_hat - 0.1 * slope beta_hats= np.concatenate([beta_hats,beta_hat],axis=1) # 업데이트 기록 . beta_hats . array([[-3. , -0.69429935, 0.39518121, 0.92619793, 1.19969943, 1.35346173, 1.45063354, 1.52022672, 1.57563243, 1.62308901, 1.66555491, 1.7044804 , 1.74061845, 1.77439615, 1.80608509, 1.83587982, 1.86393424, 1.89037863, 1.91532789, 1.93888566, 1.96114652, 1.98219738, 2.00211834, 2.02098336, 2.03886084, 2.05581406, 2.07190161, 2.0871778 , 2.10169294, 2.11549372], [-2. , 1.20703823, 2.69616455, 3.39736489, 3.73611249, 3.90716167, 3.99974804, 4.05484069, 4.0913234 , 4.11796784, 4.13890973, 4.15615392, 4.1707209 , 4.18317186, 4.19384964, 4.20298956, 4.21077081, 4.21734051, 4.2228253 , 4.22733713, 4.23097634, 4.23383353, 4.23599079, 4.2375226 , 4.23849656, 4.23897405, 4.2390108 , 4.23865734, 4.23795949, 4.23695878], [-1. , -0.97088711, -0.6887562 , -0.31363003, 0.08323465, 0.47100949, 0.83720468, 1.17758046, 1.49154526, 1.78006201, 2.04470027, 2.28721163, 2.50934361, 2.71276193, 2.8990217 , 3.06956046, 3.22570063, 3.36865582, 3.49953845, 3.61936762, 3.7290766 , 3.82952 , 3.92148029, 4.0056739 , 4.08275676, 4.1533294 , 4.21794163, 4.27709687, 4.33125596, 4.38084088]]) . β0, β1, β2까지 있으니 3개의 값이 나왔음 | . b0hats = beta_hats[0].tolist() b1hats = beta_hats[1].tolist() b2hats = beta_hats[2].tolist() . (b0hats,b1hats,b2hats) = beta_hats . b0hats,b1hats,b2hats = beta_hats # 튜플 언패킹 . np.linalg.inv(X.T@X) @ X.T @ y . array([[2.44123036], [4.10153568], [4.91830278]]) . 최적의 β추정치 | . - fig 설정 . fig = plt.figure(); fig.set_figheight(5); fig.set_figwidth(12) . &lt;Figure size 864x360 with 0 Axes&gt; . - 애니메이션 . ax1= fig.add_subplot(1,2,1) ax2= fig.add_subplot(1,2,2,projection=&#39;3d&#39;) # ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,b0hats[0] + b1hats[0]*np.exp(-x) + b2hats[0]*np.cos(5*x)) # ax2: 오른쪽그림 # β0,β1 = np.meshgrid(np.arange(-6,11,0.25),np.arange(-6,11,0.25),indexing=&#39;ij&#39;) # β0=β0.reshape(-1) # β1=β1.reshape(-1) # loss_fn = lambda b0,b1: np.sum((y-b0-b1*np.exp(-x))**2) # loss = list(map(loss_fn, β0,β1)) # ax2.scatter(β0,β1,loss,alpha=0.02) # ax2.scatter(2.46307644,3.99681332,loss_fn(2.46307644,3.99681332),s=200,marker=&#39;*&#39;) def animate(i): line.set_ydata(b0hats[i] + b1hats[i]*np.exp(-x) + b2hats[i]*np.cos(5*x)) # ax2.scatter(b0hats[i],b1hats[i],loss_fn(b0hats[i],b1hats[i]),color=&quot;grey&quot;) ani = animation.FuncAnimation(fig,animate,frames=30) ani . &lt;/input&gt; Once Loop Reflect &#50696;&#51228;3: &#52992;&#46972;&#49828;&#47484; &#51060;&#50857;&#54620; &#54400;&#51060; . $y_i approx beta_0 + beta_1 e^{-x_i} + beta_2 cos(5x_i)$ . - 데이터 . np.random.seed(50000) N= 100 x= np.linspace(-1,1,N) epsilon = np.random.randn(N)*0.5 y= 2.5+4*np.exp(-x) + 5*np.cos(5*x) + epsilon . - 데이터정리 . X=np.stack([np.ones(N),np.exp(-x),np.cos(5*x)],axis=1) y=y.reshape(N,1) . net = tf.keras.Sequential() # 2: add layer net.add(tf.keras.layers.Dense(1,use_bias=False)) # 3: compile net.compile(tf.optimizers.SGD(0.1), loss=&#39;mse&#39;) # 4: fit net.fit(X,y,epochs=30, batch_size=N) . Epoch 1/30 1/1 [==============================] - 0s 350ms/step - loss: 42.0394 Epoch 2/30 1/1 [==============================] - 0s 7ms/step - loss: 18.8108 Epoch 3/30 1/1 [==============================] - 0s 9ms/step - loss: 12.3693 Epoch 4/30 1/1 [==============================] - 0s 7ms/step - loss: 9.6941 Epoch 5/30 1/1 [==============================] - 0s 6ms/step - loss: 8.0211 Epoch 6/30 1/1 [==============================] - 0s 6ms/step - loss: 6.7375 Epoch 7/30 1/1 [==============================] - 0s 19ms/step - loss: 5.6863 Epoch 8/30 1/1 [==============================] - 0s 10ms/step - loss: 4.8101 Epoch 9/30 1/1 [==============================] - 0s 6ms/step - loss: 4.0765 Epoch 10/30 1/1 [==============================] - 0s 7ms/step - loss: 3.4616 Epoch 11/30 1/1 [==============================] - 0s 6ms/step - loss: 2.9461 Epoch 12/30 1/1 [==============================] - 0s 7ms/step - loss: 2.5137 Epoch 13/30 1/1 [==============================] - 0s 13ms/step - loss: 2.1512 Epoch 14/30 1/1 [==============================] - 0s 6ms/step - loss: 1.8471 Epoch 15/30 1/1 [==============================] - 0s 7ms/step - loss: 1.5921 Epoch 16/30 1/1 [==============================] - 0s 8ms/step - loss: 1.3782 Epoch 17/30 1/1 [==============================] - 0s 8ms/step - loss: 1.1987 Epoch 18/30 1/1 [==============================] - 0s 6ms/step - loss: 1.0482 Epoch 19/30 1/1 [==============================] - 0s 6ms/step - loss: 0.9219 Epoch 20/30 1/1 [==============================] - 0s 5ms/step - loss: 0.8160 Epoch 21/30 1/1 [==============================] - 0s 6ms/step - loss: 0.7270 Epoch 22/30 1/1 [==============================] - 0s 6ms/step - loss: 0.6524 Epoch 23/30 1/1 [==============================] - 0s 8ms/step - loss: 0.5898 Epoch 24/30 1/1 [==============================] - 0s 5ms/step - loss: 0.5372 Epoch 25/30 1/1 [==============================] - 0s 6ms/step - loss: 0.4930 Epoch 26/30 1/1 [==============================] - 0s 18ms/step - loss: 0.4559 Epoch 27/30 1/1 [==============================] - 0s 5ms/step - loss: 0.4248 Epoch 28/30 1/1 [==============================] - 0s 7ms/step - loss: 0.3986 Epoch 29/30 1/1 [==============================] - 0s 5ms/step - loss: 0.3766 Epoch 30/30 1/1 [==============================] - 0s 6ms/step - loss: 0.3581 . &lt;keras.callbacks.History at 0x2969c7073a0&gt; . loss가 잘 줄어들고 있는지 확인! | loss값의 변화가 커졌다 작아졌다를 반복하거나 급격하게 줄어들지는 않는지 확인해볼 필요가 있음(epoc이 지금처럼 작을 때만 가능) | . net.weights . [&lt;tf.Variable &#39;dense_14/kernel:0&#39; shape=(3, 1) dtype=float32, numpy= array([[2.237946 ], [4.1701503], [4.4928823]], dtype=float32)&gt;] . plt.plot(x,y,&#39;o&#39;) plt.plot(x,(X@net.weights).reshape(-1),&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x2969c6f1f70&gt;] . 적합한 회귀선이 추정되었음! | . &#49689;&#51228; . 예제2: 케라스를 이용하여 아래를 만족하는 적절한 $ beta_0$와 $ beta_1$을 구하라. 적합결과를 시각화하라. . $y_i approx beta_0 + beta_1 e^{-x_i}$ . np.random.seed(43052) N= 100 x= np.linspace(-1,1,N) epsilon = np.random.randn(N)*0.5 y= 2.5+4*np.exp(-x) +epsilon . X=np.stack([np.ones(N),np.exp(-x)],axis=1) y=y.reshape(N,1) . net = tf.keras.Sequential() # 2: add layer net.add(tf.keras.layers.Dense(1,use_bias=False)) # 3: compile net.compile(tf.optimizers.SGD(0.05), loss=&#39;mse&#39;) # 4: fit net.fit(X,y,epochs=30, verbose=0, batch_size=N) . &lt;keras.callbacks.History at 0x296a07809a0&gt; . net.weights . [&lt;tf.Variable &#39;dense_32/kernel:0&#39; shape=(2, 1) dtype=float32, numpy= array([[2.5152497], [3.9593651]], dtype=float32)&gt;] . plt.plot(x,y,&#39;o&#39;) plt.plot(x,(X@net.weights).reshape(-1),&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x296a09b8280&gt;] . β0= 2.515 β1= 3.959이고 적합된 회귀직선은 $y_i = 2.515 +3.959 e^{-x_i}$이다. | .",
            "url": "https://ki5n2.github.io/charcoal/2022/04/12/DS.html",
            "relUrl": "/2022/04/12/DS.html",
            "date": " • Apr 12, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "DS 7. 회귀분석문제, GradientTape를 이용한 풀이, GradientTape + opt.apply_gradients를 이용한 풀이, opt.minimize를 이용한 풀이, tf.keras.Sequential",
            "content": ". Data Science . lenture: Data Science_5-2nd week of lectures. | lenture date: 2022-04-04 | lecturer: Guebin choi | study date: 2022-04-06 | author: Kione kim | . . . import tensorflow as tf import numpy as np import matplotlib.pyplot as plt . import tensorflow.experimental.numpy as tnp . tnp.experimental_enable_numpy_behavior() . &#54924;&#44480;&#48516;&#49437; &#47928;&#51228; . - ${ bf y} approx 4 + 2.5 { bf x}$ . tnp.random.seed(50000) N = 200 x = tnp.linspace(0,1,N) epsilon = tnp.random.randn(N)*0.5 y = 2.5+4*x + epsilon y_true = 2.5+4*x . plt.plot(x,y,&#39;.&#39;) plt.plot(x,y_true,&#39;r--&#39;) . [&lt;matplotlib.lines.Line2D at 0x264896df2b0&gt;] . . &#51060;&#47200;&#51201; &#54400;&#51060; . - 지난 시간: 풀이1 ~ 풀이3 . &#54400;&#51060;1: &#49828;&#52860;&#46972;&#48260;&#51204; . - 포인트 . $S_{xx}=$, $S_{xy}=$ | $ hat{ beta}_0=$, $ hat{ beta}_1=$ | . x.shape,y.shape . (TensorShape([200]), TensorShape([200])) . Sxx=sum((x-x.mean())**2) Sxy=sum((x-x.mean())*(y-y.mean())) . beta1_hat = Sxy/Sxx beta0_hat = y.mean() - beta1_hat *x.mean() . beta0_hat, beta1_hat . (&lt;tf.Tensor: shape=(), dtype=float64, numpy=2.4904666055923816&gt;, &lt;tf.Tensor: shape=(), dtype=float64, numpy=4.100304074383147&gt;) . &#54400;&#51060;2: &#48289;&#53552;&#48260;&#51204; . - 포인트 . $ hat{ beta}=(X&#39;X)^{-1}X&#39;y$ | . X=tf.stack([tf.ones(N,dtype=&#39;float64&#39;),x],axis=1) y=y.reshape(N,1) . X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . tf.linalg.inv(X.T @ X) @ X.T @ y . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[2.49046661], [4.10030407]])&gt; . &#54400;&#51060;3: &#48289;&#53552;&#48260;&#51204;, &#49552;&#49892;&#54632;&#49688;&#51032; &#46020;&#54632;&#49688;&#51060;&#50857; . - 포인트 . $loss&#39;( beta)=-2X&#39;y +2X&#39;X beta$ | $ beta_{new} = beta_{old} - alpha times loss&#39;( beta_{old})$ | . y=y.reshape(N,1) X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . beta_hat = tnp.array([-5,10]).reshape(2,1) beta_hat . &lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy= array([[-5], [10]])&gt; . alpha=0.1 . $loss&#39;( beta) = -2X&#39;y+2X&#39;X beta$ . slope = -2*X.T @ y + 2*X.T@ X @ beta_hat slope . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[-1816.24745711], [ -709.49075016]])&gt; . step = - alpha*slope step . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[181.62474571], [ 70.94907502]])&gt; . for epoc in range(1000): slope = (-2*X.T @ y + 2*X.T@ X @ beta_hat)/N step = - alpha * slope beta_hat = beta_hat + step . beta_hat . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[2.49046015], [4.10031613]])&gt; . plt.plot(x,y,&#39;.&#39;) plt.plot(x,y_true,&#39;r--&#39;) plt.plot(x,X@beta_hat,&#39;b--&#39;) . [&lt;matplotlib.lines.Line2D at 0x264896a74f0&gt;] . . GradientTape&#47484; &#51060;&#50857;&#54620; &#54400;&#51060; . - 포인트 . # 포인트 1: 그레디언트 테입 with tf.GradientTape() as tape: loss = (y-yhat).T @ (y-yhat) # 포인트 2: 미분 slope = tape.gradient(loss,beta_hat) # 포인트 3: update beta_hat.assign_sub(slope*alph) . &#54400;&#51060;1: &#48289;&#53552;&#48260;&#51204; . - 선언 . tnp.random.seed(50000) N = 200 x = tnp.linspace(0,1,N) epsilon = tnp.random.randn(N)*0.5 y = 2.5+4*x + epsilon y_true = 2.5+4*x . X=tf.stack([tf.ones(N,dtype=&#39;float64&#39;),x],axis=1) y=y.reshape(N,1) . X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . tnp.array([-5.0,-10.0]).reshape(2,1) . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[ -5.], [-10.]])&gt; . - 임의의 beta_hat 선언 . beta_hat = tf.Variable(tnp.array([-5.0,-10.0]).reshape(2,1)) beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[ -5.], [-10.]])&gt; . alpha=0.1 . with tf.GradientTape(persistent=True) as tape: # tape.watch(beta_hat) yhat= X @ beta_hat loss= (y- yhat).T @ (y - yhat) /N . loss를 SSE를 N으로 나눈 MSE를 사용함! | SSE를 최소화하는 $beta$값이나 SSE를 N으로 나눈 MSE를 최소화 하는 $beta$값이랑 같기 때문에 MSE를 사용! | 보통 SSE를 사용하긴 하지만, 머신러닝 &amp; 딮러닝에선 MSE를 많이 사용함! | MSE를 사용함으로써 loss값이 N으로 나눈 만큼 작아지기 때문에 alpha값을 지난 시간보다 키웠음 ! | . tape.gradient(loss,beta_hat) # loss를 beta_hat으로 미분 . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[-29.08123729], [-16.91428792]])&gt; . 미분 값 -&gt; slope | . - 반복 . alpha=0.1 . for epoc in range(1000): with tf.GradientTape(persistent=True) as tape: yhat=X@beta_hat loss=(y-yhat).T @ (y-yhat) / N slope= tape.gradient(loss,beta_hat) beta_hat.assign_sub(slope*alpha) . beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[2.49047318], [4.1002918 ]])&gt; . 풀이1~3에서 구한 $ beta$ 값과 같음 | . &#54400;&#51060;2: &#49828;&#52860;&#46972;&#48260;&#51204; . - 포인트 . # 포인트 : 미분 slope0, slope1 = tape.gradient(loss,[beta0_hat,beta1_hat]) . tnp.random.seed(50000) N = 200 x = tnp.linspace(0,1,N) epsilon = tnp.random.randn(N)*0.5 y = 2.5+4*x + epsilon y_true = 2.5+4*x . x.shape,y.shape . (TensorShape([200]), TensorShape([200])) . beta0_hat= tf.Variable(-5.0) beta1_hat= tf.Variable(-10.0) . alpha=0.1 . for epoc in range(1000): with tf.GradientTape(persistent=True) as tape: yhat= beta0_hat + beta1_hat*x loss= sum((y-yhat)**2) / N slope0, slope1= tape.gradient(loss,[beta0_hat,beta1_hat]) beta0_hat.assign_sub(slope0*alpha) beta1_hat.assign_sub(slope1*alpha) . (beta0_hat,beta1_hat) . (&lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=2.4904754&gt;, &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=4.1002874&gt;) . for epoc in range(1000): with tf.GradientTape(persistent=True) as tape: yhat= ,,, loss= ,,, slope0, slope1= tape.gradient(loss,[beta0_hat,beta1_hat]) beta0_hat.assign_sub(slope0*alpha) beta1_hat.assign_sub(slope1*alpha) : 1. loss를 beta0, beta1으로 각각 미분 -&gt; 미분 값 2개 나오는데, beta0로 미분해준 값을 slope0로, beta1로 미분해준 값을 slope1로 받아줌!! 2. beta0_hat, beta1_hat값을 각각 변경! . 코드에는 문제없지만, 시간이 매우 오래걸림..! | 다음과 같이 코딩하는 것이 훨씬 빠름! | . - sum() 대신 tf.reduce_sum 사용! . for epoc in range(1000): with tf.GradientTape(persistent=True) as tape: yhat= beta0_hat + beta1_hat*x loss= tf.reduce_sum((y-yhat)**2) / N slope0, slope1= tape.gradient(loss,[beta0_hat,beta1_hat]) beta0_hat.assign_sub(slope0*alpha) beta1_hat.assign_sub(slope1*alpha) . (beta0_hat,beta1_hat) . (&lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=2.4904754&gt;, &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=4.1002874&gt;) . GradientTape + opt.apply_gradients&#47484; &#51060;&#50857;&#54620; &#54400;&#51060; . &#54400;&#51060;1: &#48289;&#53552;&#48260;&#51204; . - 포인트 . # 포인트: 업데이트 방식 opt.apply_gradients([(slope,beta_hat)]) # pair의 list가 입력되어야 함!! . tnp.random.seed(50000) N = 200 x = tnp.linspace(0,1,N) epsilon = tnp.random.randn(N)*0.5 y = 2.5+4*x + epsilon y_true = 2.5+4*x . X=tf.stack([tf.ones(N,dtype=&#39;float64&#39;),x],axis=1) y=y.reshape(N,1) . X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . beta_hat = tf.Variable(tnp.array([-5.0,-10.0]).reshape(2,1)) beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[ -5.], [-10.]])&gt; . alpha=0.1 . - optimizer 선언 . opt= tf.optimizers.SGD(alpha) . iter1 . with tf.GradientTape() as tape: yhat= X @ beta_hat loss= (y-yhat).T @ (y-yhat)/N slope=tape.gradient(loss,beta_hat) opt.apply_gradients([(slope,beta_hat)]) . &lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=int64, numpy=1&gt; . beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[-2.09187623], [-8.30857118]])&gt; . 한 번 미분한 값! | . iter 반복 . for epoc in range(1000): with tf.GradientTape() as tape: yhat= X @ beta_hat loss= (y-yhat).T @ (y-yhat) / N slope= tape.gradient(loss,beta_hat) opt.apply_gradients([(slope,beta_hat)]) . beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[2.49047309], [4.10029197]])&gt; . opt.apply_gradients([(slope,beta_hat)])는 beta_hat.assign_sub(slope*alpha)와 같은 기능(업데이트)을 하는 코드 | . &#54400;&#51060;2: &#49828;&#52860;&#46972;&#48260;&#51204; . - 포인트 . # 포인트코드: loss beta0_hat, beta1_hat으로 각각 미분 -&gt; 각각의 slope 값 slope0, slope1= tape.gradient(loss,[beta0_hat, beta1_hat]) # 포인트코드: 업데이트 opt.apply_gradients([(slope0,beta0_hat),(slope1,beta1_hat)]) # pair의 list가 입력 . tnp.random.seed(50000) N = 200 x = tnp.linspace(0,1,N) epsilon = tnp.random.randn(N)*0.5 y = 2.5+4*x + epsilon y_true = 2.5+4*x . x.shape,y.shape . (TensorShape([200]), TensorShape([200])) . beta0_hat= tf.Variable(-5.0) beta1_hat= tf.Variable(-10.0) . alpha=0.1 . opt=tf.optimizers.SGD(alpha) . for epoc in range(1000): with tf.GradientTape() as tape: yhat= beta0_hat + beta1_hat*x loss= tf.reduce_sum((y-yhat)**2) / N slope0, slope1= tape.gradient(loss,[beta0_hat, beta1_hat]) opt.apply_gradients([(slope0,beta0_hat), (slope1,beta1_hat)]) . beta0_hat,beta1_hat . (&lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=2.4904754&gt;, &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=4.1002874&gt;) . opt.minimize&#47484; &#51060;&#50857;&#54620; &#54400;&#51060; . : tf.GradientTape를 사용하지 않아도 됨. 어떤 계산식에 의해 미분값이 계산되는지 몰라도 쓸 수 있는 코드 . &#54400;&#51060;1: &#48289;&#53552;&#48260;&#51204;, &#49324;&#50857;&#51088;&#51221;&#51032; &#49552;&#49892;&#54632;&#49688;(lambda) . - 포인트 . # 포인트1: 손실함수 정의 loss_fn = lambda: ,,, # 포인트2: 옵티마이저 opt = tf.optimizers.SGD(alpha) # 포인트3: 미분 &amp; 업데이트 = minimize opt.minimize(loss_fn,beta_hat) . tnp.random.seed(50000) N = 200 x = tnp.linspace(0,1,N) epsilon = tnp.random.randn(N)*0.5 y = 2.5+4*x + epsilon y_true = 2.5+4*x . X=tf.stack([tf.ones(N,dtype=&#39;float64&#39;),x],axis=1) y=y.reshape(N,1) X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . alpha=0.1 beta_hat = tf.Variable(tnp.array([-5.0,-10.0]).reshape(2,1)) beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[ -5.], [-10.]])&gt; . opt=tf.optimizers.SGD(alpha) . opt.minimize(미분할 식, 미분하고자 하는 값)는 미분 + update를 동시에 수행 1. loss와 beta_hat값만 전달해주면 됨!! 2. loss는 사용자정의 함수로 전달 . loss_fn = lambda:(y-X @ beta_hat).T @ (y-X @ beta_hat)/ N . iter1 . opt.minimize(loss_fn,beta_hat) . &lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=int64, numpy=1&gt; . beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[-2.09187623], [-8.30857118]])&gt; . iter반복 . for epoc in range(1000): opt.minimize(loss_fn,beta_hat) . beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[2.49047309], [4.10029197]])&gt; . &#54400;&#51060;2:&#49828;&#52860;&#46972; &#48260;&#51204;, &#49324;&#50857;&#51088;&#51221;&#51032; &#49552;&#49892;&#54632;&#49688;(lambda) . - 포인트 . # 포인트: 미분 &amp; 업데이트 = minimize opt.minimize(loss_fn,[beta0_hat,beta1_hat]) . tnp.random.seed(50000) N = 200 x = tnp.linspace(0,1,N) epsilon = tnp.random.randn(N)*0.5 y = 2.5+4*x + epsilon y_true = 2.5+4*x . x.shape,y.shape . (TensorShape([200]), TensorShape([200])) . beta0_hat= tf.Variable(-5.0) beta1_hat= tf.Variable(-10.0) . alpha=0.1 . opt=tf.optimizers.SGD(alpha) . loss_fn= lambda: tf.reduce_sum((y-(beta0_hat+beta1_hat*x))**2) / N . iter1 . opt.minimize(loss_fn,[beta0_hat,beta1_hat]) . &lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=int64, numpy=1&gt; . beta0_hat,beta1_hat . (&lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=-2.0918763&gt;, &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=-8.308571&gt;) . iter반복 . for epoc in range(1000): opt.minimize(loss_fn,[beta0_hat,beta1_hat]) . beta0_hat,beta1_hat . (&lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=2.4904754&gt;, &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=4.1002874&gt;) . lambda &#54632;&#49688; . - 입력이 있는 형태 . lambda x: x**2 =&gt; lambda(x) = x^2 | lambda x,y: x+y =&gt; lambda(x,y) = x+y | . - 입력이 없는 형태 . lambda: y =&gt; lamnda() = y | . : 입력이 무엇이든 y를 출력하는 함수! . -&gt; lambda: tf.reduce_sum((y-(beta0_hat+beta1_hat*x))**2) =&gt; lambda() = tf.reduce_sum(y-(beta0_hat+beta1_hat*x)) . : 입력이 무엇이든 tf.reduce_sum(y-(beta0_hat+beta1_hat*x))를 출력하는 함수 . &#54400;&#51060;3: &#48289;&#53552;&#48260;&#51204;, &#49324;&#50857;&#51088;&#51221;&#51032; &#49552;&#49892;&#54632;&#49688;(def) . - 포인트 . # 포인트: 손실함수정의 def loss_fn(): return ,,, . tnp.random.seed(50000) N = 200 x = tnp.linspace(0,1,N) epsilon = tnp.random.randn(N)*0.5 y = 2.5+4*x + epsilon y_true = 2.5+4*x . X=tf.stack([tf.ones(N,dtype=&#39;float64&#39;),x],axis=1) y=y.reshape(N,1) X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . alpha=0.1 beta_hat = tf.Variable(tnp.array([-5.0,-10.0]).reshape(2,1)) beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[ -5.], [-10.]])&gt; . opt=tf.optimizers.SGD(alpha) . def loss_fn(): return tf.reduce_sum((y-X@beta_hat).T @ (y-X@beta_hat)) / N . iter1 . opt.minimize(loss_fn,beta_hat) . &lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=int64, numpy=1&gt; . beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[-2.09187623], [-8.30857118]])&gt; . iter반복 . for epoc in range(1000): opt.minimize(loss_fn,beta_hat) . beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[2.49047309], [4.10029197]])&gt; . 이 코드가 좋은 이유: 사용자 정의 함수를 내가 원하는 형태로 정의하여 사용할 수 있음! | . &#54400;&#51060;4: &#48289;&#53552;&#48260;&#51204;, &#49324;&#50857;&#51088;&#51221;&#51032; &#49552;&#49892;&#54632;&#49688;(def) . - 포인트 . # 포인트: 손실함수정의 def loss_fn(): yhat= loss= ,,, return loss . - 예시 . def loss_fn(): yhat= X@beta_hat loss= (y-yhat).T @ (y-yhat) / N return loss # loss가 출력 . 입력값이 무엇이든 loss가 출력됨. loss는 우리가 미분하고자 하는 식 | . for epoc in range(1000): opt.minimize(loss_fn,beta_hat) . beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[2.49046661], [4.10030407]])&gt; . 내가 원하는 형태의 코딩이 가능 | . &#54400;&#51060;5: &#48289;&#53552;&#48260;&#51204;, &#49324;&#50857;&#51088;&#51221;&#51032; &#49552;&#49892;&#54632;&#49688;(tf.losses.MSE) . - 포인트 . # 포인트: 이미 구현되어 있는 손실함수 이용 tf.losses.MSE(y,yhat) . tf.losses.MSE(tnp.array([1.0,2.0,3.0]), tnp.array([0.0,0.0,0.0])) . &lt;tf.Tensor: shape=(), dtype=float64, numpy=4.666666666666667&gt; . (1+4+9)/3 . 4.666666666666667 . tnp.random.seed(50000) N = 200 x = tnp.linspace(0,1,N) epsilon = tnp.random.randn(N)*0.5 y = 2.5+4*x + epsilon y_true = 2.5+4*x . X=tf.stack([tf.ones(N,dtype=&#39;float64&#39;),x],axis=1) y=y.reshape(N,1) X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . alpha=0.1 beta_hat = tf.Variable(tnp.array([-5.0,-10.0]).reshape(2,1)) beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[ -5.], [-10.]])&gt; . opt=tf.optimizers.SGD(alpha) . yhat= X @ beta_hat . tf.losses.MSE(y,yhat) . &lt;tf.Tensor: shape=(200,), dtype=float64, numpy= array([ 46.96022558, 60.70686684, 72.30282228, 81.2802598 , 57.80729918, 43.17952069, 58.53054446, 58.31180694, 61.85092764, 58.31730177, 79.71547263, 78.60501259, 71.99894261, 75.00602384, 85.12349938, 55.10406785, 73.69786462, 80.95467083, 74.6669447 , 75.82773797, 85.53770852, 67.22515134, 83.92316782, 82.73476828, 83.61351332, 71.88184929, 98.56777325, 100.69671217, 106.00993654, 99.11303261, 75.80120511, 66.43965872, 93.29103212, 92.02161062, 103.43848691, 91.95513609, 89.55063202, 102.5791008 , 104.04281702, 95.9503876 , 122.33084547, 110.14601438, 107.8128172 , 107.24683005, 114.95773419, 118.679864 , 114.32865366, 106.48965615, 138.72702545, 121.53161946, 127.26461033, 118.57340053, 113.79996022, 127.69733957, 123.58570914, 132.75464371, 125.47854101, 139.15373989, 146.19252441, 163.53659744, 139.09846468, 150.22094322, 147.44621794, 120.55776355, 146.73702063, 140.88032213, 146.51914749, 153.16727863, 157.2906466 , 140.12227851, 160.75774017, 160.93203199, 158.35458953, 186.0423395 , 160.32743626, 144.22928985, 174.58984164, 155.97987705, 161.68940014, 179.58376217, 169.20486627, 164.32615346, 180.49631444, 183.26489411, 207.81251795, 176.71076052, 186.4834373 , 176.17945897, 183.78631202, 192.71936065, 216.82573734, 183.60108262, 185.18643139, 182.91320649, 181.51531937, 208.87678113, 204.10382008, 181.3811454 , 186.22041838, 208.35807508, 223.05341586, 217.99062832, 220.93169073, 227.48967225, 204.52370814, 210.56012546, 224.69852368, 247.41250168, 236.42542716, 229.40708813, 248.79603539, 261.46634784, 255.29328625, 278.7301513 , 266.50963835, 232.72414492, 253.7221811 , 247.85548131, 244.07870316, 257.84948971, 234.30508042, 274.1894823 , 263.817655 , 242.73380909, 286.68409303, 249.79602287, 245.53710442, 269.04506651, 262.6498617 , 304.44265244, 287.7068894 , 302.79565392, 270.90160857, 288.45621453, 266.58616864, 300.3959935 , 277.55271521, 283.66872636, 310.29812029, 279.93301006, 302.14354378, 285.56093353, 279.93862274, 327.14046516, 287.59085982, 319.80234296, 360.65183304, 348.50598211, 314.8949131 , 373.42098076, 315.07724343, 342.10914738, 328.23671337, 306.01509384, 373.78602342, 298.40856652, 334.71498126, 367.58615747, 359.76181244, 350.63126972, 356.18123273, 351.43013181, 365.19477051, 383.69790541, 382.51460136, 347.73682534, 388.30267436, 382.64077176, 350.86181903, 368.12582049, 377.51971677, 380.33371329, 369.39525218, 405.61158059, 401.83207386, 391.55433637, 403.07036866, 393.6718148 , 422.72367689, 377.48186669, 415.07489252, 449.02617032, 414.40741051, 422.1835654 , 454.60513137, 412.48139172, 439.92130854, 422.2543035 , 417.95789578, 419.90903882, 441.76601488, 441.88258781, 414.02012705, 477.63963252, 438.21558695, 451.38032516, 436.86552668, 440.611652 , 465.06080711, 474.2370458 ])&gt; . 매트릭스 형태로 되어 있어 벡터 형태로 변환해서 입력해야 함 | . tf.losses.MSE(y.reshape(-1), yhat.reshape(-1)) . &lt;tf.Tensor: shape=(), dtype=float64, numpy=228.42737562724935&gt; . - 손실함수 정의 . def loss_fn(): yhat= X @ beta_hat loss= tf.losses.MSE(y.reshape(-1), yhat.reshape(-1)) return loss . for epoc in range(1000): opt.minimize(loss_fn, beta_hat) . beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[2.49047318], [4.1002918 ]])&gt; . 단점: 차원을 조절해주어야 함. 스칼라 값이 나오도록,, | . &#54400;&#51060;6: &#48289;&#53552;&#48260;&#51204;, &#49324;&#50857;&#51088;&#51221;&#51032; &#49552;&#49892;&#54632;&#49688;(tf.losses.MeanSquaredError) . - 포인트 . # 포인트: 클래스로부터 손실함수 오브젝트 생성 (함수를 찍어내는 클래스) mse_fn = tf.losses.MeanSquaredError() mse_fn(y,yhat) . tnp.random.seed(50000) N = 200 x = tnp.linspace(0,1,N) epsilon = tnp.random.randn(N)*0.5 y = 2.5+4*x + epsilon y_true = 2.5+4*x . X=tf.stack([tf.ones(N,dtype=&#39;float64&#39;),x],axis=1) y=y.reshape(N,1) X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . alpha=0.1 beta_hat = tf.Variable(tnp.array([-5.0,-10.0]).reshape(2,1)) beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[ -5.], [-10.]])&gt; . opt=tf.optimizers.SGD(alpha) . mseloss_fn = tf.losses.MeanSquaredError() . mseloss_fn(y.reshape(-1),yhat.reshape(-1)) . &lt;tf.Tensor: shape=(), dtype=float64, numpy=228.4273681640625&gt; . 이것도 스칼라 값이 나오도록 차원을 조절해주어야 함! | . - 손실함수 정의 . def loss_fn(): yhat= X @ beta_hat loss= mseloss_fn(y.reshape(-1),yhat.reshape(-1)) return loss . for epoc in range(1000): opt.minimize(loss_fn,beta_hat) . beta_hat . &lt;tf.Variable &#39;Variable:0&#39; shape=(2, 1) dtype=float64, numpy= array([[2.49047309], [4.10029197]])&gt; . - 오류 . def loss_fn(): yhat= X @ beta_hat loss= tf.losses.MeanSquaredError((y.reshape(-1),yhat.reshape(-1))) return loss . for epoc in range(1000): opt.minimize(loss_fn,beta_hat) . ValueError Traceback (most recent call last) Input In [326], in &lt;cell line: 1&gt;() 1 for epoc in range(1000): -&gt; 2 opt.minimize(loss_fn,beta_hat) File ~ anaconda3 envs ds2022 lib site-packages keras optimizer_v2 optimizer_v2.py:530, in OptimizerV2.minimize(self, loss, var_list, grad_loss, name, tape) 499 def minimize(self, loss, var_list, grad_loss=None, name=None, tape=None): 500 &#34;&#34;&#34;Minimize `loss` by updating `var_list`. 501 502 This method simply computes gradient using `tf.GradientTape` and calls (...) 528 529 &#34;&#34;&#34; --&gt; 530 grads_and_vars = self._compute_gradients( 531 loss, var_list=var_list, grad_loss=grad_loss, tape=tape) 532 return self.apply_gradients(grads_and_vars, name=name) File ~ anaconda3 envs ds2022 lib site-packages keras optimizer_v2 optimizer_v2.py:574, in OptimizerV2._compute_gradients(self, loss, var_list, grad_loss, tape) 572 if not callable(var_list): 573 tape.watch(var_list) --&gt; 574 loss = loss() 575 if callable(var_list): 576 var_list = var_list() Input In [325], in loss_fn() 1 def loss_fn(): 2 yhat= X @ beta_hat -&gt; 3 loss= tf.losses.MeanSquaredError((y.reshape(-1),yhat.reshape(-1))) 4 return loss File ~ anaconda3 envs ds2022 lib site-packages keras losses.py:310, in MeanSquaredError.__init__(self, reduction, name) 293 def __init__(self, 294 reduction=losses_utils.ReductionV2.AUTO, 295 name=&#39;mean_squared_error&#39;): 296 &#34;&#34;&#34;Initializes `MeanSquaredError` instance. 297 298 Args: (...) 308 name: Optional name for the instance. Defaults to &#39;mean_squared_error&#39;. 309 &#34;&#34;&#34; --&gt; 310 super().__init__(mean_squared_error, name=name, reduction=reduction) File ~ anaconda3 envs ds2022 lib site-packages keras losses.py:227, in LossFunctionWrapper.__init__(self, fn, reduction, name, **kwargs) 205 def __init__(self, 206 fn, 207 reduction=losses_utils.ReductionV2.AUTO, 208 name=None, 209 **kwargs): 210 &#34;&#34;&#34;Initializes `LossFunctionWrapper` class. 211 212 Args: (...) 225 **kwargs: The keyword arguments that are passed on to `fn`. 226 &#34;&#34;&#34; --&gt; 227 super().__init__(reduction=reduction, name=name) 228 self.fn = fn 229 self._fn_kwargs = kwargs File ~ anaconda3 envs ds2022 lib site-packages keras losses.py:88, in Loss.__init__(self, reduction, name) 73 def __init__(self, reduction=losses_utils.ReductionV2.AUTO, name=None): 74 &#34;&#34;&#34;Initializes `Loss` class. 75 76 Args: (...) 86 name: Optional name for the instance. 87 &#34;&#34;&#34; &gt; 88 losses_utils.ReductionV2.validate(reduction) 89 self.reduction = reduction 90 self.name = name File ~ anaconda3 envs ds2022 lib site-packages keras utils losses_utils.py:83, in ReductionV2.validate(cls, key) 80 @classmethod 81 def validate(cls, key): 82 if key not in cls.all(): &gt; 83 raise ValueError( 84 f&#39;Invalid Reduction Key: {key}. Expected keys are &#34;{cls.all()}&#34;&#39;) ValueError: Invalid Reduction Key: (&lt;tf.Tensor: shape=(200,), dtype=float64, numpy= array([1.85275314, 2.74120989, 3.40260411, 3.86480278, 2.40210613, 1.31985631, 2.34901823, 2.284458 , 2.46252602, 2.18431527, 3.42583962, 3.31318298, 2.88220399, 3.00733549, 3.52272213, 1.66944258, 2.78072594, 3.14321 , 2.73648107, 2.75313851, 3.2436347 , 2.14381816, 3.05543125, 2.94008656, 2.93801235, 2.22203501, 3.62159774, 3.67799122, 3.88907751, 3.49826642, 2.19885106, 1.59326367, 3.05068809, 2.93449805, 3.46192861, 2.8305301 , 2.65407435, 3.26883764, 3.29059035, 2.83562788, 4.0502773 , 3.43474563, 3.27274234, 3.19520052, 3.51077918, 3.63272229, 3.3809 , 2.9575735 , 4.36618343, 3.56182648, 3.76859893, 3.32632733, 3.05464109, 3.63700817, 3.40334311, 3.75810104, 3.3876501 , 3.93202274, 4.1764372 , 4.82331873, 3.77892584, 4.19113873, 4.02716554, 2.8140508 , 3.89742531, 3.60297001, 3.78792647, 4.0092427 , 4.12447136, 3.36998897, 4.16143963, 4.11805975, 3.96581155, 4.97139214, 3.94345412, 3.24070572, 4.39414946, 3.61984367, 3.7961167 , 4.43103737, 3.98777658, 3.74862454, 4.31428866, 4.36668221, 5.19459834, 4.02190318, 4.33428583, 3.90140176, 4.13467048, 4.40997807, 5.20239075, 3.97708338, 3.98520656, 3.85117406, 3.74914404, 4.67870071, 4.46237022, 3.5934099 , 3.72163712, 4.45973941, 4.90984728, 4.68912881, 4.73814294, 4.90688137, 4.0750479 , 4.23430813, 4.66331426, 5.35246718, 4.94899606, 4.66880361, 5.24563146, 5.59203164, 5.34975923, 6.01682146, 5.5964797 , 4.47640444, 5.09951338, 4.86402962, 4.69337013, 5.07779304, 4.2768764 , 5.47826588, 5.11181129, 4.39901233, 5.7005923 , 4.52352963, 4.33796533, 5.02068374, 4.77431511, 5.96587303, 5.42926138, 5.81810993, 4.82592311, 5.30058169, 4.59379835, 5.54801606, 4.82574257, 4.95804583, 5.68060751, 4.74627408, 5.34710083, 4.81312113, 4.59568804, 5.90109513, 4.72232315, 5.59658612, 6.65415208, 6.28138025, 5.30809268, 6.83666644, 5.21272686, 5.90825308, 5.4791133 , 4.8048449 , 6.59485311, 4.48556154, 5.45602146, 6.28308931, 6.02768964, 5.73520098, 5.83256331, 5.65601759, 5.96936635, 6.39725355, 6.31677447, 5.35624566, 6.36368854, 6.16924599, 5.2890948 , 5.69414292, 5.88715305, 5.90918155, 5.57644188, 6.44633357, 6.30203093, 5.99376212, 6.23239137, 5.94669229, 6.61552144, 5.4339177 , 6.32816074, 7.09476023, 6.21127041, 6.35112611, 7.07523998, 6.01315549, 6.62756748, 6.15184238, 5.9967824 , 5.99419475, 6.47049184, 6.42301354, 5.69924333, 7.15647568, 6.18485576, 6.44671813, 6.05208212, 6.0912541 , 6.61551979, 6.77698431])&gt;, &lt;tf.Tensor: shape=(200,), dtype=float64, numpy= array([2.49047318, 2.51107766, 2.53168214, 2.55228662, 2.5728911 , 2.59349559, 2.61410007, 2.63470455, 2.65530903, 2.67591351, 2.69651799, 2.71712247, 2.73772696, 2.75833144, 2.77893592, 2.7995404 , 2.82014488, 2.84074936, 2.86135384, 2.88195832, 2.90256281, 2.92316729, 2.94377177, 2.96437625, 2.98498073, 3.00558521, 3.02618969, 3.04679418, 3.06739866, 3.08800314, 3.10860762, 3.1292121 , 3.14981658, 3.17042106, 3.19102555, 3.21163003, 3.23223451, 3.25283899, 3.27344347, 3.29404795, 3.31465243, 3.33525692, 3.3558614 , 3.37646588, 3.39707036, 3.41767484, 3.43827932, 3.4588838 , 3.47948829, 3.50009277, 3.52069725, 3.54130173, 3.56190621, 3.58251069, 3.60311517, 3.62371966, 3.64432414, 3.66492862, 3.6855331 , 3.70613758, 3.72674206, 3.74734654, 3.76795103, 3.78855551, 3.80915999, 3.82976447, 3.85036895, 3.87097343, 3.89157791, 3.9121824 , 3.93278688, 3.95339136, 3.97399584, 3.99460032, 4.0152048 , 4.03580928, 4.05641377, 4.07701825, 4.09762273, 4.11822721, 4.13883169, 4.15943617, 4.18004065, 4.20064514, 4.22124962, 4.2418541 , 4.26245858, 4.28306306, 4.30366754, 4.32427202, 4.34487651, 4.36548099, 4.38608547, 4.40668995, 4.42729443, 4.44789891, 4.46850339, 4.48910788, 4.50971236, 4.53031684, 4.55092132, 4.5715258 , 4.59213028, 4.61273476, 4.63333925, 4.65394373, 4.67454821, 4.69515269, 4.71575717, 4.73636165, 4.75696613, 4.77757062, 4.7981751 , 4.81877958, 4.83938406, 4.85998854, 4.88059302, 4.9011975 , 4.92180199, 4.94240647, 4.96301095, 4.98361543, 5.00421991, 5.02482439, 5.04542887, 5.06603336, 5.08663784, 5.10724232, 5.1278468 , 5.14845128, 5.16905576, 5.18966024, 5.21026473, 5.23086921, 5.25147369, 5.27207817, 5.29268265, 5.31328713, 5.33389161, 5.3544961 , 5.37510058, 5.39570506, 5.41630954, 5.43691402, 5.4575185 , 5.47812298, 5.49872747, 5.51933195, 5.53993643, 5.56054091, 5.58114539, 5.60174987, 5.62235435, 5.64295884, 5.66356332, 5.6841678 , 5.70477228, 5.72537676, 5.74598124, 5.76658572, 5.7871902 , 5.80779469, 5.82839917, 5.84900365, 5.86960813, 5.89021261, 5.91081709, 5.93142157, 5.95202606, 5.97263054, 5.99323502, 6.0138395 , 6.03444398, 6.05504846, 6.07565294, 6.09625743, 6.11686191, 6.13746639, 6.15807087, 6.17867535, 6.19927983, 6.21988431, 6.2404888 , 6.26109328, 6.28169776, 6.30230224, 6.32290672, 6.3435112 , 6.36411568, 6.38472017, 6.40532465, 6.42592913, 6.44653361, 6.46713809, 6.48774257, 6.50834705, 6.52895154, 6.54955602, 6.5701605 , 6.59076498])&gt;). Expected keys are &#34;(&#39;auto&#39;, &#39;none&#39;, &#39;sum&#39;, &#39;sum_over_batch_size&#39;)&#34; . 이는 오류 | . tf.keras.Sequential . - $ hat{y}_i= hat{ beta}_0+ hat{ beta}_1x_i$ 의 서로다른 표현 . import graphviz def gv(s): return graphviz.Source(&#39;digraph G{ rankdir=&quot;LR&quot;&#39;+s + &#39;; }&#39;) . - 방식1: 스칼라버전, bias=False . gv(&#39;&#39;&#39; &quot;1&quot; -&gt; &quot;beta0_hat + x*beta1_hat, bias=False&quot;[label=&quot;* beta0_hat&quot;] &quot;x&quot; -&gt; &quot;beta0_hat + x*beta1_hat, bias=False&quot;[label=&quot;* beta1_hat&quot;] &quot;beta0_hat + x*beta1_hat, bias=False&quot; -&gt; &quot;yhat&quot;[label=&quot;indentity&quot;] &#39;&#39;&#39;) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G 1 1 beta0_hat + x*beta1_hat, &#160;&#160;&#160;bias=False beta0_hat + x*beta1_hat, &#160;&#160;&#160;bias=False 1&#45;&gt;beta0_hat + x*beta1_hat, &#160;&#160;&#160;bias=False * beta0_hat yhat yhat beta0_hat + x*beta1_hat, &#160;&#160;&#160;bias=False&#45;&gt;yhat indentity x x x&#45;&gt;beta0_hat + x*beta1_hat, &#160;&#160;&#160;bias=False * beta1_hat - 방식2: 스칼라버전, bias=True . gv(&#39;&#39;&#39; &quot;x&quot; -&gt; &quot;x*beta1_hat, bias=True&quot;[label=&quot;*beta1_hat&quot;] ; &quot;x*beta1_hat, bias=True&quot; -&gt; &quot;yhat&quot;[label=&quot;indentity&quot;] &#39;&#39;&#39;) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G x x x*beta1_hat, &#160;&#160;&#160;bias=True x*beta1_hat, &#160;&#160;&#160;bias=True x&#45;&gt;x*beta1_hat, &#160;&#160;&#160;bias=True *beta1_hat yhat yhat x*beta1_hat, &#160;&#160;&#160;bias=True&#45;&gt;yhat indentity - 방식3: 벡터버전, bias=False . gv(&#39;&#39;&#39; &quot;X=[1 x]&quot; -&gt; &quot;X@beta_hat, bias=False&quot;[label=&quot;@beta_hat&quot;] ; &quot;X@beta_hat, bias=False&quot; -&gt; &quot;yhat&quot;[label=&quot;indentity&quot;] &#39;&#39;&#39;) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G X=[1 x] X=[1 x] X@beta_hat, &#160;&#160;&#160;bias=False X@beta_hat, &#160;&#160;&#160;bias=False X=[1 x]&#45;&gt;X@beta_hat, &#160;&#160;&#160;bias=False @beta_hat yhat yhat X@beta_hat, &#160;&#160;&#160;bias=False&#45;&gt;yhat indentity &#54400;&#51060;1: &#48289;&#53552;&#48260;&#51204;, &#49324;&#50857;&#51088;&#51221;&#51032; &#49552;&#49892;&#54632;&#49688; . - 포인트 . # 포인트1: 네트워크 생성 net = tf.keras.Sequential() # 포인트2: 네트워크의 아키텍처 설계 net.add(tf.keras.layers.Dense(1,input_shape=(2,),use_bias=False)) # 포인트3: 네트워크 컴파일 = 아키텍처 + 손실함수 + 옵티마이저 net.compile(opt,loss=loss_fn2) # 포인트4: 미분 &amp; update net.fit(X,y,epochs=1000,verbose=0,batch_size=N) . tnp.random.seed(50000) N = 200 x = tnp.linspace(0,1,N) epsilon = tnp.random.randn(N)*0.5 y = 2.5+4*x + epsilon y_true = 2.5+4*x . X=tf.stack([tf.ones(N,dtype=&#39;float64&#39;),x],axis=1) y=y.reshape(N,1) X.shape,y.shape . (TensorShape([200, 2]), TensorShape([200, 1])) . - 네트워크 생성 . net = tf.keras.Sequential() . net.summary() . ValueError Traceback (most recent call last) Input In [16], in &lt;cell line: 1&gt;() -&gt; 1 net.summary() File ~ anaconda3 envs ds2022 lib site-packages keras engine training.py:2775, in Model.summary(self, line_length, positions, print_fn, expand_nested, show_trainable) 2753 &#34;&#34;&#34;Prints a string summary of the network. 2754 2755 Args: (...) 2772 ValueError: if `summary()` is called before the model is built. 2773 &#34;&#34;&#34; 2774 if not self.built: -&gt; 2775 raise ValueError( 2776 &#39;This model has not yet been built. &#39; 2777 &#39;Build the model first by calling `build()` or by calling &#39; 2778 &#39;the model on a batch of data.&#39;) 2779 layer_utils.print_summary( 2780 self, 2781 line_length=line_length, (...) 2784 expand_nested=expand_nested, 2785 show_trainable=show_trainable) ValueError: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data. . 현재 아무것도 없음 | 다음과 같이 layer를 만들어야 함 | . - 네트워크의 아키텍처 설계 . net.add(tf.keras.layers.Dense(units=1,input_shape=(2,),use_bias=False)) # 뼈대, 아키텍처 설계 = yhat을 만들 계획 . net.summary() . Model: &#34;sequential_2&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_1 (Dense) (None, 1) 2 dense_2 (Dense) (None, 1) 1 ================================================================= Total params: 3 Trainable params: 3 Non-trainable params: 0 _________________________________________________________________ . 무엇인가 나왔음! | layer가 추가된 것임 | . units=1: 출력의 차원 | input_shape: x의 dimension | use_bias: bias 사용여부 | . - 네트워크 컴파일(아키텍처, 손실함수, 옵티마이저) . def loss_fn2(y,yhat): # 손실함수 정의, 입력값이 항상 y, yhat이 와야함 return (y-yhat).T @ (y-yhat) / N . alpha=0.1 . opt=tf.optimizers.SGD(alpha) # 옵티마이저 선택 . net.compile(opt,loss=loss_fn2) # 컴파일 = 아키텍처 + 손실함수 + 옵티마이저 . 네트워크의 형태(아키텍처), 손실함수, 손실함수를 미분할 옵티마이저 전달 | . - 네트워크 적합: for문-미분-업데이트의 기능 . net.fit(X,y,epochs=10,batch_size=N) . Epoch 1/10 1/1 [==============================] - 0s 332ms/step - loss: 0.2631 Epoch 2/10 1/1 [==============================] - 0s 6ms/step - loss: 0.2631 Epoch 3/10 1/1 [==============================] - 0s 4ms/step - loss: 0.2631 Epoch 4/10 1/1 [==============================] - 0s 6ms/step - loss: 0.2631 Epoch 5/10 1/1 [==============================] - 0s 9ms/step - loss: 0.2631 Epoch 6/10 1/1 [==============================] - 0s 6ms/step - loss: 0.2631 Epoch 7/10 1/1 [==============================] - 0s 5ms/step - loss: 0.2631 Epoch 8/10 1/1 [==============================] - 0s 6ms/step - loss: 0.2631 Epoch 9/10 1/1 [==============================] - 0s 5ms/step - loss: 0.2631 Epoch 10/10 1/1 [==============================] - 0s 7ms/step - loss: 0.2631 . &lt;keras.callbacks.History at 0x1c4f4d66eb0&gt; . verbose=0사용 -&gt; 적합되는 과정 생략 | . net.fit(X,y,epochs=10,verbose=0,batch_size=N) # 미분 &amp; update의 반복, epochs= 반복 수, batch_size= 일단 N . &lt;keras.callbacks.History at 0x1c4f4ef3a60&gt; . 이에 대해 적합된 결과는 net.weights를 통해 알 수 있음 | . net.weights . [&lt;tf.Variable &#39;dense_1/kernel:0&#39; shape=(2, 1) dtype=float32, numpy= array([[2.4904754], [4.1002874]], dtype=float32)&gt;] . 정리: 1. net = tf.keras.Sequential() 2. net.add(tf.keras.layers.Dense(units=1,input_shape=(2,),use_bias=False)) 3-1. def loss_fn2(y,yhat): # 입력값이 항상 y, yhat이 와야함 return (y-yhat).T @ (y-yhat) / N 3-2. alpha=0.1 3-3. opt=tf.optimizers.SGD(alpha) 3-4. net.compile(opt,loss=loss_fn2) 4. net.fit(X,y,epochs=10,verbose=0,batch_size=N) 5. net.weights 1. 네트워크 생성 2. 하나의 layer(층) 추가(여러 layer도 추가 가능) 아키텍처 설계: 입력을 가지고 출력을 어떠한 방식으로 만들 것인지 컴퓨터에게 전달해주는 것. 여기서, x를 가지고 yhat을 어떠한 방식으로 만들 것인지 컴퓨터에게 전달해주는 것. 3-1. 손실함수 정의 3-2. 옵티마이저 정의 위해 학습율 설정 3-3. 옵티마이저 오브젝트 생성 3-4. 옵티마이저 오브젝트, 손실함수를 네트워크에 알려줌 4. 미분 &amp; 업데이트의 반복(for문) 5. 결과값 확인 .",
            "url": "https://ki5n2.github.io/charcoal/2022/04/06/DS.html",
            "relUrl": "/2022/04/06/DS.html",
            "date": " • Apr 6, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "DS 6. 최적화문제, tf.keras.optimizers를 이용한 최적화방법, 회귀분석",
            "content": ". Data Science . lenture: Data Science_5-1nd week of lectures. | lenture date: 2022-03-30 | lecturer: Guebin choi | study date: 2022-03-30 | author: Kione kim | . . import tensorflow as tf import numpy as np import matplotlib.pyplot as plt . import tensorflow.experimental.numpy as tnp . tnp.experimental_enable_numpy_behavior() . &#52572;&#51201;&#54868;&#47928;&#51228; . - $loss=( frac{1}{2} beta-1)^2$ . - 기존의 학습 $$ beta_{next} leftarrow beta_{old} - alpha left[ frac{ partial}{ partial beta} loss( beta) right]_{ beta= beta_{old}}$$ . beta = tf.Variable(-10.0) alpha=0.01/6 for k in range(100): with tf.GradientTape(persistent=True) as tape: loss = (beta/2-1)**2 beta.assign_sub(alpha*tape.gradient(loss,beta)) beta . - 이 방식의 단점: . 위의 식을 알고 있어야 함 | 사람들 생각: (위의 식을 알지 정확하게 알지 못하더라도) $β_{old}$ 에서의 미분값과 $β_{old}$(현재 위치)를 통해 $β_{new}$(좀 더 나은 $β$)가 나오는 정도만 알고 있으면, 이미 구현되어 있는 식(위의 식)에 값을 넣기만 하면 계산되는 프로세스를 만들 수 있지 않을까? | 그래서 만든 것: optimizer | . tf.keras.optimizers&#47484; &#51060;&#50857;&#54620; &#52572;&#51201;&#54868;&#48169;&#48277; . &#48169;&#48277;1: opt.apply_gradients()&#47484; &#51060;&#50857; . - optimizer 정의 : 학습율 함께 정의 . alpha=0.01/6 . opt=tf.keras.optimizers.SGD(learning_rate=alpha) . . opt.learning_rate . &lt;tf.Variable &#39;learning_rate:0&#39; shape=() dtype=float32, numpy=0.0016666667&gt; . opt.lr . &lt;tf.Variable &#39;learning_rate:0&#39; shape=() dtype=float32, numpy=0.0016666667&gt; . id(opt.learning_rate) . 2567521054336 . id(opt.lr) . 2567521054336 . opt.learning_rate와 opt.lr은 같은 것임, 둘 중 쓰고 싶은 것 쓰면 됨! | . . - optimizer에 들어갈 입력값 정리 . beta | beta에서의 미분값 | . beta= tf.Variable(-10.0) beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=-10.0&gt; . with tf.GradientTape(persistent=True) as mytape: loss=(beta/2 -1)**2 slope=mytape.gradient(loss,beta) # 기울기라는 변수로 저장 slope . &lt;tf.Tensor: shape=(), dtype=float32, numpy=-6.0&gt; . - .apply_gradients() . opt.apply_gradients([(slope, beta)]) # 튜플의 리스트화하여 입력 . &lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=int64, numpy=1&gt; . beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=-9.99&gt; . beta값이 바꼈음 | 이 값은 -10에서 0.01만큼 움직인 값임! -&gt; 베타를 한 번 업데이트한 값 | 즉, 위 과정은 iter1과 같음 | 여기서 주의점: opt.apply_gradients()의 입력으로 pair의 list를 전달해야한다는 것 | . - iter2 . with tf.GradientTape(persistent=True) as mytape: loss=(beta/2 -1)**2 slope=mytape.gradient(loss,beta) . opt.apply_gradients([(slope, beta)]) # 튜플의 리스트화하여 입력 . &lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=int64, numpy=2&gt; . beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=-9.980008&gt; . 한 번 더 업데이트 되었음 | . - iter3:for문을 통한 반복 . alpha=0.01/6 opt=tf.keras.optimizers.SGD(alpha) beta=tf.Variable(-10.0) . for epoc in range(10000): with tf.GradientTape() as mytape: loss=(beta/2 -1)**2 slope=mytape.gradient(loss,beta) opt.apply_gradients([(slope,beta)]) . beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=1.9971251&gt; . 그런데 이게 더 어려운 것 아닌가..? | 차라리 식을 아는 게 더 편한 것 같음 | . 하지만, 외워야 할 식이 하나만 있는 것이 아니다..! 여러가지 최적화 방법들이 존재.. 각각의 방법들이 식이 조금씩 다르다 | 따라서 옵티마이저를 쓰는 방법을 알고 있으면 식을 알지 못하더라도 계산할 수 있다 | 결국은 옵티마이저를 쓰는 게 편리하다! | . &#48169;&#48277;2: opt.minimize()&#47484; &#51060;&#50857; . opt.apply_gradients()는 loss식 &amp; beta(old)값 &amp; beta(old)에서의 기울기(slope)를 전달해주면 되는 반면 opt.minimize()는 loss식 &amp; loss식을 무엇으로 미분할지만 전달해주면 알아서 계산해준다. . - α, β, optimizer 선언 . alpha=0.01/6 opt=tf.keras.optimizers.SGD(alpha) beta=tf.Variable(-10.0) . opt.minimize? . Signature: opt.minimize(loss, var_list, grad_loss=None, name=None, tape=None) Docstring: Minimize `loss` by updating `var_list`. This method simply computes gradient using `tf.GradientTape` and calls `apply_gradients()`. If you want to process the gradient before applying then call `tf.GradientTape` and `apply_gradients()` explicitly instead of using this function. Args: loss: `Tensor` or callable. If a callable, `loss` should take no arguments and return the value to minimize. If a `Tensor`, the `tape` argument must be passed. var_list: list or tuple of `Variable` objects to update to minimize `loss`, or a callable returning the list or tuple of `Variable` objects. Use callable when the variable list would otherwise be incomplete before `minimize` since the variables are created at the first time `loss` is called. grad_loss: (Optional). A `Tensor` holding the gradient computed for `loss`. name: (Optional) str. Name for the returned operation. tape: (Optional) `tf.GradientTape`. If `loss` is provided as a `Tensor`, the tape that computed the `loss` must be provided. Returns: An `Operation` that updates the variables in `var_list`. The `iterations` will be automatically increased by 1. Raises: ValueError: If some of the variables are not `Variable` objects. File: c: users kko anaconda3 envs ds2022 lib site-packages keras optimizer_v2 optimizer_v2.py Type: method . loss를 함수의 형태로 전달해야 함! | . loss_fn= lambda: (beta/2-1)**2 . opt.minimize(loss_fn,beta) . &lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=int64, numpy=1&gt; . numpy=1은 1번 업데이트 했다는 의미 | . beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=-9.99&gt; . $β$값을 보니 $-10.0$에서 한 번 업데이트한 값인 $-9.99$이 나타났음 | 즉, 위 과정은 iter1과 같음 | . - iter2:for문을 통한 반복 . alpha=0.01/6 opt=tf.keras.optimizers.SGD(alpha) beta=tf.Variable(-10.0) loss_fn= lambda: (beta/2-1)**2 . for epoc in range(10000): opt.minimize(loss_fn,beta) . beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=1.9971251&gt; . 2에 근접한 값이 나왔음 | . loss_fn . &lt;function __main__.&lt;lambda&gt;()&gt; . loss_fn() . &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.0661923e-06&gt; . 위 값은 현재시점 β에 해당하는 loss값이다. | 다시 말해, loss_fn()을 실행하면, 현재시점에서의 $(beta/2-1)**2$ 값이 출력된다. | . &#44592;&#53440; . - tf.keras.optimizers.SGD와 tf.optimizers.SGD의 차이점 . _opt1=tf.keras.optimizers.SGD() _opt2=tf.optimizers.SGD() . type(_opt1), type(_opt2) . (keras.optimizer_v2.gradient_descent.SGD, keras.optimizer_v2.gradient_descent.SGD) . type이 같음! | . - tf.optimizers.SGD로 위의 과정 계산 . alpha=0.01/6 opt=tf.optimizers.SGD(alpha) beta=tf.Variable(-10.0) loss_fn= lambda: (beta/2-1)**2 . for epoc in range(10000): opt.minimize(loss_fn,beta) . beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=1.9971251&gt; . 똑같은 값이 나옴 -&gt; 같은 기능 | . - 다른 방법 . tf.optimizers? . Type: module String form: &lt;module &#39;keras.api._v2.keras.optimizers&#39; from &#39;C: Users kko anaconda3 envs ds2022 lib site-packages keras api _v2 keras optimizers __init__.py&#39;&gt; File: c: users kko anaconda3 envs ds2022 lib site-packages keras api _v2 keras optimizers __init__.py Docstring: Public API for tf.keras.optimizers namespace. . tf.keras.optimizers? . Type: module String form: &lt;module &#39;keras.api._v2.keras.optimizers&#39; from &#39;C: Users kko anaconda3 envs ds2022 lib site-packages keras api _v2 keras optimizers __init__.py&#39;&gt; File: c: users kko anaconda3 envs ds2022 lib site-packages keras api _v2 keras optimizers __init__.py Docstring: Public API for tf.keras.optimizers namespace. . 파일이 위치한 장소가 같음! | . 차이 없음! | . &#54924;&#44480;&#48516;&#49437; . - ${ bf y} approx 4 + 2.5 { bf x}$에서 $4$와 $2.5$를 모른다고 생각하고 $β_{0}, β_{1}$를 구하는 방법 . - 선언 . tnp.random.seed(50000) n= 500 # samplesize x= tnp.linspace(0,1,n) epsilon= tnp.random.randn(n)*0.5 . y=4+2.5*x+epsilon y_true=4+2.5*x . plt.plot(x,y,&#39;.&#39;) plt.plot(x,y_true,&#39;--r&#39;) . [&lt;matplotlib.lines.Line2D at 0x255cc386430&gt;] . 파란색 점들을 통해 빨강색 점을 추론 | . &#54400;&#51060;1 : $ beta$&#44396;&#54616;&#45716; &#44277;&#49885;&#51012; &#53685;&#54620; &#54400;&#51060; . tnp.random.seed(50000) n= 500 x= tnp.linspace(0,1,n) epsilon= tnp.random.randn(n)*0.5 y=4+2.5*x+epsilon . Sxx= sum((x-np.mean(x))**2) Sxy= sum((x-np.mean(x))*(y-np.mean(y))) . beta1_h = Sxy/Sxx beta0_h = np.mean(y) - beta1_h*np.mean(x) . beta0_h,beta1_h . (&lt;tf.Tensor: shape=(), dtype=float64, numpy=4.043123346730244&gt;, &lt;tf.Tensor: shape=(), dtype=float64, numpy=2.4858994002326082&gt;) . 거의 근접한 값이 나옴 | . &#54400;&#51060;2 : &#48289;&#53552; &amp; &#47588;&#53944;&#47533;&#49828;&#47484; &#51060;&#50857;&#54620; &#54400;&#51060; . tnp.random.seed(50000) n= 500 x= tnp.linspace(0,1,n) epsilon= tnp.random.randn(n)*0.5 y=4+2.5*x+epsilon . - X선언 . x[:20] . &lt;tf.Tensor: shape=(20,), dtype=float64, numpy= array([0. , 0.00200401, 0.00400802, 0.00601202, 0.00801603, 0.01002004, 0.01202405, 0.01402806, 0.01603206, 0.01803607, 0.02004008, 0.02204409, 0.0240481 , 0.0260521 , 0.02805611, 0.03006012, 0.03206413, 0.03406814, 0.03607214, 0.03807615])&gt; . tf.ones(n)[:20] . &lt;tf.Tensor: shape=(20,), dtype=float32, numpy= array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)&gt; . X=tf.stack([tf.ones(n,dtype=&#39;float64&#39;),x],axis=1) X[:20] . &lt;tf.Tensor: shape=(20, 2), dtype=float64, numpy= array([[1. , 0. ], [1. , 0.00200401], [1. , 0.00400802], [1. , 0.00601202], [1. , 0.00801603], [1. , 0.01002004], [1. , 0.01202405], [1. , 0.01402806], [1. , 0.01603206], [1. , 0.01803607], [1. , 0.02004008], [1. , 0.02204409], [1. , 0.0240481 ], [1. , 0.0260521 ], [1. , 0.02805611], [1. , 0.03006012], [1. , 0.03206413], [1. , 0.03406814], [1. , 0.03607214], [1. , 0.03807615]])&gt; . y[:20] . &lt;tf.Tensor: shape=(20,), dtype=float64, numpy= array([3.35275314, 4.22611941, 4.87242315, 5.31953133, 3.8417442 , 2.7444039 , 3.75847533, 3.67882462, 3.84180216, 3.54850093, 4.77493479, 4.64718767, 4.2011182 , 4.31115921, 4.81145538, 2.94308534, 4.03927822, 4.3866718 , 3.96485239, 3.96641934])&gt; . y=y.reshape(n,1) . y[:20] . &lt;tf.Tensor: shape=(20, 1), dtype=float64, numpy= array([[3.35275314], [4.22611941], [4.87242315], [5.31953133], [3.8417442 ], [2.7444039 ], [3.75847533], [3.67882462], [3.84180216], [3.54850093], [4.77493479], [4.64718767], [4.2011182 ], [4.31115921], [4.81145538], [2.94308534], [4.03927822], [4.3866718 ], [3.96485239], [3.96641934]])&gt; . X.shape,Y.shape . (TensorShape([500, 2]), TensorShape([500, 1])) . tf.linalg.inv(X.T@X) @ X.T @ y . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[4.04312335], [2.4858994 ]])&gt; . &#54400;&#51060;3: (&#53584;&#49436;&#54540;&#47196;&#50864;&#47484; &#50416;&#51648; &#50506;&#44256;) &#44221;&#49324;&#54616;&#44053;&#48277;&#51012; &#51060;&#50857;&#54620; &#54400;&#51060; . : 도함수를 알고 있기 때문 . tnp.random.seed(50000) n= 500 x= tnp.linspace(0,1,n) epsilon= tnp.random.randn(n)*0.5 y=4+2.5*x+epsilon . X=tf.stack([tf.ones(n,dtype=&#39;float64&#39;),x],axis=1) X[:20] . &lt;tf.Tensor: shape=(20, 2), dtype=float64, numpy= array([[1. , 0. ], [1. , 0.00200401], [1. , 0.00400802], [1. , 0.00601202], [1. , 0.00801603], [1. , 0.01002004], [1. , 0.01202405], [1. , 0.01402806], [1. , 0.01603206], [1. , 0.01803607], [1. , 0.02004008], [1. , 0.02204409], [1. , 0.0240481 ], [1. , 0.0260521 ], [1. , 0.02805611], [1. , 0.03006012], [1. , 0.03206413], [1. , 0.03406814], [1. , 0.03607214], [1. , 0.03807615]])&gt; . y=y.reshape(n,1) y[:20] . &lt;tf.Tensor: shape=(20, 1), dtype=float64, numpy= array([[3.35275314], [4.22611941], [4.87242315], [5.31953133], [3.8417442 ], [2.7444039 ], [3.75847533], [3.67882462], [3.84180216], [3.54850093], [4.77493479], [4.64718767], [4.2011182 ], [4.31115921], [4.81145538], [2.94308534], [4.03927822], [4.3866718 ], [3.96485239], [3.96641934]])&gt; . X.shape, y.shape . (TensorShape([500, 2]), TensorShape([500, 1])) . - 임의의 beta 선언 . beta= tnp.array([-5.0,-2.0]).reshape(2,1) beta . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[-5.], [-2.]])&gt; . - 미분계수를 통한 slope선언 (loss&#39; = slope) . cf. $loss = (y-yhat)&#39;(y-yhat) =&gt; (y-x*beta)&#39;(y-x*beta) =&gt; loss&#39;= -2x&#39;y +2x&#39;xb$ . slope=-2*X.T @ y + 2*X.T @ X @beta slope . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[-11286.07304685], [ -6018.35976984]])&gt; . $$ beta_{next} leftarrow beta_{old} - alpha left[ frac{ partial}{ partial beta} loss( beta) right]_{ beta= beta_{old}}$$ : $step = alpha * loss&#39;$, $loss&#39; = slope$ -&gt; $step$= $alpha * slope$ . step = -alpha * slope step . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[18.81012174], [10.03059962]])&gt; . - 반복 . for epoc in range(1000): slope= -2*X.T @ y + 2*X.T @ X @ beta step = -slope * alpha beta = beta + step . beta . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[4.04312335], [2.4858994 ]])&gt; . &#52628;&#44032;&#54617;&#49845; . 풀이3을 완성하라. 즉 경사하강법을 이용하여 적절한 beta를 추정하라. . iteration 횟수는 1000번으로 설정 | 학습률은 0.001로 설정 | beta의 초기값은 beta= tnp.array([-5.0,10.0]).reshape(2,1) | . tnp.random.seed(50000) n= 500 x= tnp.linspace(0,1,n) epsilon= tnp.random.randn(n)*0.5 y=4+2.5*x+epsilon . X=tf.stack([tf.ones(n,dtype=&#39;float64&#39;),x],axis=1) X[:20] . &lt;tf.Tensor: shape=(20, 2), dtype=float64, numpy= array([[1. , 0. ], [1. , 0.00200401], [1. , 0.00400802], [1. , 0.00601202], [1. , 0.00801603], [1. , 0.01002004], [1. , 0.01202405], [1. , 0.01402806], [1. , 0.01603206], [1. , 0.01803607], [1. , 0.02004008], [1. , 0.02204409], [1. , 0.0240481 ], [1. , 0.0260521 ], [1. , 0.02805611], [1. , 0.03006012], [1. , 0.03206413], [1. , 0.03406814], [1. , 0.03607214], [1. , 0.03807615]])&gt; . y=y.reshape(n,1) y[:20] . &lt;tf.Tensor: shape=(20, 1), dtype=float64, numpy= array([[3.35275314], [4.22611941], [4.87242315], [5.31953133], [3.8417442 ], [2.7444039 ], [3.75847533], [3.67882462], [3.84180216], [3.54850093], [4.77493479], [4.64718767], [4.2011182 ], [4.31115921], [4.81145538], [2.94308534], [4.03927822], [4.3866718 ], [3.96485239], [3.96641934]])&gt; . X.shape,y.shape . (TensorShape([500, 2]), TensorShape([500, 1])) . beta= tnp.array([-5.0,10.0]).reshape(2,1) beta . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[-5.], [10.]])&gt; . slope=-2*X.T @ y + 2*X.T @ X @ beta slope . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[0.], [0.]])&gt; . alpha=0.001 . step = -slope * alpha step . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[-0.], [-0.]])&gt; . for epoc in range(1000): slope= -2*X.T @ y + 2*X.T @ X @ beta step = -slope * alpha beta = beta + step . beta . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[4.04312335], [2.4858994 ]])&gt; .",
            "url": "https://ki5n2.github.io/charcoal/2022/03/30/DS.html",
            "relUrl": "/2022/03/30/DS.html",
            "date": " • Mar 30, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "DS 5. 경사하강법, Grident Descent",
            "content": ". Data Science . lenture: Data Science_4-2nd week of lectures. | lenture date: 2022-03-28 | lecturer: Guebin choi | study date: 2022-03-29, 2022-03-30 | author: Kione kim | . . import tensorflow as tf import numpy as np import matplotlib.pyplot as plt . import tensorflow.experimental.numpy as tnp . tnp.experimental_enable_numpy_behavior() . &#44221;&#49324;&#54616;&#44053;&#48277; - &#52572;&#51201;&#54868;&#47928;&#51228; . - $loss= ( frac{1}{2} beta -1)^2$를 최소로 하는 $ beta$를 컴퓨터를 통해 구하는 문제를 생각해보자. (답은 당연히 $ beta=2$) . &#48169;&#48277; 2: Grid Descent . &#50508;&#44256;&#47532;&#51608; . (1) 임의의 초기값을 선정하고 loss를 계산한다. . $ beta=10 to loss(10)=(10/2-1)^2=16.0$ | . (10/2-1)**2 . 16.0 . (2) 임의의 초기값에서 좌우로 약간씩 이동해보고 loss를 계산한다. . 왼쪽으로 이동: $ beta=10.01, quad loss(10.01)=16.040025$ | 오른쪽으로 이동: $ beta=9.99, quad loss(9.99)=15.960025$ | . (10.01 /2 -1)**2 . 16.040025 . (9.99 /2 -1)**2 . 15.960025000000002 . (3) (2)의 결과를 보고 어느쪽으로 이동하는것이 유리한지 따져보고 유리한 방향으로 이동한다. . 유리한 방향: 절대값이 작은 쪽 . $ beta=9.99$ 로 이동 | . (4) (2)-(3) 의 과정을 반복한다. 왼쪽/오른쪽 모두 가봐도 유리한 지점이 없다면 알고리즘을 멈춘다. . &#50508;&#44256;&#47532;&#51608; &#44048;&#49345; . - 알고리즘이 멈추는 지점은 $ beta=2$이다. $ beta=2$일 때 loss가 0이 되므로 왼쪽으로 가도, 오른쪽으로 가도 현재 loss보다 크기 때문이다. . - 이 알고리즘은 grid search의 단점을 극복함! . $loss=(x beta-y)^2$의 꼴에서 $[-10,10]$ 이외의 지점에 해가 존재하여도 적절하게 해를 찾을 것. | 또한 비효율적으로 $ beta=2$ 이후에도 탐색을 반복하지 않음. | . &#50508;&#44256;&#47532;&#51608;&#54644;&#49437; . (1)의 의미: 임의의 초기값에서의 loss 계산(미분) (2)의 의미: 미분을 하라는 뜻 (3)의 의미: update (4)의 의미: 반복 . &#48120;&#48516;&#44228;&#49688;&#51032; &#51032;&#48120;&amp;&#49688;&#49885;&#54868; . - 미분계수의 의미 . 미분계수가 양수이다 -&gt; 왼쪽으로 이동해야 = 마이너스 0.01 | 미분계수가 음수이다 -&gt; 오른쪽으로 이동 = 플러스 0.01 | . - 수식화 . $$ beta_{next} = begin{cases} beta_{old} - 0.01 &amp; loss&#39;( beta_{old})&gt;0 beta_{old} + 0.01 &amp; loss&#39;( beta_{old})&lt;0 end{cases}$$ . 언제나 0.01씩 이동하는 것이 맞을까? . | loss 값의 절대값이 크면(찾아야 할 베타값으로 부터 거리가 먼 값이라면) 0.01씩 이동해서 언제 다 이동하지? . | 절대값이 크면(찾아야 하는 베타값으로부터 거리가 먼 경우) 이동을 많이 하고 절대값이 작으면(찾아야 하는 베타값으로부터 거리가 가까운 경우) 이동을 적게 하는 알고리즘으로 개선하고싶음! . | . beta = np.linspace(-10,5) plt.plot(beta,(beta/2-1)**2) . [&lt;matplotlib.lines.Line2D at 0x16d99c0e370&gt;] . - 위 그림에서 $ beta=-10$ 일 경우의 접선의 기울기는 $-6$이고 $ beta=-4$ 일때 접선의 기울기는 $-3$이다. . $ because loss = (0.5 beta-1)^2 to loss&#39; = 0.5 beta-1$ . $ beta=-10$에서 0.01만큼 이동했다면 $ beta=-4$에서 0.005만큼 이동해야 한다. | . - 개선한 알고리즘의 수식화 . $$ beta_{next} leftarrow beta_{old} - alpha left[ frac{ partial}{ partial beta} loss( beta) right]_{ beta= beta_{old}}$$ . 전의 수식이랑 좀 달라보이지만 $ beta_{old}$를 이동시켜 $ beta_{next}$를 만든다는 개념은 동일! | $ alpha&gt;0$ | $ alpha$의 의미: 한 번 업데이트할때 움직이는 보폭(걸음걸이), 절대값이 크면 큰 보폭으로 걷고 절대값이 작으면 작은 보폭으로 걷는다! | $ alpha= frac{0.01}{6}$ 로 만약 설정하면 $ beta=-10$일때 오른쪽으로 $0.01$움직임 | . 개선한 알고리즘을 이용한 풀이 . - with문 . beta= tf.Variable(-10.0) . with tf.GradientTape(persistent=True) as mytape: loss= (beta/2-1)**2 . mytape.gradient(loss,beta) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=-6.0&gt; . $beta=-10$일 때 기울기(미분계수)가 $-6$이 나옴 | . beta= tf.Variable(-4.0) . with tf.GradientTape(persistent=True) as mytape: loss= (beta/2-1)**2 . mytape.gradient(loss,beta) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=-3.0&gt; . $beta=-4$일 떄 기울기(미분계수)가 $-3$이 나옴 | . iter1: $beta=-10$ 출발해서 $0.01$ 이동! . beta= tf.Variable(-10.0) . with tf.GradientTape(persistent=True) as mytape: loss= (beta/2-1)**2 . mytape.gradient(loss,beta) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=-6.0&gt; . alpha=0.01/6 . - -$α$이기 떄문에 beta.assign_sub를 이용! . beta.assign_sub(alpha*mytape.gradient(loss,beta)) . &lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=float32, numpy=-9.99&gt; . 10에서 이동하기 시작하여 -9.99가 되었음 | . iter2: $beta=-9.99$ 출발해서 다시 $0.01$ 이동! . beta= tf.Variable(-9.99) . with tf.GradientTape(persistent=True) as mytape: loss= (beta/2-1)**2 . beta.assign_sub(alpha*mytape.gradient(loss,beta)) . &lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=float32, numpy=-9.980008&gt; . $-9.99$에서 $0.01$이동하여 $-9.98$이 되었음 | . iter3: 반복! . - for문 . beta= tf.Variable(-10.0) for k in range(10000): with tf.GradientTape() as mytape: loss=(beta/2 -1)**2 beta.assign_sub(alpha*mytape.gradient(loss,beta)) . beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=1.9971251&gt; . $10000$번 반복해보았더니 $beta$가 이론적인 값인 $2$에 가까운 값($1.997$)이 나왔음! | . - $10000$번 반복이 아닌 $100$번 정도 반복해도 이론적인 값인 $2$에 가깝게 나올까? . beta= tf.Variable(-10.0) for k in range(100): with tf.GradientTape() as mytape: loss=(beta/2 -1)**2 beta.assign_sub(alpha*mytape.gradient(loss,beta)) . beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=-9.040152&gt; . $2$와 거리가 먼 $-9$ 값이 나옴 | . - 그렇다면 $1000$번은 어떻까? . beta= tf.Variable(-10.0) for k in range(1000): with tf.GradientTape() as mytape: loss=(beta/2 -1)**2 beta.assign_sub(alpha*mytape.gradient(loss,beta)) . beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=-3.2133684&gt; . 아까보단 가까운 값($-3.2133$)이 나오긴 했음! . | 그런데 $1000$번을 반복해도 나오지 않은 건 좀...! . | 이는 설정한 alpha 값이 작기 때문! 즉 보폭이 작으니 많이 걸어야 하는 꼴..! . | . cf tf.Variable의 진가! . 왜 써야하는지 의문이 들었던 tf.Variable()가 점점 이해되기 시작함 | 안 그래도 제외된 기능이 많은데 assign_sub, assign_add와 같은 기능이 있는 이유 -&gt; 이것이 tf.Variable()의 목적이기 때문!! | tf.Variable()에 다른 기능들이 없는 이유는 tf.Variable()의 목적을 이루는데 필요하지 않은 기능들이기 때문! | tf.Gradient(persistent=False)가 default인 이유: 미분계산은 한 번하고 버리기 때문 ! | . &#54617;&#49845;&#47456; . - 목표: 아래의 학습과정을 시각화해보자. . beta = tf.Variable(-10.0) alpha=0.01/6 for k in range(100): with tf.GradientTape(persistent=True) as tape: loss = (beta/2-1)**2 beta.assign_sub(alpha*tape.gradient(loss,beta)) beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=-9.040152&gt; . &#49884;&#44033;&#54868; &#50696;&#48708;&#54617;&#49845; . - 설정 . from matplotlib import animation . plt.rcParams[&quot;animation.html&quot;]=&quot;jshtml&quot; . - 도화지(fig) &amp; 네모틀(axes) . fig = plt.figure() # plt.figure()는 그림 물체를 만드는 함수이고 그림 물체의 이름을 fig로 지정 . &lt;Figure size 432x288 with 0 Axes&gt; . type(fig) . matplotlib.figure.Figure . Figure라는 타입을 갖는 물체임! | . ax = fig.add_subplot() # fig.add_subplot는 네모틀(물체)을 만드는 함수이고 이를 ax(es)로 지정 . fig . - 도화지와 네모틀는 포함관계에 있음. . fig.axes . [&lt;AxesSubplot:&gt;] . fig.axes[0] # 원소가 추출됨 . &lt;AxesSubplot:&gt; . id(fig.axes[0]) . 1570293991936 . id(ax) . 1570293991936 . fig . 따라서 도화지를 출력하면 네모틀도 자동으로 출력됨 | . - 네모틀(ax)의 특수기능(=메소드)중에는 plot이 있음. 이것은 또 어떤 오브젝트를 생성함 . point = ax.plot([1,2,3],[3,4,5],&#39;or&#39;) point . [&lt;matplotlib.lines.Line2D at 0x2b175243f70&gt;] . point[0] . &lt;matplotlib.lines.Line2D at 0x16d9cd46280&gt; . point=point[0] point . &lt;matplotlib.lines.Line2D at 0x2b175243f70&gt; . 이는 다음 코드와 같다(튜플언패킹) | . point, = ax.plot([1,2,3],[3,4,5],&#39;or&#39;) point . &lt;matplotlib.lines.Line2D at 0x2b175263790&gt; . . (1,) . (1,) . 1+2 . 3 . (1,) + (2,) . (1, 2) . a,b = [1,2] . a . 1 . b . 2 . a, = [1] . a . 1 . . fig . point는 오브젝트 -&gt; x,y data를 변경해보자. | . point.get_xdata() . array([1, 2, 3]) . x data가 출력됨 | . point.get_ydata() . array([3, 4, 5]) . y data가 출력됨 | . point.set_ydata([4,4,4]) . y data가 변경됨! | . point.get_ydata() . [4, 4, 4] . fig . 왜 기존 데이터가 사라지지 않았지..? | . - 애니매이션 . def animate(i): if i%2 == 0: point.set_ydata([3,4,5]) else: point.set_ydata([4,4,4]) . ani=animation.FuncAnimation(fig,animate,frames=30) ani . &lt;/input&gt; Once Loop Reflect 시각화 예비학습 끝 . . &#54617;&#49845;&#44284;&#51221; &#44396;&#54788;! . - 한 번에 구현하기 힘드니 간단한 그림을 먼저 구현해보자! . - 곡선위의 세 점의 변화를 시각화해보자 . beta_lst=[-10.0,-9.0,-8.0] loss_lst=[(-10.0/2 -1)**2, (-9.0/2 -1)**2, (-8.0/2 -1)**2] . fig=plt.figure() ax=fig.add_subplot() . - 곡선그리기 . _beta= np.linspace(-15,19) ax.plot(_beta,(_beta/2 -1)**2) . [&lt;matplotlib.lines.Line2D at 0x16d9ce29490&gt;] . fig . - 점을 찍기 . ax.plot(beta_lst[0],loss_lst[0],&#39;ro&#39;) fig . - 어떻게 애니메이션이 동작할지 정의하기 . point, = ax.plot(beta_lst[0], loss_lst[0], &#39;ro&#39;) fig . def animate(i): point.set_xdata(beta_lst[:(i+1)]) point.set_ydata(loss_lst[:(i+1)]) . ani=animation.FuncAnimation(fig,animate,frames=3) ani . &lt;/input&gt; Once Loop Reflect - 이제 이 과정을 학습해보자 beta = tf.Variable(-10.0) alpha=0.01/6 for k in range(100): with tf.GradientTape(persistent=True) as tape: loss = (beta/2-1)**2 beta.assign_sub(alpha*tape.gradient(loss,beta)) beta . - 위 과정에 대한 애니메이션: 학습과정기록 . - 비어있는 리스트 . beta_lst=[] loss_lst=[] . - beta &amp; alpha 선언 . beta = tf.Variable(-10.0) alpha = 0.01/6 . - beta 넘파이화 . beta.numpy() . -10.0 . - for문에 쓰일 beta, loss 변경값 . beta_lst.append(beta.numpy()) loss_lst.append((beta.numpy()/2 -1)**2) . beta_lst . [-10.0] . loss_lst . [36.0] . - for문: 100번 반복 . for k in range(100): with tf.GradientTape() as mytape: loss=(beta/2 -1)**2 # 로스 식 beta.assign_sub(alpha*mytape.gradient(loss,beta)) # 베타값 변경 beta_lst.append(beta.numpy()) # 변경된 베타값 넘파이화한 후 베타 리스트에 저장 loss_lst.append((beta.numpy()/2 -1)**2) # 변경된 베타값에 대한 로스값 넘파이화 후 로스 리스트에 저장 . beta_lst[:20] . [-10.0, -9.99, -9.980008, -9.970025, -9.96005, -9.950083, -9.9401245, -9.930175, -9.920233, -9.910299, -9.900374, -9.890457, -9.8805485, -9.870648, -9.860756, -9.850872, -9.840997, -9.831129, -9.82127, -9.811419] . loss_lst[:20] . [36.0, 35.94002362785341, 35.88014867059451, 35.82037499958483, 35.76069678330009, 35.701119605823806, 35.64164333883673, 35.58226785413012, 35.5229873395956, 35.463807360728424, 35.40472778963908, 35.34574282873655, 35.28685802961354, 35.22807326469979, 35.16938275088614, 35.11079202589826, 35.052300962485106, 34.99390379198394, 34.935606038288824, 34.87740194234448] . 비어있던 베타리스트, 로스리스트에 값이 저장되어 있음 | . - 애니메이션 . fig= plt.figure() # fig 선언 ax= fig.add_subplot() . NameError Traceback (most recent call last) Input In [1], in &lt;cell line: 1&gt;() -&gt; 1 fig= plt.figure() # fig 선언 2 ax= fig.add_subplot() NameError: name &#39;plt&#39; is not defined . _beta= np.linspace(-15,19) # 애니메이션에 쓰일 곡선 그리기 ax.plot(_beta,(_beta/2 -1)**2) . [&lt;matplotlib.lines.Line2D at 0x16d9fda7a30&gt;] . point, = ax.plot(beta_lst[0], loss_lst[0], &#39;ro&#39;) # fig에 애니메이션에서 움직일 점 찍기 fig . ani=animation.FuncAnimation(fig,animate,frames=100) ani . &lt;/input&gt; Once Loop Reflect 넘 느리다..! 학습율을 높여보자! | . - $α$가 $0.1$ 이면 어떨까? . beta_lst=[] loss_lst=[] . beta = tf.Variable(-10.0) alpha = 0.1 . beta_lst.append(beta.numpy()) loss_lst.append((beta.numpy()/2 -1)**2) . for k in range(100): with tf.GradientTape() as mytape: loss=(beta/2 -1)**2 # 로스 식 beta.assign_sub(alpha*mytape.gradient(loss,beta)) # 베타값 변경 beta_lst.append(beta.numpy()) # 변경된 베타값 넘파이화한 후 베타 리스트에 저장 loss_lst.append((beta.numpy()/2 -1)**2) # 변경된 베타값에 대한 로스값 넘파이화 후 로스 리스트에 저장 . fig= plt.figure() # fig 선언 ax= fig.add_subplot() . _beta= np.linspace(-15,19) # 애니메이션에 쓰일 곡선 그리기 ax.plot(_beta,(_beta/2 -1)**2) . [&lt;matplotlib.lines.Line2D at 0x16d9fe17580&gt;] . point, = ax.plot(beta_lst[0], loss_lst[0], &#39;ro&#39;) # fig에 애니메이션에서 움직일 점 찍기 fig . ani=animation.FuncAnimation(fig,animate,frames=100) ani . &lt;/input&gt; Once Loop Reflect 아까보다 훨 나음! | 더 크게 하면 어떻게 될까? | . - 이전보다 α를 훨씬키워 3.0 정도가 되면 어떻게 될까? . beta_lst=[] loss_lst=[] . beta = tf.Variable(-10.0) alpha = 3.9 . beta_lst.append(beta.numpy()) loss_lst.append((beta.numpy()/2 -1)**2) . for k in range(100): with tf.GradientTape() as mytape: loss=(beta/2 -1)**2 # 로스 식 beta.assign_sub(alpha*mytape.gradient(loss,beta)) # 베타값 변경 beta_lst.append(beta.numpy()) # 변경된 베타값 넘파이화한 후 베타 리스트에 저장 loss_lst.append((beta.numpy()/2 -1)**2) # 변경된 베타값에 대한 로스값 넘파이화 후 로스 리스트에 저장 . fig= plt.figure() # fig 선언 ax= fig.add_subplot() . _beta= np.linspace(-15,19) # 애니메이션에 쓰일 곡선 그리기 ax.plot(_beta,(_beta/2 -1)**2) . [&lt;matplotlib.lines.Line2D at 0x16da0119fa0&gt;] . point, = ax.plot(beta_lst[0], loss_lst[0], &#39;ro&#39;) # fig에 애니메이션에서 움직일 점 찍기 fig . ani=animation.FuncAnimation(fig,animate,frames=100) ani . &lt;/input&gt; Once Loop Reflect α가 너무 커 한 번에 반대 방향으로 이동했음 | 이 학습율 같은 경우는 비효율적이긴 하지만 최적의 베타값을 찾았으나, 이는 운이 좋은 경우임 ! | 다음 더 큰 α로 학습해보자! | . - α가 4.05 때 학습 . beta_lst=[] loss_lst=[] . beta = tf.Variable(-10.0) alpha = 4.05 . beta_lst.append(beta.numpy()) loss_lst.append((beta.numpy()/2 -1)**2) . for k in range(100): with tf.GradientTape() as mytape: loss=(beta/2 -1)**2 # 로스 식 beta.assign_sub(alpha*mytape.gradient(loss,beta)) # 베타값 변경 beta_lst.append(beta.numpy()) # 변경된 베타값 넘파이화한 후 베타 리스트에 저장 loss_lst.append((beta.numpy()/2 -1)**2) # 변경된 베타값에 대한 로스값 넘파이화 후 로스 리스트에 저장 . fig= plt.figure() # fig 선언 ax= fig.add_subplot() . _beta= np.linspace(-15,19) # 애니메이션에 쓰일 곡선 그리기 ax.plot(_beta,(_beta/2 -1)**2) . [&lt;matplotlib.lines.Line2D at 0x16da193ed90&gt;] . point, = ax.plot(beta_lst[0], loss_lst[0], &#39;ro&#39;) # fig에 애니메이션에서 움직일 점 찍기 fig . ani=animation.FuncAnimation(fig,animate,frames=100) ani . &lt;/input&gt; Once Loop Reflect α가 너무 커 기울기의 절대값이 더 커지는 현상이 발생함! | 학습율이 너무 크면 문제가 생긴다 | . &#52628;&#44032;&#54617;&#49845; . 경사하강법을 이용하여 $y=(x-1)^2$의 최소값을 구하고 이를 애니메이션으로 시각화하라. (100번정도에 수렴하도록 적당한 학습률을 설정할것) . beta_lst=[] loss_lst=[] . beta = tf.Variable(5.0) # 반드시 소수형태로 표현! alpha = 0.025 . beta_lst.append(beta.numpy()) loss_lst.append((beta.numpy()-1)**2) . for k in range(100): with tf.GradientTape() as mytape: loss=(beta-1)**2 # 로스 식 beta.assign_sub(alpha*mytape.gradient(loss,beta)) # 베타값 변경 beta_lst.append(beta.numpy()) # 변경된 베타값 넘파이화한 후 베타 리스트에 저장 loss_lst.append((beta.numpy()-1)**2) # 변경된 베타값에 대한 로스값 넘파이화 후 로스 리스트에 저장 . fig= plt.figure() # fig 선언 ax= fig.add_subplot() . _beta= np.linspace(-4,6) # 애니메이션에 쓰일 곡선 그리기 ax.plot(_beta,(_beta-1)**2) . [&lt;matplotlib.lines.Line2D at 0x16da4f9c340&gt;] . point, = ax.plot(beta_lst[0], loss_lst[0], &#39;ro&#39;) # fig에 애니메이션에서 움직일 점 찍기 fig . ani=animation.FuncAnimation(fig,animate,frames=100) ani . &lt;/input&gt; Once Loop Reflect $β$가 $5$에서 출발하여 $α=0.025$로 하여 $β=1$에 수렴 | $x=1$이다. | . beta_lst[100] . 1.0236822 .",
            "url": "https://ki5n2.github.io/charcoal/2022/03/29/DS.html",
            "relUrl": "/2022/03/29/DS.html",
            "date": " • Mar 29, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "DS 4. 미분, 경사하강법, grid search",
            "content": ". Data Science . lenture: Data Science_4-1nd week of lectures. | lenture date: 2022-03-23 | lecturer: Guebin choi | study date: 2022-03-23 | author: Kione kim | . . import tensorflow as tf import numpy as np import matplotlib.pyplot as plt . import tensorflow.experimental.numpy as tnp # tnp를 사용하면 넘파이에 익숙한 문법을 모두 쓸 수 있음 tnp.experimental_enable_numpy_behavior() # 기존에 생성된 tf.constant 자료형은 넘파이와 유사하게 동작한다. . &#48120;&#48516; . tf.GradientTape() . &#52852;&#54168;&#50696;&#51228; . - $x,y$ 선언 . x=tnp.array([20.1,22.2,22.7,23.3,24.4,25.1,26.2,27.3,28.4,30.4]) x . &lt;tf.Tensor: shape=(10,), dtype=float64, numpy=array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4])&gt; . tf.random.set_seed(50000) y=10.2+ 2.2*x+ tnp.random.randn(10) y . &lt;tf.Tensor: shape=(10,), dtype=float64, numpy= array([53.12550628, 59.48221878, 61.86480622, 64.06900254, 63.52340823, 62.85870759, 67.29683042, 69.54750897, 72.283444 , 76.08682149])&gt; . - 임의의 $β_0, β_1$ 값 설정 . beta0=tf.Variable([9.0]) beta1=tf.Variable([2.0]) . - with문 . with tf.GradientTape(persistent=True) as mytape: loss=sum((y-beta0-beta1*x)**2) mytape.gradient(loss,beta0), mytape.gradient(loss,beta1) . (&lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([-119.87651], dtype=float32)&gt;, &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([-3008.6094], dtype=float32)&gt;) . loss(잔차제곱합)를 β_0, β_1 각각에 대해 미분하여 대입한 값을 보았더니 0과는 거리가 멀다. 더 나은 직선이 많을 것 같다. . | 다른 베타값에 대한 미분값을 살펴보고 싶은데 위의 코드처럼 각각을 적용하는 것은 확장성이 떨어진다. . | 매트릭스 미분을 활용해보자! . | . - 매트릭스를 활용한 계산 . . &#48373;&#49845; . - 모형의 매트릭스화 . - 우리의 모형 . $y_i = beta_0 + beta_1 x_i + epsilon_i, quad i=1,2, dots,10$ . 이를 풀어서 쓰면 . $ begin{cases} y_1 = beta_0 + beta_1 x_1 + epsilon_1 y_2 = beta_0 + beta_1 x_2 + epsilon_2 dots y_{10} = beta_0 + beta_1 x_{10} + epsilon_{10} end{cases}$ . 아래와 같다. . $ begin{bmatrix} y_1 y_2 dots y_{10} end{bmatrix} = begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 dots &amp; dots 1 &amp; x_{10} end{bmatrix} begin{bmatrix} beta_0 beta_1 end{bmatrix} + begin{bmatrix} epsilon_1 epsilon_2 dots epsilon_{10} end{bmatrix} $ . 벡터와 매트릭스 형태로 표현하면 . ${ bf y} = { bf X} { boldsymbol beta} + boldsymbol{ epsilon}$ . - 손실함수의 매트릭스화 . $loss= sum_{i=1}^{n}(y_i- beta_0- beta_1x_i)^2$ . 이를 벡터로 표현하면, . $loss=({ bf y}-{ bf X}{ boldsymbol beta})^ top({ bf y}-{ bf X}{ boldsymbol beta})={ bf y}^ top { bf y} - { bf y}^ top { bf X}{ boldsymbol beta} - { boldsymbol beta}^ top { bf X}^ top { bf y} + { boldsymbol beta}^ top { bf X}^ top { bf X} { boldsymbol beta}$ . - 미분하는 과정의 매트릭스화 . loss를 최소화하는 ${ boldsymbol beta}$를 구해야하므로 loss를 ${ boldsymbol beta}$로 미분한식을 0이라고 놓고 풀면 된다. . $ frac{ partial}{ partial boldsymbol{ beta}} loss = frac{ partial}{ partial boldsymbol{ beta}} { bf y}^ top { bf y} - frac{ partial}{ partial boldsymbol{ beta}} { bf y}^ top { bf X}{ boldsymbol beta} - frac{ partial}{ partial boldsymbol{ beta}} { boldsymbol beta}^ top { bf X}^ top { bf y} + frac{ partial}{ partial boldsymbol{ beta}} { boldsymbol beta}^ top { bf X}^ top { bf X} { boldsymbol beta}$ . $= 0 - { bf X}^ top { bf y}- { bf X}^ top { bf y} + 2{ bf X}^ top { bf X}{ boldsymbol beta} $ . 따라서 $ frac{ partial}{ partial boldsymbol{ beta}}loss=0$을 풀면 아래와 같다. . $ boldsymbol{ hat beta}= ({ bf X}^ top { bf X})^{-1}{ bf X}^ top { bf y} $ . . - 매트릭스로 $x,y$ 선언 . [1]*10 + [2]*10 . [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] . tnp.array([1]*10 + [2]*10).reshape(2,10).T . &lt;tf.Tensor: shape=(10, 2), dtype=int32, numpy= array([[1, 2], [1, 2], [1, 2], [1, 2], [1, 2], [1, 2], [1, 2], [1, 2], [1, 2], [1, 2]])&gt; . x=tnp.array([1]*10 + [20.1,22.2,22.7,23.3,24.4,25.1,26.2,27.3,28.4,30.4]).reshape(2,10).T x . &lt;tf.Tensor: shape=(10, 2), dtype=float64, numpy= array([[ 1. , 20.1], [ 1. , 22.2], [ 1. , 22.7], [ 1. , 23.3], [ 1. , 24.4], [ 1. , 25.1], [ 1. , 26.2], [ 1. , 27.3], [ 1. , 28.4], [ 1. , 30.4]])&gt; . beta_true= tnp.array([[10.2,2.2]]) beta_true . &lt;tf.Tensor: shape=(1, 2), dtype=float64, numpy=array([[10.2, 2.2]])&gt; . x@beta_true . ValueError Traceback (most recent call last) Input In [72], in &lt;cell line: 1&gt;() -&gt; 1 x@beta_true File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages six.py:718, in reraise(tp, value, tb) 716 value = tp() 717 if value.__traceback__ is not tb: --&gt; 718 raise value.with_traceback(tb) 719 raise value 720 finally: ValueError: Matrix size-incompatible: In[0]: [10,2], In[1]: [1,2] [Op:MatMul] . 메트릭스 선언을 잘못하면 오류가 남..! 잘못된 계산 | . beta_true= tnp.array([[10.2],[2.2]]) beta_true . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[10.2], [ 2.2]])&gt; . matrix 선언이 중요함,, | . x@beta_true . &lt;tf.Tensor: shape=(10, 1), dtype=float64, numpy= array([[54.42], [59.04], [60.14], [61.46], [63.88], [65.42], [67.84], [70.26], [72.68], [77.08]])&gt; . tnp.random.seed(50000) y=x@beta_true + tnp.random.randn(10).reshape(10,1) y . &lt;tf.Tensor: shape=(10, 1), dtype=float64, numpy= array([[53.12550628], [59.48221878], [61.86480622], [64.06900254], [63.52340823], [62.85870759], [67.29683042], [69.54750897], [72.283444 ], [76.08682149]])&gt; . - 미분하고 싶은 $β$값 정의 . beta= tnp.array([[9.0],[2.0]]) beta . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[9.], [2.]])&gt; . - with문 . with tf.GradientTape() as mytape: loss=(y-x@beta).T @ (y-x@beta) . mytape.gradient(loss,beta) . β가 tf.constant로 정의되었기 때문에 계산결과 Nan이 되었다. | . with tf.GradientTape() as mytape: mytape.watch(beta) loss=(y-x@beta).T @ (y-x@beta) . mytape.gradient(loss,beta) . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[ -119.87650904], [-3008.60929929]])&gt; . 앞서 직접 구한 값과 동일하게 나왔다 | . - 다음과 같이 변환하여 보다 직관적으로 표현할 수 있다. . beta= tnp.array([[9.0],[2.0]]) with tf.GradientTape(persistent=True) as mytape: mytape.watch(beta) yhat=x@beta # yhat- 추정치 loss=(y-yhat).T @ (y-yhat) . mytape.gradient(loss,beta) . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[ -119.87650904], [-3008.60929929]])&gt; . with tf.GradientTape() as mytape: mytape.watch(beta) yhat=x@beta # yhat- 추정치 loss=(y-yhat).T @ (y-yhat) ... ... ... 등등 : 계속해서 선형변환, 비선형변환 등등을 추가하여 계산할 수 있어 매우 편리하다고 한다... . - 이론적 풀이 . $loss&#39;( beta)= - {2 bf X}&#39; { bf y} + 2{ bf X}&#39; { bf X}{ boldsymbol beta} $ . -2 * x.T @ y + 2 * x.T @ x @ beta . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[ -119.87650904], [-3008.60929929]])&gt; . - 이론적인 $β$의 최적값을 찾아보고 (즉 $ hat beta$을 찾고) 그 지점에서 loss의 미분값(=접선의 기울기)을 구하라. 결과가 0인지 확인하라. 단 0은 길이가 2이고 각 원소가 0인 벡터이다. . $ boldsymbol{ hat beta}= ({ bf X}^ top { bf X})^{-1}{ bf X}^ top { bf y} $ . bhat = tf.linalg.inv(x.T @ x) @ x.T @ y # tf.linalg.inv()는 역행렬 구하는 기능 bhat . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[13.49949892], [ 2.05974916]])&gt; . 앞서 구한 것보다 매우 근접한 값이 나왔다. | . with tf.GradientTape(persistent=True) as mytape: mytape.watch(bhat) yhat= x@bhat loss= (y-yhat).T @ (y-yhat) . mytape.gradient(loss,bhat) . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[-1.87583282e-12], [-4.64863703e-11]])&gt; . bhat에서 접선의 기울기는 0과 매우 가까운 값이 계산되었다. | . &#44221;&#49324;&#54616;&#44053;&#48277; . &#52572;&#51201;&#54868;&#47928;&#51228; . - $loss= ( frac{1}{2} beta -1)^2$를 최소로 하는 $ beta$를 컴퓨터를 통해 구하는 문제를 생각해보자. (답은 당연히 $ beta=2$) . &#48169;&#48277; 1: grid search . 알고리즘: step1: beta를 적당한 범위 내 값들로 설정한다. step2: 각각의 범위 내 값들에 대한 loss를 계산한다. step3: loss값들 중 가장 작은 beta 값을 찾는다. . beta= tnp.linspace(-10,10,100) loss= (beta/2 -1)**2 . loss . &lt;tf.Tensor: shape=(100,), dtype=float64, numpy= array([3.60000000e+01, 3.47980818e+01, 3.36165697e+01, 3.24554637e+01, 3.13147638e+01, 3.01944700e+01, 2.90945822e+01, 2.80151005e+01, 2.69560249e+01, 2.59173554e+01, 2.48990919e+01, 2.39012346e+01, 2.29237833e+01, 2.19667381e+01, 2.10300990e+01, 2.01138659e+01, 1.92180390e+01, 1.83426181e+01, 1.74876033e+01, 1.66529946e+01, 1.58387920e+01, 1.50449954e+01, 1.42716049e+01, 1.35186205e+01, 1.27860422e+01, 1.20738700e+01, 1.13821039e+01, 1.07107438e+01, 1.00597898e+01, 9.42924191e+00, 8.81910009e+00, 8.22936435e+00, 7.66003469e+00, 7.11111111e+00, 6.58259361e+00, 6.07448220e+00, 5.58677686e+00, 5.11947760e+00, 4.67258443e+00, 4.24609734e+00, 3.84001632e+00, 3.45434139e+00, 3.08907254e+00, 2.74420977e+00, 2.41975309e+00, 2.11570248e+00, 1.83205795e+00, 1.56881951e+00, 1.32598714e+00, 1.10356086e+00, 9.01540659e-01, 7.19926538e-01, 5.58718498e-01, 4.17916539e-01, 2.97520661e-01, 1.97530864e-01, 1.17947148e-01, 5.87695133e-02, 1.99979594e-02, 1.63248648e-03, 3.67309458e-03, 2.61197837e-02, 6.89725538e-02, 1.32231405e-01, 2.15896337e-01, 3.19967350e-01, 4.44444444e-01, 5.89327620e-01, 7.54616876e-01, 9.40312213e-01, 1.14641363e+00, 1.37292113e+00, 1.61983471e+00, 1.88715437e+00, 2.17488011e+00, 2.48301194e+00, 2.81154984e+00, 3.16049383e+00, 3.52984389e+00, 3.91960004e+00, 4.32976227e+00, 4.76033058e+00, 5.21130497e+00, 5.68268544e+00, 6.17447199e+00, 6.68666463e+00, 7.21926334e+00, 7.77226814e+00, 8.34567901e+00, 8.93949597e+00, 9.55371901e+00, 1.01883481e+01, 1.08433833e+01, 1.15188246e+01, 1.22146720e+01, 1.29309254e+01, 1.36675849e+01, 1.44246505e+01, 1.52021222e+01, 1.60000000e+01])&gt; . . - 가장 작은 값을 찾는 함수 tf.argmin()이용 . tf.argmin([1,-1,2,-2]) . &lt;tf.Tensor: shape=(), dtype=int64, numpy=3&gt; . 가장 작은 값이 있는 인덱스를 출력해준다 | . . tf.argmin(loss) . &lt;tf.Tensor: shape=(), dtype=int64, numpy=59&gt; . beta[tf.argmin(loss)] . &lt;tf.Tensor: shape=(), dtype=float64, numpy=1.9191919191919187&gt; . beta[59] . &lt;tf.Tensor: shape=(), dtype=float64, numpy=1.9191919191919187&gt; . 이론적 값인 2와 근접한 값이 나왔음 | . beta[60] . &lt;tf.Tensor: shape=(), dtype=float64, numpy=2.121212121212121&gt; . beta[58] . &lt;tf.Tensor: shape=(), dtype=float64, numpy=1.7171717171717162&gt; . loss[59], loss[60], loss[58] . (&lt;tf.Tensor: shape=(), dtype=float64, numpy=0.0016324864809713505&gt;, &lt;tf.Tensor: shape=(), dtype=float64, numpy=0.0036730945821854847&gt;, &lt;tf.Tensor: shape=(), dtype=float64, numpy=0.01999795939189892&gt;) . 앞 뒤로 한 개씩 차이나는 인덱스에 대한 loss값을 계산한 결과를 보니, 59번째 인덱스의 loss가 가장 작은 것을 알 수 있다. | . &#44536;&#47532;&#46300;&#49436;&#52824;&#51032; &#47928;&#51228;&#51216; . - 문제1: local minimum . 지정한 범위 외에서 더 작은 loss값이 나올 수 있음. 즉, 지정한 범위 내에 global minimum이 존재한다는 보장이 없음 | . - 문제2: 효율적이지 않음 . 모든 loss를 찾는 건 비효율적일 수 있음. 초반 또는 중간에 $loss=0$인 값을 찾았음에도 계산을 멈추지 않고 (더 이상 탐색할 필요가 없음에도) 끝까지 계산함 | . &#52628;&#44032;&#54617;&#49845; . - 그리드서치를 이용하여 $(x-1)^2$을 최소화하는 $x$값을 구하여라. . beta= tnp.linspace(-5,5,1000) loss= (beta-1)**2 . tf.argmin(loss) . &lt;tf.Tensor: shape=(), dtype=int64, numpy=599&gt; . beta[599] . &lt;tf.Tensor: shape=(), dtype=float64, numpy=0.9959959959959956&gt; . 이론적인 값인 1과 근접한 값이 나왔다 | .",
            "url": "https://ki5n2.github.io/charcoal/2022/03/23/DS.html",
            "relUrl": "/2022/03/23/DS.html",
            "date": " • Mar 23, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "DS 3. Tensorflow 기본 문법(2), tf.GradientTape()",
            "content": ". Data Science . lenture: Data Science_3-2nd week of lectures. | lenture date: 2022-03-21 | lecturer: Guebin choi | study date: 2022-03-22 | author: Kione kim | . . import tensorflow as tf import numpy as np . tnp . tnp &#49324;&#50857;&#48176;&#44221; . - tf.constant는 쓰기 너무 어려움! 넘파이가 지원하는 편리한 기능을 사용할 수 없음 . 어려운 점 1: .reshape() 메소드 불가능/ tf.reshape()만 가능 . 어려운 점 2: .transpose(), .T 불가능/ tf.transpose()만 가능 . 어려운 점 3: 암묵적 형변환 불가능 . 어려운 점 4: (2,2) @ (2,) 연산 불가능 . 등등 . - 예시1: .reshape() . a=np.array([1,2,3,4]).reshape(2,2) a . array([[1, 2], [3, 4]]) . a=tf.constant([1,2,3,4]).reshape(2,2) . AttributeError Traceback (most recent call last) Input In [3], in &lt;cell line: 1&gt;() -&gt; 1 a=tf.constant([1,2,3,4]).reshape(2,2) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:508, in Tensor.__getattr__(self, name) 504 def __getattr__(self, name): 505 if name in {&#34;T&#34;, &#34;astype&#34;, &#34;ravel&#34;, &#34;transpose&#34;, &#34;reshape&#34;, &#34;clip&#34;, &#34;size&#34;, 506 &#34;tolist&#34;, &#34;data&#34;}: 507 # TODO(wangpeng): Export the enable_numpy_behavior knob --&gt; 508 raise AttributeError(&#34;&#34;&#34; 509 &#39;{}&#39; object has no attribute &#39;{}&#39;. 510 If you are looking for numpy-related methods, please run the following: 511 from tensorflow.python.ops.numpy_ops import np_config 512 np_config.enable_numpy_behavior()&#34;&#34;&#34;.format(type(self).__name__, name)) 513 self.__getattribute__(name) AttributeError: &#39;EagerTensor&#39; object has no attribute &#39;reshape&#39;. If you are looking for numpy-related methods, please run the following: from tensorflow.python.ops.numpy_ops import np_config np_config.enable_numpy_behavior() . tf.reshape(tf.constant([1,2,3,4]),(2,2)) # 이렇게 써야함 . - 예시2: .transpose() . np.array([1,2,3,4]).transpose().reshape(2,2).T . array([[1, 3], [2, 4]]) . tf.constant([1,2,3,4]).transpose() . AttributeError Traceback (most recent call last) Input In [5], in &lt;cell line: 1&gt;() -&gt; 1 tf.constant([1,2,3,4]).transpose() File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:508, in Tensor.__getattr__(self, name) 504 def __getattr__(self, name): 505 if name in {&#34;T&#34;, &#34;astype&#34;, &#34;ravel&#34;, &#34;transpose&#34;, &#34;reshape&#34;, &#34;clip&#34;, &#34;size&#34;, 506 &#34;tolist&#34;, &#34;data&#34;}: 507 # TODO(wangpeng): Export the enable_numpy_behavior knob --&gt; 508 raise AttributeError(&#34;&#34;&#34; 509 &#39;{}&#39; object has no attribute &#39;{}&#39;. 510 If you are looking for numpy-related methods, please run the following: 511 from tensorflow.python.ops.numpy_ops import np_config 512 np_config.enable_numpy_behavior()&#34;&#34;&#34;.format(type(self).__name__, name)) 513 self.__getattribute__(name) AttributeError: &#39;EagerTensor&#39; object has no attribute &#39;transpose&#39;. If you are looking for numpy-related methods, please run the following: from tensorflow.python.ops.numpy_ops import np_config np_config.enable_numpy_behavior() . tf.transpose(tf.constant([1,2,3,4])) # 이렇게 써야함 . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])&gt; . tf.transpose(tf.reshape(tf.transpose(tf.constant([1,2,3,4])),(2,2))) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 3], [2, 4]])&gt; . 쓰기 불편,, | . - 예시3: 암묵적 형변환 . np.array([1,2,3])+np.array([1.1,2.2,3.3]) . array([2.1, 4.2, 6.3]) . tf.constant([1,2,3])+tf.constant([1.1,2.2,3.3]) . InvalidArgumentError Traceback (most recent call last) Input In [9], in &lt;cell line: 1&gt;() -&gt; 1 tf.constant([1,2,3])+tf.constant([1.1,2.2,3.3]) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:AddV2] . 암묵적 형변환 안 됨,, | . - 예시4: .max, .min 등등 넘파이에서 가능한 .max를 사용하려면 tf.constant에서는 tf.reduce_max()를 .min를 사용하려면 tf.reduce_min()를 사용해야함 . tf.reduce_max(tf.transpose(tf.reshape(tf.transpose(tf.constant([1,2,3,4])),(2,2)))) . &lt;tf.Tensor: shape=(), dtype=int32, numpy=4&gt; . tf.reduce_min(tf.transpose(tf.reshape(tf.transpose(tf.constant([1,2,3,4])),(2,2)))) . &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt; . - 예시5: (2,2) @ (2,) 연산 . np.array([[1.0,2.0],[3.0,4.0]]) @ np.array([1,2]) . array([ 5., 11.]) . np.array([1,2]) @ np.array([[1.0,2.0],[3.0,4.0]]) . array([ 7., 10.]) . 차원이 맞지 않아도 넘파이에서는 알아서 잘 계산해줌 | . np.array([[1.0,2.0],[3.0,4.0]]) @ np.array([1,2]).reshape(2,1) . array([[ 5.], [11.]]) . np.array([1,2]).reshape(2,1) @ np.array([[1.0,2.0],[3.0,4.0]]) . ValueError Traceback (most recent call last) Input In [15], in &lt;cell line: 1&gt;() -&gt; 1 np.array([1,2]).reshape(2,1) @ np.array([[1.0,2.0],[3.0,4.0]]) ValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)-&gt;(n?,m?) (size 2 is different from 1) . 헷갈릴 것 같다면 .reshape()를 써서 명시해줄 수 있다 | . tf.constant([[1.0,2.0],[3.0,4.0]]) @ tf.constant([1,2]) . InvalidArgumentError Traceback (most recent call last) Input In [16], in &lt;cell line: 1&gt;() -&gt; 1 tf.constant([[1.0,2.0],[3.0,4.0]]) @ tf.constant([1,2]) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute MatMul as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:MatMul] . 차원이 맞지 않으면 계산을 하지 않는다. | . tnp &#49324;&#50857; . import tensorflow.experimental.numpy as tnp # tnp를 사용하면 넘파이에 익숙한 문법을 모두 쓸 수 있음 tnp.experimental_enable_numpy_behavior() # 기존에 생성된 tf.constant 자료형은 넘파이와 유사하게 동작한다. . tnp.array([1,2,3]) . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])&gt; . tnp.diag([1,1]) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 0], [0, 1]])&gt; . &#53440;&#51077; . type(tf.constant([1,2])),type(tnp.array([1,2])) . (tensorflow.python.framework.ops.EagerTensor, tensorflow.python.framework.ops.EagerTensor) . tnp를 사용해도 타입은 변하지 않는다. 모두 EagerTensor | . - 앞서 본 어려운 점 1인 .reshape()가 사용 가능! . tf.constant([1,2,3,4]).reshape(2,2) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]])&gt; . - 어려운 점 2인 .transpose, .T 도 사용 가능! . tf.constant([1,2,3,4]).reshape(2,2).transpose().T . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]])&gt; . - 어려운 점 3인 암묵적 형변환도 가능! . tf.constant([1,2,3]) + tf.constant([1.1,2.2,3.3]) . &lt;tf.Tensor: shape=(3,), dtype=float64, numpy=array([2.10000002, 4.20000005, 6.29999995])&gt; . - 어려운 점 4인 .max(), .min() 등도 가능! . tf.constant([1,2,3]) +tf.constant([1.1,2.2,3.3]).max() . &lt;tf.Tensor: shape=(3,), dtype=float64, numpy=array([4.29999995, 5.29999995, 6.29999995])&gt; . tf.constant([1,2,3]) + tf.constant([1.1,2.2,3.3]).min() . &lt;tf.Tensor: shape=(3,), dtype=float64, numpy=array([2.10000002, 3.10000002, 4.10000002])&gt; . - 어려운 점 5인 (2,2) @ (2,)의 연산도 가능! . tnp.diag([1,1]) @ tf.constant([1,2]) . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2])&gt; . tf.constant([1,2]) @ tnp.diag([1,1]) . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2])&gt; . 많은 단점을 개선했음!! | . - 하지만 안 되는 것도 있음 . a = np.array([1,2,3]) a . array([1, 2, 3]) . a[0] = 0 a . array([0, 2, 3]) . a=tnp.array([1,2,3]) a . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])&gt; . a[0]=0 a . TypeError Traceback (most recent call last) Input In [31], in &lt;cell line: 1&gt;() -&gt; 1 a[0]=0 2 a TypeError: &#39;tensorflow.python.framework.ops.EagerTensor&#39; object does not support item assignment . 이는 안 됨 | . tf.Variable . &#50696;&#48708;&#54617;&#49845; . a=8 a . 8 . id(a) . 140715972567008 . a=10 a . 10 . id(a) . 140715972567072 . 이는 값을 변경(편집)한 것이 아니라 재할당한 것이다. | . b=10 id(b) . 140715972567072 . 1) tf.constant는 메모리에 그 값을 올리는 것 -&gt; 메모리에 있는 것은 바꿀 수 없음 -&gt; 값을 변경하고자 하면 재할당 해야 함 . 2) tf.Variable은 메모리에 있는 값을 변경(편집)할 수 있음 . . - 선언 . tf.Variable([1,2]) . &lt;tf.Variable &#39;Variable:0&#39; shape=(2,) dtype=int32, numpy=array([1, 2])&gt; . - type . type(tf.Variable([1,2])) . tensorflow.python.ops.resource_variable_ops.ResourceVariable . ResourceVariable 처음 보는 타입 | . - tf.constant() 선언 후 변환 . tf.Variable(tf.constant([1,2])) . &lt;tf.Variable &#39;Variable:0&#39; shape=(2,) dtype=int32, numpy=array([1, 2])&gt; . - np.array() 선언 후 변환 . tf.Variable(np.array([1,2])) . &lt;tf.Variable &#39;Variable:0&#39; shape=(2,) dtype=int32, numpy=array([1, 2])&gt; . - 인덱싱 . a=tf.Variable([1,2,3,4]) a[:2] . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2])&gt; . - 연산 . tf.Variable([1,2]) + tf.Variable([2,1]) . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 3])&gt; . 그런데 살펴보니, 인덱싱과 연산 후에 자료형이 tf.Variable에서 tf.Tensor로 바꼈다. | . a=tf.Variable([1,2]) b=tf.Variable([2,1]) type(a), type(b) . (tensorflow.python.ops.resource_variable_ops.ResourceVariable, tensorflow.python.ops.resource_variable_ops.ResourceVariable) . type(a+b) . tensorflow.python.framework.ops.EagerTensor . tf.Variable()로 만든 후 간단한연산을 하면 그 결과는 tf.constant()로 만든 오브젝트와 동일해짐. | . tf.Variable([1,2]) + tf.Variable([1.1,2.2]) . &lt;tf.Tensor: shape=(2,), dtype=float64, numpy=array([2.10000002, 4.20000005])&gt; . 이는 원래 안 되지만, tnp.experimental_enable_numpy_behavior()를 선언하면 가능함 | . tf.Variable([1,2,3,4]).reshape(2,2) . AttributeError Traceback (most recent call last) Input In [46], in &lt;cell line: 1&gt;() -&gt; 1 tf.Variable([1,2,3,4]).reshape(2,2) AttributeError: &#39;ResourceVariable&#39; object has no attribute &#39;reshape&#39; . 이것은 또 안 됨.. | . tnp의 전부 되는 것은 아니고 일부만 가능 | . - tf.concat . a=tf.Variable([[1,2],[3,4]]) b=tf.Variable([[-1,-2],[-3,-4]]) . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(4, 2), dtype=int32, numpy= array([[ 1, 2], [ 3, 4], [-1, -2], [-3, -4]])&gt; . tf.concat([a,b],axis=1) . &lt;tf.Tensor: shape=(2, 4), dtype=int32, numpy= array([[ 1, 2, -1, -2], [ 3, 4, -3, -4]])&gt; . - tf.stack . tf.stack([a,b],axis=0) . &lt;tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy= array([[[ 1, 2], [ 3, 4]], [[-1, -2], [-3, -4]]])&gt; . tf.stack([a,b],axis=1) . &lt;tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy= array([[[ 1, 2], [-1, -2]], [[ 3, 4], [-3, -4]]])&gt; . - 변수값 변경 가능 . a=tf.Variable([1,2]) a . &lt;tf.Variable &#39;Variable:0&#39; shape=(2,) dtype=int32, numpy=array([1, 2])&gt; . id(a) . 1561676107296 . a.assign_add([-1,2]) a . &lt;tf.Variable &#39;Variable:0&#39; shape=(2,) dtype=int32, numpy=array([0, 4])&gt; . id(a) . 1561676107296 . 위를 살펴보니, 메모리 주소가 같다. 즉 값이 재할당 된 것이 아닌 변경된 것임을 알 수 있다. | . : tf.constant()는 일반메모리에, tf.Variable은 GPU에 . &#48120;&#48516; . :Tensorflow를 사용하는 가장 큰 이유 . 모티브 . - 예제: 컴퓨터를 이용하여 $x=2$에서 $y=3x^2$의 접선의 기울기를 구해보자. . - (손풀이) . $ frac{dy}{dx}=6x$ 이므로, $x=2$를 대입 -&gt; 답 : 12. . - (컴퓨터로 풀이) . 도함수를 어떻게 구할지 모르겠으나 일단 $x=2$에서 접선의 기울기만 계산해보자 . step 1: 답만계산 . x1=2 y1=3*x1**2 . x2=2.000001 y2=3*x2**2 . (y2-y1)/(x2-x1) . 12.000003000266702 . step 2: 함수화 . def f(x): return 3*x**2 . def d(f,x): # python에서는 d(f,x)로 선언 가능 return (f(x+0.000001)-f(x))/0.000001 # f(x+a)-f(x)/a 꼴 . d(f,2) . 12.000003001944037 . d(f,3) . 18.000003002782705 . step 3: lambda 이용 . d(lambda x: 3*x**2,2) . 12.000003001944037 . d(lambda x: 3*x**2,3) . 18.000003002782705 . d(lambda x: x**2,3) . 6.000001000927568 . - 2개의 변수를 가지는 함수에 대한 미분 . def d(f,x): return (f(x+0.000001)-f(x))/0.000001 . def f(x,y): return x**2 + 3*y . d(f,(3,2)) # 미분을 하는 함수 d에 x**2+3*y를 적용시켜 미분시킨 후 x,y에 3,2를 각각 대입하라. . TypeError Traceback (most recent call last) Input In [68], in &lt;cell line: 1&gt;() -&gt; 1 d(f,(3,2)) Input In [66], in d(f, x) 1 def d(f,x): -&gt; 2 return (f(x+0.000001)-f(x))/0.000001 TypeError: can only concatenate tuple (not &#34;float&#34;) to tuple . 오류가 남 | . 이는 확장성이 떨어지기 때문에 다른 방법이 필요함 | . tf.GradientTape() . - 예제1: $x=2$에서 $y=3x^2$의 도함수 값을 구하여라. . x=tf.Variable([2.0]) a=tf.constant([3.0]) . . tf.GradientTape() . &lt;tensorflow.python.eager.backprop.GradientTape at 0x16b9b289130&gt; . 무엇인가 만들어졌음 | . mytape=tf.GradientTape() . dir(mytape) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__enter__&#39;, &#39;__eq__&#39;, &#39;__exit__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;_ensure_recording&#39;, &#39;_persistent&#39;, &#39;_pop_tape&#39;, &#39;_push_tape&#39;, &#39;_recording&#39;, &#39;_tape&#39;, &#39;_tf_api_names&#39;, &#39;_tf_api_names_v1&#39;, &#39;_watch_accessed_variables&#39;, &#39;_watched_variables&#39;, &#39;batch_jacobian&#39;, &#39;gradient&#39;, &#39;jacobian&#39;, &#39;reset&#39;, &#39;stop_recording&#39;, &#39;watch&#39;, &#39;watched_variables&#39;] . dir()을 찍어보니 다음과 같은 게 있음 | . __enter__ | __exit__ | ?mytape.__enter__ . Signature: mytape.__enter__() Docstring: Enters a context inside which operations are recorded on this tape. File: c: users kko anaconda3 envs ds2022 lib site-packages tensorflow python eager backprop.py Type: method . 이는 함수이고 tape를 기록하는 기능을 함 | . ?mytape.__exit__ . Signature: mytape.__exit__(typ, value, traceback) Docstring: Exits the recording context, no further operations are traced. File: c: users kko anaconda3 envs ds2022 lib site-packages tensorflow python eager backprop.py Type: method . 함수인데 ( )안에 None, None, None를 입력해주어야 한다. 기록을 끄는 기능을 함 | . tf.GradientTape() 사용법: mytape.__enter__ 기록할 내용 mytape.__exit__ . x=tf.Variable([2.0]) # 미분하고 싶은 변수는 Variable로 할당 a=tf.constant([3.0]) # a는 상수로, 값을 저장하고 싶은 것은 constant로 할당 . mytape.__enter__() y=a*x**2 mytape.__exit__(None,None,None) . mytape.gradient(y,x) # 변수 x로 y를 미분 . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt; . - 예제2 . x=tf.Variable([2.0]) . mytape=tf.GradientTape() . mytape.__enter__() a=(x/2)*3 # a를 기록할 내용으로 가져왔음 y=a*x**2 mytape.__exit__(None,None,None) . mytape.gradient(y,x) # 변수 x로 y를 미분 . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([18.], dtype=float32)&gt; . a를 기록할 내용에서 지정해준 것 뿐인데 12가 아닌 18이 나왔음 | . 이는 다음의 과정을 통해 나온 결과임 | . $a= frac{3}{2}x$ . $y=ax^2= frac{3}{2}x^3$ . $ frac{dy}{dx}= frac{3}{2}3 x^2$ . 1.5 × 3 × 4 = 18 . 1.5 * 3 * 4 . 18.0 . 즉 y는 $a=3$을 기록한 것이 아니라, $a= frac{3}{2}x$를 기록한 것이다. | . - 테이프의 개념(중요) . - 상황 예시 . 미분계산을 컴퓨터에게 부탁하고 싶다. 예를 들어 $y=3x^2$에 대한 미분계산을 컴퓨터에 부탁 하기 위해서는 노트 및 연습장(=테이프)에 $y=3x^2$이라는 수식을 써서 보여줘야 한다. 이 때 컴퓨터에게 식($y$)이 무엇인지 그리고 무엇으로 미분하고 싶은지($x$)를 명시해야 한다. . - 비유 . (1) mytape = tf.GradientTape(): . tf.GradientTape() 는 컴퓨터에게 전달할 노트 생성 | mytape= 는 생성한 노트의 이름을 mytape이라고 지정 | . (2) mytape.__enter__(): . mytape 라는 노트를 연다. | . (3) a=x/2*3; y=a*x**2: . 컴퓨터에게 보여줄 식(미분하고자 하는 식) | . (4) mytape.__exit__(None,None,None): mytape라는 공책을 닫는다. . mytape 라는 노트를 닫는다. | . (5) mytape.gradient(y,x): $y$를 $x$로 미분한다는 메모를 남겨 컴퓨터에 전달 . - 여기서 가장 중요한 것은 노트를 언제 열고 닫는지이다 . 1) . x=tf.Variable([2.0]) a=x/2*3 # a=x*(3/2) -&gt; a=3 #2 mytape=tf.GradientTape() #3 mytape.__enter__() y=a*x**2 # y=3*x**2, a는 이미 3의 값을 가짐 mytape.__exit__(None,None,None) #4 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt; . 2) . x=tf.Variable([2.0]) #2 mytape=tf.GradientTape() #3 mytape.__enter__() a=x/2*3 y=a*x**2 # a=(3*x)/2로 y=(3*x)/2*x**2 mytape.__exit__(None,None,None) #4 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([18.], dtype=float32)&gt; . 이를 유심히 살펴보니, 코드가 뭔가 깔끔하지가 않음. 중복되는 것도 있어 보임. . | 보다 깔끔하고 효율적인 코드가 필요! -&gt; with문활용 . | . - 참고: x=tf.constant([2]) float형으로 입력하지 않으면 오류!! tf.Variable([2])도 마찬가지 . x=tf.constant([2]) #2 mytape=tf.GradientTape() #3 mytape.__enter__() a=x/2*3 y=a*x**2 # a=(3*x)/2로 y=(3*x)/2*x**2 mytape.__exit__(None,None,None) #4 mytape.gradient(y,x) . WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32 . x=tf.Variable([2]) #2 mytape=tf.GradientTape() #3 mytape.__enter__() a=x/2*3 y=a*x**2 # a=(3*x)/2로 y=(3*x)/2*x**2 mytape.__exit__(None,None,None) #4 mytape.gradient(y,x) . WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32 . with&#47928;&#51012; &#54876;&#50857;&#54620; tf.GradientTape() . with문 사용법: with tf.GradientTape() as mytape: 컴퓨터에게 전달할 수식 1. tf.GradientTape()를 실행하면 오브젝트가 하나 생성되는데 이를 mytape라고 지정한다. 기존에 mytape=tf.GradientTape()을 with tf.GradientTape as mytape으로 지정해준다. 2. with문이 시작되면서 mytape.__enter__()이 실행 3. 컴퓨터에게 전달한 수식 실행 4. with문이 끝나면서 mytape.__exit__(None,None,None)가 실행 . - with문 사용한 예제 풀이 . 1) . x=tf.Variable([2.0]) a=x/2*3 with tf.GradientTape() as mytape: y=a*x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt; . 2) . x=tf.Variable([2.0]) with tf.GradientTape() as mytape: a=x/2*3 y=a*x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([18.], dtype=float32)&gt; . - persistent=True: 계산한 값을 버리지 않는 기능으로 계속해서 출력할 수 있다 . x=tf.Variable([2.0]) a=x/2*3 with tf.GradientTape() as mytape: y=a*x**2 . mytape.gradient(y,x),mytape.gradient(y,x) . RuntimeError Traceback (most recent call last) Input In [115], in &lt;cell line: 1&gt;() -&gt; 1 mytape.gradient(y,x),mytape.gradient(y,x) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python eager backprop.py:1029, in GradientTape.gradient(self, target, sources, output_gradients, unconnected_gradients) 999 &#34;&#34;&#34;Computes the gradient using operations recorded in context of this tape. 1000 1001 Note: Unless you set `persistent=True` a GradientTape can only be used to (...) 1026 called with an unknown value. 1027 &#34;&#34;&#34; 1028 if self._tape is None: -&gt; 1029 raise RuntimeError(&#34;A non-persistent GradientTape can only be used to &#34; 1030 &#34;compute one set of gradients (or jacobians)&#34;) 1031 if self._recording: 1032 if not self._persistent: RuntimeError: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians) . 두 번 실행하면 오류가 난다 | . x=tf.Variable([2.0]) a=x/2*3 with tf.GradientTape(persistent=True) as mytape: y=a*x**2 . mytape.gradient(y,x),mytape.gradient(y,x) . (&lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt;, &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt;) . 오류 해결! | . - 미분계산에 사용할 변수($x$)를 tf.constant로 설정하면 계산이 되지 않는다. . x=tf.constant([2.0]) a=x/2*3 with tf.GradientTape(persistent=True) as mytape: y=a*x**2 mytape.gradient(y,x) . print(mytape.gradient(y,x)) . None . 미분계산에 사용할 변수는 tf.Variable로 설정해야 한다 | . - 자동감시모드 &amp; 수동감시모드 . - 예시 . notename.watch(x):를 사용하면 미분계산에 사용할 변수($x$)를 tf.constant()로 설정하였더라도 계산이 된다. . x=tf.constant([2.0]) a=x/2*3 with tf.GradientTape(persistent=True) as mytape: mytape.watch(x) y=a*x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt; . 계산이 되었음 ! | . tf.Variable(): 자동감시모드 tf.constant(): 감시 X `notename.watch(감시할 변수)`사용: (감시할 변수에 대한) 수동감시모드 . - 자동감시모드(기존) . x=tf.Variable([2.0]) a=x/2*3 with tf.GradientTape(persistent=True) as mytape: y=a*x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt; . - 자동감시모드 off : watch_accessed_variables=False 사용 . x=tf.Variable([2.0]) a=x/2*3 with tf.GradientTape(persistent=True,watch_accessed_variables=False) as mytape: y=a*x**2 mytape.gradient(y,x) . - 수동감시모드 . x=tf.constant([2.0]) a=x/2*3 with tf.GradientTape(persistent=True) as mytape: mytape.watch(x) # 수동감시 y=a*x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt; . - 자동감시모드 -&gt; 자동감시모드 off -&gt; 수동감시 ON . x=tf.Variable([2.0]) a=x/2*3 with tf.GradientTape(persistent=True,watch_accessed_variables=False) as mytape: mytape.watch(x) y=a*x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt; . 가능! | . 헷갈리면 언제나 mytape.watch(변수)를 명시해도 괜찮음! | 오류가 나는 것은 아니니! | . &#52628;&#44032;&#54617;&#49845; . - tf.GradientTape( )를 이용하여 $y=x^2$에서 $x=0$에서의 접선의 기울기를 구하라. . x=tf.constant([0.0]) with tf.GradientTape(persistent=True) as mytape: mytape.watch(x) y=x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)&gt; .",
            "url": "https://ki5n2.github.io/charcoal/2022/03/22/DS.html",
            "relUrl": "/2022/03/22/DS.html",
            "date": " • Mar 22, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "DS 2. Tensorflow 기본 문법(1) - tf.constant",
            "content": ". Data Science . lenture: Data Science_2-2, 3-1nd week of lectures. | lenture date: 2022-03-14, 2022-03-16 | lecturer: Guebin choi | study date: 2022-03-18, 2022-03-20 | author: Kione kim | . . Tensorflow &#49324;&#50857;&#48277; . import tensorflow as tf import numpy as np . tf.config.experimental.list_physical_devices(&#39;GPU&#39;) . [] . NO GPU | . tf.constant . &#50696;&#48708;&#54617;&#49845;: &#51473;&#52393;&#47532;&#49828;&#53944; . [1,[2,3]] . [1, [2, 3]] . _[1][1] . 3 . lst = [[1,2],[3,4]] lst . [[1, 2], [3, 4]] . lst[0][1] . 2 . lst[1][0] . 3 . 1 2 3 4 . print(lst[0][0]) # (1,1) print(lst[0][1]) # (1,2) print(lst[1][0]) # (2,1) print(lst[1][1]) # (2,2) . 1 2 3 4 . 이는 벡터일 뿐인데 매트릭스처럼 보임(매트릭스는 아님) | . - 이를(매트릭스처럼 보이는 것을) 활용하여 행렬을 만들어보자 . $4×2$ . lst = [[1,2],[3,4],[5,6],[7,8]] lst . [[1, 2], [3, 4], [5, 6], [7, 8]] . $4×1$ . lst = [[1],[2],[3],[4]] lst # 길이가 4인 column-vector처럼 보임 . [[1], [2], [3], [4]] . $2×4$ . lst = [[1,2,3,4],[5,6,7,8]] lst . [[1, 2, 3, 4], [5, 6, 7, 8]] . $1×4$ . lst = [[1,2,3,4]] lst # 길이가 4인 row-vector처럼 보임 . [[1, 2, 3, 4]] . - 3차원 . lst = [[[1,2],[3,4]],[[5,6],[7,8]]] # 2×2×2 매트릭스처럼 보임 lst . [[[1, 2], [3, 4]], [[5, 6], [7, 8]]] . print(lst[0][0][0]) print(lst[0][0][1]) print(lst[0][1][0]) print(lst[0][1][1]) # 차원 2 print(lst[1][0][0]) print(lst[1][0][1]) print(lst[1][1][0]) print(lst[1][1][1]) . 1 2 3 4 5 6 7 8 . &#49440;&#50616; . - 스칼라 . _scalar = tf.constant(1) _scalar . &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt; . - 벡터 . [1,2,3] # 리스트 . [1, 2, 3] . _vector = tf.constant([1,2,3]) # 리스트를 tf.constant()함수를 사용하여 벡터로 _vector . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])&gt; . _vector[-1], _vector[-2] . (&lt;tf.Tensor: shape=(), dtype=int32, numpy=3&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;) . - 아래 두 코드는 다름. 두 번째 코드는 의도하지 않은 결과임 . a=tf.constant([1,2,3,4]) a . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])&gt; . a=tf.constant(1,2,3,4) a . &lt;tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 1., 1.])&gt; . tf.constant([ ]) [ ]를 사용해주어야 함 ! | . - 매트릭스 . _mat = tf.constant([[1,2,3],[4,5,6]]) _mat . &lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy= array([[1, 2, 3], [4, 5, 6]])&gt; . 하나의 행렬로 묶을 때는 행렬처음과 끝에 [ ]로 받아주어야 한다. | . _mat[0] . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])&gt; . _mat[0][0] . &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt; . _mat[0,0] . &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt; . _mat[0][0]를 _mat[0,0]와 같이 사용할 수 있다 | . - 첫번째 행을 뽑는 방법 . - 방법1 . _mat[0] . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])&gt; . - 방법2 . _mat[0,:] . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])&gt; . - 첫번째 열을 뽑는 방법 . _mat[:,0] . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 4])&gt; . _mat[:,-1] . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 6])&gt; . 즉 행과 열을 모두 뽑을 수 있는 방법은 방법2이다. 확장성이 있음 | . type(_scalar) . tensorflow.python.framework.ops.EagerTensor . EagerTensor임을 기억 | . type(_vector) . tensorflow.python.framework.ops.EagerTensor . tf.constant&#51032; &#48520;&#54200;&#54620;&#51216; . 1. dtype 모든 원소가 똑같아야함 2. 값을 바꿀 수 없음 3. dtype이 다르면 연산이 불가능 . 2. 값을 바꿀 수 없음 . _mat[0,0] = 10 . TypeError Traceback (most recent call last) Input In [41], in &lt;cell line: 1&gt;() -&gt; 1 _mat[0,0] = 10 TypeError: &#39;tensorflow.python.framework.ops.EagerTensor&#39; object does not support item assignment . 3. dtype이 다르면 연산 불가능 . tf.constant([1,2])+ tf.constant([3,4]) . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6])&gt; . tf.constant([1.1,2])+ tf.constant([3,4]) . InvalidArgumentError Traceback (most recent call last) Input In [43], in &lt;cell line: 1&gt;() -&gt; 1 tf.constant([1.1,2])+ tf.constant([3,4]) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2] . tf.constant([1.1,2]) . &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.1, 2. ], dtype=float32)&gt; . tf.constant([3,4]) . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4])&gt; . 뜯어보니, tf.constant([1.1,2])는 float형이고 tf.constant([3,4])는 int형이다. float과 int가 달라서 계산이 안 된 것,, ? OMG | . - 다음과 같이 해야 한다 . tf.constant([1.1,2])+tf.constant([3.,4.]) . &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.1, 6. ], dtype=float32)&gt; . tf.constant([1.1,2])+tf.constant([3,4.]) . &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.1, 6. ], dtype=float32)&gt; . tf.constant([1.1,2])+tf.constant([3.,4]) . &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.1, 6. ], dtype=float32)&gt; . int형에 있는 하나의 원소에 .을 찍어주면 float형이 된다. | . - 같은 float형이라도 불가능한 경우가 있음 . tf.constant([1.1,2]) . &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.1, 2. ], dtype=float32)&gt; . tf.constant([3.0,4.0],dtype=tf.float64) . &lt;tf.Tensor: shape=(2,), dtype=float64, numpy=array([3., 4.])&gt; . tf.constant([1.1,2])+tf.constant([3.0,4.0],dtype=tf.float64) . InvalidArgumentError Traceback (most recent call last) Input In [56], in &lt;cell line: 1&gt;() -&gt; 1 tf.constant([1.1,2])+tf.constant([3.0,4.0],dtype=tf.float64) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2] . float32와 float64가 달라서 오류,,,? OMG2 | . tf.constant $ to$ &#45336;&#54028;&#51060; . _vector = tf.constant([1,2,3,4]) _vector . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])&gt; . np.array(_vector) # 방법1 . array([1, 2, 3, 4]) . _vector.numpy() . array([1, 2, 3, 4]) . Tensorflow 내에서 numpy를 쓸 수 있다 | . &#50672;&#49328; . - 더하기 . a=tf.constant([1,2,3]) b=tf.constant([4,5,6]) a+b . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 7, 9])&gt; . tf.add(a,b) . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 7, 9])&gt; . - 곱하기 . a=tf.constant([[1,2],[3,4]]) b=tf.constant([[5,6],[7,8]]) a*b . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[ 5, 12], [21, 32]])&gt; . tf.multiply(a,b) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[ 5, 12], [21, 32]])&gt; . 각 원소끼리 곱 | . - 행렬곱 . a=tf.constant([[1,2],[3,4]]) b=tf.constant([[1,0],[0,1]]) a@b . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]])&gt; . tf.matmul(a,b) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]])&gt; . - 역행렬 . a=tf.constant([[1,0],[0,2]]) a . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 0], [0, 2]])&gt; . tf.linalg.inv(a) . InvalidArgumentError Traceback (most recent call last) Input In [69], in &lt;cell line: 1&gt;() -&gt; 1 tf.linalg.inv(a) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python ops gen_linalg_ops.py:1505, in matrix_inverse(input, adjoint, name) 1503 return _result 1504 except _core._NotOkStatusException as e: -&gt; 1505 _ops.raise_from_not_ok_status(e, name) 1506 except _core._FallbackException: 1507 pass File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: Value for attr &#39;T&#39; of int32 is not in the list of allowed values: double, float, half, complex64, complex128 ; NodeDef: {{node MatrixInverse}}; Op&lt;name=MatrixInverse; signature=input:T -&gt; output:T; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]&gt; [Op:MatrixInverse] . 당연히 되어야하는데 오류가 남. 이는 a가 int이지만, 역행렬 값은 0.5(소수값)이 나오기 때문.. OMG3 . | 따라서 다음과 같이 하면 가능.. . | . a=tf.constant([[1.0,0],[0,2]]) a . &lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 0.], [0., 2.]], dtype=float32)&gt; . tf.linalg.inv(a) . &lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1. , 0. ], [0. , 0.5]], dtype=float32)&gt; . a도 float형으로 했기 때문에 가능 | . a @ tf.linalg.inv(a) . &lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 0.], [0., 1.]], dtype=float32)&gt; . - 행렬식, 대각합 . a=tf.constant([[1.0,0],[0,2]]) a . &lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 0.], [0., 2.]], dtype=float32)&gt; . tf.linalg.det(a) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.0&gt; . tf.linalg.trace(a) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=3.0&gt; . - 집계함수 . a=tf.constant([[1,2,3],[4,5,6]]) a . &lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy= array([[1, 2, 3], [4, 5, 6]])&gt; . tf.reduce_sum(a) . &lt;tf.Tensor: shape=(), dtype=int32, numpy=21&gt; . tf.sum(a) # 잘못된 코드1 . AttributeError Traceback (most recent call last) Input In [82], in &lt;cell line: 1&gt;() -&gt; 1 tf.sum(a) AttributeError: module &#39;tensorflow&#39; has no attribute &#39;sum&#39; . a.sum(a) # 잘못된 코드2 . AttributeError Traceback (most recent call last) Input In [56], in &lt;cell line: 1&gt;() -&gt; 1 a.sum(a) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:513, in Tensor.__getattr__(self, name) 505 if name in {&#34;T&#34;, &#34;astype&#34;, &#34;ravel&#34;, &#34;transpose&#34;, &#34;reshape&#34;, &#34;clip&#34;, &#34;size&#34;, 506 &#34;tolist&#34;, &#34;data&#34;}: 507 # TODO(wangpeng): Export the enable_numpy_behavior knob 508 raise AttributeError(&#34;&#34;&#34; 509 &#39;{}&#39; object has no attribute &#39;{}&#39;. 510 If you are looking for numpy-related methods, please run the following: 511 from tensorflow.python.ops.numpy_ops import np_config 512 np_config.enable_numpy_behavior()&#34;&#34;&#34;.format(type(self).__name__, name)) --&gt; 513 self.__getattribute__(name) AttributeError: &#39;tensorflow.python.framework.ops.EagerTensor&#39; object has no attribute &#39;sum&#39; . tf.reduce_max(a) . &lt;tf.Tensor: shape=(), dtype=int32, numpy=6&gt; . tf.reduce_min(a) . &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt; . tf.reduce_mean(a) . &lt;tf.Tensor: shape=(), dtype=int32, numpy=3&gt; . 왜 평균이 3.5가 아닌 3이 나오지? | . - 행렬곱 고급 . _I=tf.constant([[1.0,0.0],[0.0,1.0]]) _I . &lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 0.], [0., 1.]], dtype=float32)&gt; . _x=tf.constant([11,22]) _x . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([11, 22])&gt; . _I @ _x . InvalidArgumentError Traceback (most recent call last) Input In [91], in &lt;cell line: 1&gt;() -&gt; 1 _I @ _x File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute MatMul as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:MatMul] . 오류가 남. | 이유: _x가 길이가 2인 열벡터도 아니고 길이가 2인 행벡터도 아니기 때문, _x는 그저 길이가 2인 벡터임 | . _x @ _I . InvalidArgumentError Traceback (most recent call last) Input In [92], in &lt;cell line: 1&gt;() -&gt; 1 _x @ _I File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute MatMul as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:MatMul] . 이것 또한 마찬가지, 열벡터가 아니기 때문 | . - 다음과 같이 표현해주어야 함 . - 열벡터 선언 . _x=tf.constant([[11],[22]]) _x . &lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy= array([[11], [22]])&gt; . - cf. 행벡터 . _x=tf.constant([[11,22]]) _x . &lt;tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[11, 22]])&gt; . _I @ _x . InvalidArgumentError Traceback (most recent call last) Input In [101], in &lt;cell line: 1&gt;() -&gt; 1 _I @ _x File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute MatMul as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:MatMul] . float형으로 선언해주지 않아서 난 오류 | . _x=tf.constant([[11.0],[22.0]]) _x . &lt;tf.Tensor: shape=(2, 1), dtype=float32, numpy= array([[11.], [22.]], dtype=float32)&gt; . _I @ _x . &lt;tf.Tensor: shape=(2, 1), dtype=float32, numpy= array([[11.], [22.]], dtype=float32)&gt; . - 행벡터 선언 tf.constant([[ , ]]) . _x=tf.constant([[11.0,22.0]]) _x . &lt;tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[11., 22.]], dtype=float32)&gt; . _x @ _I . &lt;tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[11., 22.]], dtype=float32)&gt; . &#54805;&#53468;&#48320;&#54872; . - 기본 . a=tf.constant([1,2,3,4]) a . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])&gt; . 이는 길이가 4인 벡터 | . tf.reshape(a,(2,2)) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]])&gt; . tf.reshape(a,(4,1)) . &lt;tf.Tensor: shape=(4, 1), dtype=int32, numpy= array([[1], [2], [3], [4]])&gt; . tf.reshape(a,(1,4)) . &lt;tf.Tensor: shape=(1, 4), dtype=int32, numpy=array([[1, 2, 3, 4]])&gt; . - 응용 -1이용 : -1은 자동 연산하여 값을 채워주는 기능 . a=tf.constant([0,1,2,3,4,5,6,7,8,9,10,11]) a . &lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])&gt; . tf.reshape(a,(4,3)) # 기본 . &lt;tf.Tensor: shape=(4, 3), dtype=int32, numpy= array([[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8], [ 9, 10, 11]])&gt; . tf.reshape(a,(4,-1)) # 응용 . &lt;tf.Tensor: shape=(4, 3), dtype=int32, numpy= array([[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8], [ 9, 10, 11]])&gt; . tf.reshape(a,(2,2,3)) # 기본 . &lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]]])&gt; . tf.reshape(a,(2,2,-1)) # 응용 . &lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]]])&gt; . tf.reshape(a,(3,2,2)) # 기본 . &lt;tf.Tensor: shape=(3, 2, 2), dtype=int32, numpy= array([[[ 0, 1], [ 2, 3]], [[ 4, 5], [ 6, 7]], [[ 8, 9], [10, 11]]])&gt; . tf.reshape(a,(3,2,-1)) . &lt;tf.Tensor: shape=(3, 2, 2), dtype=int32, numpy= array([[[ 0, 1], [ 2, 3]], [[ 4, 5], [ 6, 7]], [[ 8, 9], [10, 11]]])&gt; . tf.reshape(a,(2,-1)) . &lt;tf.Tensor: shape=(2, 6), dtype=int32, numpy= array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11]])&gt; . $2×6$ 행렬로 만들어줌, 즉, 3차원으로 만들고 싶을 땐 두 번째 값까지는 채워줘야 함 | . - reshape한 것을 다시 reshape 해줄 수 있음 . - reshape한 것을 1차원으로 다시 만들어보자 . b=tf.reshape(a,(2,2,-1)) b . &lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]]])&gt; . tf.reshape(b,12) # 기본 . &lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])&gt; . tf.reshape(b,-1) # 응용 . &lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])&gt; . &#49440;&#50616;&#44256;&#44553; . - 대각행렬선언 . - 넘파이로 먼저 만들고 tf.constant( )를 사용하여 자료형 변환 . np.diag([1,2,3]) . array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]) . tf.constant(np.diag([1,2,3])) . &lt;tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[1, 0, 0], [0, 2, 0], [0, 0, 3]])&gt; . - 1으로만 이루어진 텐서 만들기 . tf.ones((3,4)) . &lt;tf.Tensor: shape=(3, 4), dtype=float32, numpy= array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]], dtype=float32)&gt; . tf.ones([3,4]) . &lt;tf.Tensor: shape=(3, 4), dtype=float32, numpy= array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]], dtype=float32)&gt; . tf.reshape([1]*12,(3,4)) . &lt;tf.Tensor: shape=(3, 4), dtype=int32, numpy= array([[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]])&gt; . tf.reshape(tf.constant([1]*12),(3,4)) . &lt;tf.Tensor: shape=(3, 4), dtype=int32, numpy= array([[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]])&gt; . 같은 결과 | . - 0으로만 이루어진 텐서 만들기 . tf.zeros([3,3]) . &lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]], dtype=float32)&gt; . tf.zeros((3,3)) . &lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]], dtype=float32)&gt; . - 리스트로 변환 후 텐서로 변환하지 않고 바로 텐서로 바꾸기 : 즉, a $ to$ list $ to$ tensor - X a $ to$ tensor - O . range(12) . range(0, 12) . a=range(0,12) a? . Type: range String form: range(0, 12) Length: 12 Docstring: range(stop) -&gt; range object range(start, stop[, step]) -&gt; range object Return an object that produces a sequence of integers from start (inclusive) to stop (exclusive) by step. range(i, j) produces i, i+1, i+2, ..., j-1. start defaults to 0, and stop is omitted! range(4) produces 0, 1, 2, 3. These are exactly the valid indices for a list of 4 elements. When step is given, it specifies the increment (or decrement). . range? 가 무엇인지는 모르겠지만, 일단 리스트로 바꿔보자. | . list(a) . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] . list 형태로 변환되었다. | . - 동일한 논리로 range 가 무엇인지는 모르겠지만, tf.constant를 이용하여 텐서형태로 바꿔보자. (tf.constant가 텐서로 변환해주는 기능) . tf.constant(range(0,12)) . &lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])&gt; . tf.constant(range(1,12)) # 1부터 시작 . &lt;tf.Tensor: shape=(11,), dtype=int32, numpy=array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])&gt; . tf.constant(range(2,6)) . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([2, 3, 4, 5])&gt; . tf.constant(range(2,21,2)) # 2칸씩 점프 . &lt;tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 2, 4, 6, 8, 10, 12, 14, 16, 18, 20])&gt; . tf.constant(range(2,21,3)) # 3칸씩 점프 . &lt;tf.Tensor: shape=(7,), dtype=int32, numpy=array([ 2, 5, 8, 11, 14, 17, 20])&gt; . - 등간격 수열 만들기 . tf.linspace(0,1,14) # 0 ~ 1 까지 길이가 14인 수열 만들기 . &lt;tf.Tensor: shape=(14,), dtype=float64, numpy= array([0. , 0.07692308, 0.15384615, 0.23076923, 0.30769231, 0.38461538, 0.46153846, 0.53846154, 0.61538462, 0.69230769, 0.76923077, 0.84615385, 0.92307692, 1. ])&gt; . tf.linspace(-1,20,14) # -1 ~ 20 까지 길이가 14인 수열 . &lt;tf.Tensor: shape=(14,), dtype=float64, numpy= array([-1. , 0.61538462, 2.23076923, 3.84615385, 5.46153846, 7.07692308, 8.69230769, 10.30769231, 11.92307692, 13.53846154, 15.15384615, 16.76923077, 18.38461538, 20. ])&gt; . tf.linspace([0,-1],[14,20],14) # 첫 열: 0~14까지, 두 번째 열: -1~20까지 길이가 14인 수열 . &lt;tf.Tensor: shape=(14, 2), dtype=float64, numpy= array([[ 0. , -1. ], [ 1.07692308, 0.61538462], [ 2.15384615, 2.23076923], [ 3.23076923, 3.84615385], [ 4.30769231, 5.46153846], [ 5.38461538, 7.07692308], [ 6.46153846, 8.69230769], [ 7.53846154, 10.30769231], [ 8.61538462, 11.92307692], [ 9.69230769, 13.53846154], [10.76923077, 15.15384615], [11.84615385, 16.76923077], [12.92307692, 18.38461538], [14. , 20. ]])&gt; . - $14×2$가 아닌 $2×14$ 행렬은? . : axis=1사용 . tf.linspace([0,-1],[1,20],14,axis=1) . &lt;tf.Tensor: shape=(2, 14), dtype=float64, numpy= array([[ 0. , 0.07692308, 0.15384615, 0.23076923, 0.30769231, 0.38461538, 0.46153846, 0.53846154, 0.61538462, 0.69230769, 0.76923077, 0.84615385, 0.92307692, 1. ], [-1. , 0.61538462, 2.23076923, 3.84615385, 5.46153846, 7.07692308, 8.69230769, 10.30769231, 11.92307692, 13.53846154, 15.15384615, 16.76923077, 18.38461538, 20. ]])&gt; . tf.linspace([0,-1],[1,20],14,axis=0) . &lt;tf.Tensor: shape=(14, 2), dtype=float64, numpy= array([[ 0. , -1. ], [ 0.07692308, 0.61538462], [ 0.15384615, 2.23076923], [ 0.23076923, 3.84615385], [ 0.30769231, 5.46153846], [ 0.38461538, 7.07692308], [ 0.46153846, 8.69230769], [ 0.53846154, 10.30769231], [ 0.61538462, 11.92307692], [ 0.69230769, 13.53846154], [ 0.76923077, 15.15384615], [ 0.84615385, 16.76923077], [ 0.92307692, 18.38461538], [ 1. , 20. ]])&gt; . - 랜덤 . tf.random.normal([10]) . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([-2.031805 , 0.0878811 , -0.08389507, -0.4712213 , 1.7228402 , 1.5234696 , -0.45930204, 0.27446908, 0.6777201 , 1.2311221 ], dtype=float32)&gt; . tf.random.normal(10) . InvalidArgumentError Traceback (most recent call last) Input In [131], in &lt;cell line: 1&gt;() -&gt; 1 tf.random.normal(10) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: shape must be a vector of {int32,int64}, got shape [] [Op:RandomStandardNormal] . 위와 같이 하면 오류가 남 | . tf.random.normal([3,3]) . &lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[-0.67909116, 1.6647867 , -1.1921434 ], [-0.41828915, -1.007226 , -0.37517777], [-0.35723418, -0.90447557, -0.21201086]], dtype=float32)&gt; . tf.random.uniform([3,3]) . &lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[0.49846053, 0.53244936, 0.37250876], [0.5088717 , 0.01882815, 0.50129974], [0.8890096 , 0.7716527 , 0.68743026]], dtype=float32)&gt; . - numpy를 이용한 자료형 변환 . a=np.random.randn(10) a . array([ 1.42470939, -0.43431904, 0.35631914, -0.83401698, 0.98403914, 0.03123622, 0.3625249 , 0.45672775, 0.51236327, 0.74739683]) . list(a) # 일단 리스트로 변환해 봄 . [1.4247093944590954, -0.4343190394693054, 0.35631913687969213, -0.8340169822900257, 0.9840391372400604, 0.031236220641082953, 0.36252489894658657, 0.4567277510989872, 0.5123632705088501, 0.7473968310235103] . tf.constant(a) . &lt;tf.Tensor: shape=(10,), dtype=float64, numpy= array([ 1.42470939, -0.43431904, 0.35631914, -0.83401698, 0.98403914, 0.03123622, 0.3625249 , 0.45672775, 0.51236327, 0.74739683])&gt; . - tf.random이 numpy에 있는 모든 기능을 구현하는 것은 아님. . np.random.randn(10) . array([-0.37923556, 1.89366845, -0.60768019, 0.89680048, -0.11687065, -0.67507322, 3.45690649, 0.13774121, 0.5305251 , -0.37030568]) . tf.random.randn([10]) . AttributeError Traceback (most recent call last) Input In [143], in &lt;cell line: 1&gt;() -&gt; 1 tf.random.randn([10]) AttributeError: module &#39;tensorflow._api.v2.random&#39; has no attribute &#39;randn&#39; . tf.concat . tf.concat 사용법: 축 지정이 매우 헷갈리기 때문에 외우는 게 필요함 python은 0부터 시작하기 때문에 첫 번째 축이 0을 의미, 두 번째 축이 1을 의미, 세 번째 축이 2를 의미한다. (2차원에선) 함수 축을 그릴 때 가로를 그린 후 세로를 그리기 때문에 첫 번째 축이 가로, 두 번째 축이 세로를 의미한다. (2차원에선) 따라서 axis=0은 가로로 쌓는다는 것(아래로 계속해서)을 의미하고 axis=1은 세로로 쌓는다는 것(옆으로 계속해서)을 의미한다. 3차원부터는 앞서 정리한 것처럼 첫 번째 축-0, 두 번째 축-1, 세 번째 축-2 으로 외우는 것이 좋다. . - $2×1$ 벡터와 $2×1$ 벡터를 concat해서 $2×2$ 벡터로 만든다 . a=tf.constant([[1],[2]]) b=tf.constant([[3],[4]]) . a,b . (&lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy= array([[1], [2]])&gt;, &lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy= array([[3], [4]])&gt;) . tf.concat([a,b]) . TypeError Traceback (most recent call last) Input In [151], in &lt;cell line: 1&gt;() -&gt; 1 tf.concat([a,b]) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util dispatch.py:1076, in add_dispatch_support.&lt;locals&gt;.decorator.&lt;locals&gt;.op_dispatch_handler(*args, **kwargs) 1074 if iterable_params is not None: 1075 args, kwargs = replace_iterable_params(args, kwargs, iterable_params) -&gt; 1076 result = api_dispatcher.Dispatch(args, kwargs) 1077 if result is not NotImplemented: 1078 return result TypeError: Missing required positional argument . - concat을 사용할 때는 축을 반드시 지정해주어야 한다. 그렇지 않으면 위와 같이 오류가 뜬다. . tf.concat([a,b],axis=1) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 3], [2, 4]])&gt; . - $2×1$ 벡터와 $2×1$ 벡터를 concat해서 $4×1$ 벡터로 만든다 . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(4, 1), dtype=int32, numpy= array([[1], [2], [3], [4]])&gt; . - $1×2$ 벡터와 $1×2$ 벡터를 concat해서 $2×2$ 벡터로 만든다 . a=tf.constant([1,2]) b=tf.constant([3,4]) a,b . (&lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2])&gt;, &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4])&gt;) . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])&gt; . 의도하지 않은 결과가 나타나는 이유? : 전체 축에 대한 [ ]를 입력해주지 않았기 때문....... | . a=tf.constant([[1,2]]) b=tf.constant([[3,4]]) a,b . (&lt;tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[1, 2]])&gt;, &lt;tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[3, 4]])&gt;) . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]])&gt; . - $1×2$ 벡터와 $1×2$ 벡터를 concat해서 $1×4$ 벡터로 만든다 . tf.concat([a,b],axis=1) . &lt;tf.Tensor: shape=(1, 4), dtype=int32, numpy=array([[1, 2, 3, 4]])&gt; . axis=0은 아래로 쌓이고 axis=1은 옆으로 쌓인다고 기억하자. | . - 3차원으로 확장해보자 : 첫 번째 축이 무엇인지 파악하는 것이 중요함 ! 다음 예제에서 첫 번째 축은 $2×3$행렬이 두 개 있는 3차원 축을 의미함 . a=tf.reshape(tf.constant(range(12)),(2,2,3)) b=-a a,b . (&lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]]])&gt;, &lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy= array([[[ 0, -1, -2], [ -3, -4, -5]], [[ -6, -7, -8], [ -9, -10, -11]]])&gt;) . - $2×2×3$ 벡터와 $2×2×3$ 벡터를 concat해서 $4×2×3$ 벡터로 만든다 . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(4, 2, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]], [[ 0, -1, -2], [ -3, -4, -5]], [[ -6, -7, -8], [ -9, -10, -11]]])&gt; . 합치고자 하는 것이 첫 번째 축이기 때문에 axis=0을 이용한다 | . - $2×2×3$ 벡터와 $2×2×3$ 벡터를 concat해서 $2×4×3$ 벡터로 만든다 . tf.concat([a,b],axis=1) . &lt;tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5], [ 0, -1, -2], [ -3, -4, -5]], [[ 6, 7, 8], [ 9, 10, 11], [ -6, -7, -8], [ -9, -10, -11]]])&gt; . 합치고자 하는 것이 두 번째 축이기 때문에 axis=1을 이용한다 | . - $2×2×3$ 벡터와 $2×2×3$ 벡터를 concat해서 $2×2×6$ 벡터로 만든다 . tf.concat([a,b],axis=2) . &lt;tf.Tensor: shape=(2, 2, 6), dtype=int32, numpy= array([[[ 0, 1, 2, 0, -1, -2], [ 3, 4, 5, -3, -4, -5]], [[ 6, 7, 8, -6, -7, -8], [ 9, 10, 11, -9, -10, -11]]])&gt; . 합치고자 하는 것이 세 번째 축이기 때문에 axis=2를 이용한다. | . - 다른 가능한 방법 . tf.concat([a,b],axis=-1) . &lt;tf.Tensor: shape=(2, 2, 6), dtype=int32, numpy= array([[[ 0, 1, 2, 0, -1, -2], [ 3, 4, 5, -3, -4, -5]], [[ 6, 7, 8, -6, -7, -8], [ 9, 10, 11, -9, -10, -11]]])&gt; . 이는 axis=2와 같다. 이는 -1이 뒤에서 첫번째 숫자를 의미하고 2가 뒤에서 첫번째 숫자(마지막 숫자)이기 때문이다 | . tf.concat([a,b],axis=1) . &lt;tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5], [ 0, -1, -2], [ -3, -4, -5]], [[ 6, 7, 8], [ 9, 10, 11], [ -6, -7, -8], [ -9, -10, -11]]])&gt; . tf.concat([a,b],axis=-2) . &lt;tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5], [ 0, -1, -2], [ -3, -4, -5]], [[ 6, 7, 8], [ 9, 10, 11], [ -6, -7, -8], [ -9, -10, -11]]])&gt; . 마찬가지로 위 두 코드는 같은 결과를 나타낸다. | . - $(4,)$와 $(4,)$ concat $(8,)$ . a=tf.constant([1,2,3,4]) b=-a a,b . (&lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])&gt;, &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4])&gt;) . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(8,), dtype=int32, numpy=array([ 1, 2, 3, 4, -1, -2, -3, -4])&gt; . tf.concat([a,b],axis=1) . InvalidArgumentError Traceback (most recent call last) Input In [191], in &lt;cell line: 1&gt;() -&gt; 1 tf.concat([a,b],axis=1) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: ConcatOp : Expected concatenating dimensions in the range [-1, 1), but got 1 [Op:ConcatV2] name: concat . axis=0 으로 하면 $2×4$벡터가 만들어져야 하는 거 아닌가? | 즉, axis=1로 해야 길이가 $8$인 벡터가 만들어지는 거 아닌가? | 그런데 심지어 axis=1은 오류까지 뜬다?! | . 이유: $(4,),(4,),(8,)$은 길이가 각각 4,4,8인 튜플(1차원)이기에 애초에 축이 1개만 존재했기 때문이다. 즉 축이 2개가 존재하지 않기에 axis=1은 오류가 나고 축이 하나만 존재(1차원 형태)하기에 axis=0만 가능하다. 따라서 $2×4$ 또는 $4×2$(2차원 형태)는 애초에 불가능하다. | . tf.concat은 dimension(차원)을 변환시킬 수 없다. | . 즉, one dimension $ to$ 결과 one, two dimension $ to$ 결과 two, three dimension $ to$ 결과 three . dimension(차원)을 변환시키려면 다음과 같이 tf.stack을 사용해야 한다. . tf.stack . - $(4)$ 벡터와 $(4)$ 벡터를 concat해서 $(4,2)$ 벡터로 만든다 . $(4, )$ stack $(4, )$ $ to$ $(4,2)$ : 두 번째 축을 비어있다고 인식 | . a=tf.stack([1,2,3,4]) b=-a a,b . (&lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])&gt;, &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4])&gt;) . tf.stack? . Signature: tf.stack(values, axis=0, name=&#39;stack&#39;) Docstring: Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor. See also `tf.concat`, `tf.tile`, `tf.repeat`. Packs the list of tensors in `values` into a tensor with rank one higher than each tensor in `values`, by packing them along the `axis` dimension. Given a list of length `N` of tensors of shape `(A, B, C)`; if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`. if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`. Etc. For example: &gt;&gt;&gt; x = tf.constant([1, 4]) &gt;&gt;&gt; y = tf.constant([2, 5]) &gt;&gt;&gt; z = tf.constant([3, 6]) &gt;&gt;&gt; tf.stack([x, y, z]) &lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy= array([[1, 4], [2, 5], [3, 6]], dtype=int32)&gt; &gt;&gt;&gt; tf.stack([x, y, z], axis=1) &lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy= array([[1, 2, 3], [4, 5, 6]], dtype=int32)&gt; This is the opposite of unstack. The numpy equivalent is `np.stack` &gt;&gt;&gt; np.array_equal(np.stack([x, y, z]), tf.stack([x, y, z])) True Args: values: A list of `Tensor` objects with the same shape and type. axis: An `int`. The axis to stack along. Defaults to the first dimension. Negative values wrap around, so the valid range is `[-(R+1), R+1)`. name: A name for this operation (optional). Returns: output: A stacked `Tensor` with the same type as `values`. Raises: ValueError: If `axis` is out of the range [-(R+1), R+1). File: c: users kko anaconda3 envs ds2022 lib site-packages tensorflow python ops array_ops.py Type: function . tf.stack()은 default가 axis=0이다 | . tf.stack([a,b]) . &lt;tf.Tensor: shape=(2, 4), dtype=int32, numpy= array([[ 1, 2, 3, 4], [-1, -2, -3, -4]])&gt; . tf.stack([a,b],axis=0) . &lt;tf.Tensor: shape=(2, 4), dtype=int32, numpy= array([[ 1, 2, 3, 4], [-1, -2, -3, -4]])&gt; . 따라서 위 두 코드가 같다 | . tf.stack([a,b],axis=1) . &lt;tf.Tensor: shape=(4, 2), dtype=int32, numpy= array([[ 1, -1], [ 2, -2], [ 3, -3], [ 4, -4]])&gt; . - $(4)$ 벡터와 $(4)$ 벡터를 concat해서 $(4,2)$ 벡터로 만든다 . $(4, )$ stack $(4, )$ $ to$ $(4,2)$ : 두 번째 축을 비어있다고 인식 | . tf.stack([a,b],axis=0) . &lt;tf.Tensor: shape=(2, 4), dtype=int32, numpy= array([[ 1, 2, 3, 4], [-1, -2, -3, -4]])&gt; . - (2,3,4,5) stack (2,3,4,5) $ to$ (2,2,3,4,5) : 첫 번째 축이 비어있다고 인식 . a=tf.reshape(tf.constant(range(2*3*4*5)),(2,3,4,5)) b=-a a,b . (&lt;tf.Tensor: shape=(2, 3, 4, 5), dtype=int32, numpy= array([[[[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [ 10, 11, 12, 13, 14], [ 15, 16, 17, 18, 19]], [[ 20, 21, 22, 23, 24], [ 25, 26, 27, 28, 29], [ 30, 31, 32, 33, 34], [ 35, 36, 37, 38, 39]], [[ 40, 41, 42, 43, 44], [ 45, 46, 47, 48, 49], [ 50, 51, 52, 53, 54], [ 55, 56, 57, 58, 59]]], [[[ 60, 61, 62, 63, 64], [ 65, 66, 67, 68, 69], [ 70, 71, 72, 73, 74], [ 75, 76, 77, 78, 79]], [[ 80, 81, 82, 83, 84], [ 85, 86, 87, 88, 89], [ 90, 91, 92, 93, 94], [ 95, 96, 97, 98, 99]], [[100, 101, 102, 103, 104], [105, 106, 107, 108, 109], [110, 111, 112, 113, 114], [115, 116, 117, 118, 119]]]])&gt;, &lt;tf.Tensor: shape=(2, 3, 4, 5), dtype=int32, numpy= array([[[[ 0, -1, -2, -3, -4], [ -5, -6, -7, -8, -9], [ -10, -11, -12, -13, -14], [ -15, -16, -17, -18, -19]], [[ -20, -21, -22, -23, -24], [ -25, -26, -27, -28, -29], [ -30, -31, -32, -33, -34], [ -35, -36, -37, -38, -39]], [[ -40, -41, -42, -43, -44], [ -45, -46, -47, -48, -49], [ -50, -51, -52, -53, -54], [ -55, -56, -57, -58, -59]]], [[[ -60, -61, -62, -63, -64], [ -65, -66, -67, -68, -69], [ -70, -71, -72, -73, -74], [ -75, -76, -77, -78, -79]], [[ -80, -81, -82, -83, -84], [ -85, -86, -87, -88, -89], [ -90, -91, -92, -93, -94], [ -95, -96, -97, -98, -99]], [[-100, -101, -102, -103, -104], [-105, -106, -107, -108, -109], [-110, -111, -112, -113, -114], [-115, -116, -117, -118, -119]]]])&gt;) . tf.stack([a,b],axis=0) . &lt;tf.Tensor: shape=(2, 2, 3, 4, 5), dtype=int32, numpy= array([[[[[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [ 10, 11, 12, 13, 14], [ 15, 16, 17, 18, 19]], [[ 20, 21, 22, 23, 24], [ 25, 26, 27, 28, 29], [ 30, 31, 32, 33, 34], [ 35, 36, 37, 38, 39]], [[ 40, 41, 42, 43, 44], [ 45, 46, 47, 48, 49], [ 50, 51, 52, 53, 54], [ 55, 56, 57, 58, 59]]], [[[ 60, 61, 62, 63, 64], [ 65, 66, 67, 68, 69], [ 70, 71, 72, 73, 74], [ 75, 76, 77, 78, 79]], [[ 80, 81, 82, 83, 84], [ 85, 86, 87, 88, 89], [ 90, 91, 92, 93, 94], [ 95, 96, 97, 98, 99]], [[ 100, 101, 102, 103, 104], [ 105, 106, 107, 108, 109], [ 110, 111, 112, 113, 114], [ 115, 116, 117, 118, 119]]]], [[[[ 0, -1, -2, -3, -4], [ -5, -6, -7, -8, -9], [ -10, -11, -12, -13, -14], [ -15, -16, -17, -18, -19]], [[ -20, -21, -22, -23, -24], [ -25, -26, -27, -28, -29], [ -30, -31, -32, -33, -34], [ -35, -36, -37, -38, -39]], [[ -40, -41, -42, -43, -44], [ -45, -46, -47, -48, -49], [ -50, -51, -52, -53, -54], [ -55, -56, -57, -58, -59]]], [[[ -60, -61, -62, -63, -64], [ -65, -66, -67, -68, -69], [ -70, -71, -72, -73, -74], [ -75, -76, -77, -78, -79]], [[ -80, -81, -82, -83, -84], [ -85, -86, -87, -88, -89], [ -90, -91, -92, -93, -94], [ -95, -96, -97, -98, -99]], [[-100, -101, -102, -103, -104], [-105, -106, -107, -108, -109], [-110, -111, -112, -113, -114], [-115, -116, -117, -118, -119]]]]])&gt; . - (2,3,4,5) stack (2,3,4,5) . 두 번째 축이 비어있다고 인식 | (2,?,3,4,5) stack (2,?,3,4,5) $ to$ (2,2,3,4,5) | . tf.stack([a,b],axis=1) . &lt;tf.Tensor: shape=(2, 2, 3, 4, 5), dtype=int32, numpy= array([[[[[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [ 10, 11, 12, 13, 14], [ 15, 16, 17, 18, 19]], [[ 20, 21, 22, 23, 24], [ 25, 26, 27, 28, 29], [ 30, 31, 32, 33, 34], [ 35, 36, 37, 38, 39]], [[ 40, 41, 42, 43, 44], [ 45, 46, 47, 48, 49], [ 50, 51, 52, 53, 54], [ 55, 56, 57, 58, 59]]], [[[ 0, -1, -2, -3, -4], [ -5, -6, -7, -8, -9], [ -10, -11, -12, -13, -14], [ -15, -16, -17, -18, -19]], [[ -20, -21, -22, -23, -24], [ -25, -26, -27, -28, -29], [ -30, -31, -32, -33, -34], [ -35, -36, -37, -38, -39]], [[ -40, -41, -42, -43, -44], [ -45, -46, -47, -48, -49], [ -50, -51, -52, -53, -54], [ -55, -56, -57, -58, -59]]]], [[[[ 60, 61, 62, 63, 64], [ 65, 66, 67, 68, 69], [ 70, 71, 72, 73, 74], [ 75, 76, 77, 78, 79]], [[ 80, 81, 82, 83, 84], [ 85, 86, 87, 88, 89], [ 90, 91, 92, 93, 94], [ 95, 96, 97, 98, 99]], [[ 100, 101, 102, 103, 104], [ 105, 106, 107, 108, 109], [ 110, 111, 112, 113, 114], [ 115, 116, 117, 118, 119]]], [[[ -60, -61, -62, -63, -64], [ -65, -66, -67, -68, -69], [ -70, -71, -72, -73, -74], [ -75, -76, -77, -78, -79]], [[ -80, -81, -82, -83, -84], [ -85, -86, -87, -88, -89], [ -90, -91, -92, -93, -94], [ -95, -96, -97, -98, -99]], [[-100, -101, -102, -103, -104], [-105, -106, -107, -108, -109], [-110, -111, -112, -113, -114], [-115, -116, -117, -118, -119]]]]])&gt; . - (2,3,4,5) stack (2,3,4,5) . 마지막 축이 비어있다고 인식 | (2,3,4,5,?) stack (2,3,4,5,?) $ to$ (2,3,4,5,2) | . tf.stack([a,b],axis=-1) . &lt;tf.Tensor: shape=(2, 3, 4, 5, 2), dtype=int32, numpy= array([[[[[ 0, 0], [ 1, -1], [ 2, -2], [ 3, -3], [ 4, -4]], [[ 5, -5], [ 6, -6], [ 7, -7], [ 8, -8], [ 9, -9]], [[ 10, -10], [ 11, -11], [ 12, -12], [ 13, -13], [ 14, -14]], [[ 15, -15], [ 16, -16], [ 17, -17], [ 18, -18], [ 19, -19]]], [[[ 20, -20], [ 21, -21], [ 22, -22], [ 23, -23], [ 24, -24]], [[ 25, -25], [ 26, -26], [ 27, -27], [ 28, -28], [ 29, -29]], [[ 30, -30], [ 31, -31], [ 32, -32], [ 33, -33], [ 34, -34]], [[ 35, -35], [ 36, -36], [ 37, -37], [ 38, -38], [ 39, -39]]], [[[ 40, -40], [ 41, -41], [ 42, -42], [ 43, -43], [ 44, -44]], [[ 45, -45], [ 46, -46], [ 47, -47], [ 48, -48], [ 49, -49]], [[ 50, -50], [ 51, -51], [ 52, -52], [ 53, -53], [ 54, -54]], [[ 55, -55], [ 56, -56], [ 57, -57], [ 58, -58], [ 59, -59]]]], [[[[ 60, -60], [ 61, -61], [ 62, -62], [ 63, -63], [ 64, -64]], [[ 65, -65], [ 66, -66], [ 67, -67], [ 68, -68], [ 69, -69]], [[ 70, -70], [ 71, -71], [ 72, -72], [ 73, -73], [ 74, -74]], [[ 75, -75], [ 76, -76], [ 77, -77], [ 78, -78], [ 79, -79]]], [[[ 80, -80], [ 81, -81], [ 82, -82], [ 83, -83], [ 84, -84]], [[ 85, -85], [ 86, -86], [ 87, -87], [ 88, -88], [ 89, -89]], [[ 90, -90], [ 91, -91], [ 92, -92], [ 93, -93], [ 94, -94]], [[ 95, -95], [ 96, -96], [ 97, -97], [ 98, -98], [ 99, -99]]], [[[ 100, -100], [ 101, -101], [ 102, -102], [ 103, -103], [ 104, -104]], [[ 105, -105], [ 106, -106], [ 107, -107], [ 108, -108], [ 109, -109]], [[ 110, -110], [ 111, -111], [ 112, -112], [ 113, -113], [ 114, -114]], [[ 115, -115], [ 116, -116], [ 117, -117], [ 118, -118], [ 119, -119]]]]])&gt; . 3&#44060;&#51032; array&#44032; &#51080;&#51012; &#44221;&#50864; . - 예제1: (2,3,4), (2,3,4), (2,3,4) 1) (2,3,4), (2,3,4), (2,3,4) -&gt; (6,3,4) . a=tf.reshape(tf.constant(range(2*3*4)),(2,3,4)) b=-a c=2*a . a, b, c 모두 3차원이고 나타내고자 하는 것도 3차원이니 차원이 늘어나는 것은 아니다 -&gt; tf.stack가 아닌 tf.concat을 사용 . tf.concat([a,b,c],axis=0) . &lt;tf.Tensor: shape=(6, 3, 4), dtype=int32, numpy= array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[ 12, 13, 14, 15], [ 16, 17, 18, 19], [ 20, 21, 22, 23]], [[ 0, -1, -2, -3], [ -4, -5, -6, -7], [ -8, -9, -10, -11]], [[-12, -13, -14, -15], [-16, -17, -18, -19], [-20, -21, -22, -23]], [[ 0, 2, 4, 6], [ 8, 10, 12, 14], [ 16, 18, 20, 22]], [[ 24, 26, 28, 30], [ 32, 34, 36, 38], [ 40, 42, 44, 46]]])&gt; . 6×3×4가 되었음 | . - 2. (2,3,4), (2,3,4), (2,3,4) -&gt; (2,9,4) . tf.concat([a,b,c],axis=1) . &lt;tf.Tensor: shape=(2, 9, 4), dtype=int32, numpy= array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [ 0, -1, -2, -3], [ -4, -5, -6, -7], [ -8, -9, -10, -11], [ 0, 2, 4, 6], [ 8, 10, 12, 14], [ 16, 18, 20, 22]], [[ 12, 13, 14, 15], [ 16, 17, 18, 19], [ 20, 21, 22, 23], [-12, -13, -14, -15], [-16, -17, -18, -19], [-20, -21, -22, -23], [ 24, 26, 28, 30], [ 32, 34, 36, 38], [ 40, 42, 44, 46]]])&gt; . - 3. (2,3,4), (2,3,4), (2,3,4) -&gt; (2,3,12) . tf.concat([a,b,c],axis=2) . &lt;tf.Tensor: shape=(2, 3, 12), dtype=int32, numpy= array([[[ 0, 1, 2, 3, 0, -1, -2, -3, 0, 2, 4, 6], [ 4, 5, 6, 7, -4, -5, -6, -7, 8, 10, 12, 14], [ 8, 9, 10, 11, -8, -9, -10, -11, 16, 18, 20, 22]], [[ 12, 13, 14, 15, -12, -13, -14, -15, 24, 26, 28, 30], [ 16, 17, 18, 19, -16, -17, -18, -19, 32, 34, 36, 38], [ 20, 21, 22, 23, -20, -21, -22, -23, 40, 42, 44, 46]]])&gt; . - 예제2: (2,3,4), (2,3,4), (2,3,4) 1) (2,3,4), (2,3,4), (2,3,4) -&gt; (3,2,3,4) -&gt; axis=0 . a, b, c 모두 3차원이지만 나타내고자 하는 것은 4차원이니 차원이 늘어난다 -&gt; tf.stack 사용 . tf.stack([a,b,c],axis=0) . &lt;tf.Tensor: shape=(3, 2, 3, 4), dtype=int32, numpy= array([[[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[ 12, 13, 14, 15], [ 16, 17, 18, 19], [ 20, 21, 22, 23]]], [[[ 0, -1, -2, -3], [ -4, -5, -6, -7], [ -8, -9, -10, -11]], [[-12, -13, -14, -15], [-16, -17, -18, -19], [-20, -21, -22, -23]]], [[[ 0, 2, 4, 6], [ 8, 10, 12, 14], [ 16, 18, 20, 22]], [[ 24, 26, 28, 30], [ 32, 34, 36, 38], [ 40, 42, 44, 46]]]])&gt; . 2) (2,3,4), (2,3,4), (2,3,4) -&gt; (2,3,3,4) -&gt; axis=1 . tf.stack([a,b,c],axis=1) . &lt;tf.Tensor: shape=(2, 3, 3, 4), dtype=int32, numpy= array([[[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[ 0, -1, -2, -3], [ -4, -5, -6, -7], [ -8, -9, -10, -11]], [[ 0, 2, 4, 6], [ 8, 10, 12, 14], [ 16, 18, 20, 22]]], [[[ 12, 13, 14, 15], [ 16, 17, 18, 19], [ 20, 21, 22, 23]], [[-12, -13, -14, -15], [-16, -17, -18, -19], [-20, -21, -22, -23]], [[ 24, 26, 28, 30], [ 32, 34, 36, 38], [ 40, 42, 44, 46]]]])&gt; . 3) (2,3,4), (2,3,4), (2,3,4) -&gt; (2,3,3,4) -&gt; axis=2 . tf.stack([a,b,c],axis=2) . &lt;tf.Tensor: shape=(2, 3, 3, 4), dtype=int32, numpy= array([[[[ 0, 1, 2, 3], [ 0, -1, -2, -3], [ 0, 2, 4, 6]], [[ 4, 5, 6, 7], [ -4, -5, -6, -7], [ 8, 10, 12, 14]], [[ 8, 9, 10, 11], [ -8, -9, -10, -11], [ 16, 18, 20, 22]]], [[[ 12, 13, 14, 15], [-12, -13, -14, -15], [ 24, 26, 28, 30]], [[ 16, 17, 18, 19], [-16, -17, -18, -19], [ 32, 34, 36, 38]], [[ 20, 21, 22, 23], [-20, -21, -22, -23], [ 40, 42, 44, 46]]]])&gt; . 4) (2,3,4), (2,3,4), (2,3,4) -&gt; (2,3,4,3) -&gt; axis=3 . tf.stack([a,b,c],axis=3) . &lt;tf.Tensor: shape=(2, 3, 4, 3), dtype=int32, numpy= array([[[[ 0, 0, 0], [ 1, -1, 2], [ 2, -2, 4], [ 3, -3, 6]], [[ 4, -4, 8], [ 5, -5, 10], [ 6, -6, 12], [ 7, -7, 14]], [[ 8, -8, 16], [ 9, -9, 18], [ 10, -10, 20], [ 11, -11, 22]]], [[[ 12, -12, 24], [ 13, -13, 26], [ 14, -14, 28], [ 15, -15, 30]], [[ 16, -16, 32], [ 17, -17, 34], [ 18, -18, 36], [ 19, -19, 38]], [[ 20, -20, 40], [ 21, -21, 42], [ 22, -22, 44], [ 23, -23, 46]]]])&gt; . - 예제3: (2,3,4), (4,3,4) -&gt; (6,3,4) . a=tf.reshape(tf.constant(range(2*3*4)),(2,3,4)) b=tf.reshape(-tf.constant(range(4*3*4)),(4,3,4)) . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(6, 3, 4), dtype=int32, numpy= array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[ 12, 13, 14, 15], [ 16, 17, 18, 19], [ 20, 21, 22, 23]], [[ 0, -1, -2, -3], [ -4, -5, -6, -7], [ -8, -9, -10, -11]], [[-12, -13, -14, -15], [-16, -17, -18, -19], [-20, -21, -22, -23]], [[-24, -25, -26, -27], [-28, -29, -30, -31], [-32, -33, -34, -35]], [[-36, -37, -38, -39], [-40, -41, -42, -43], [-44, -45, -46, -47]]])&gt; . tf.concat([a,b],axis=1) . InvalidArgumentError Traceback (most recent call last) Input In [22], in &lt;cell line: 1&gt;() -&gt; 1 tf.concat([a,b],axis=1) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: ConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [2,3,4] vs. shape[1] = [4,3,4] [Op:ConcatV2] name: concat . tf.concat([a,b],axis=2) . InvalidArgumentError Traceback (most recent call last) Input In [23], in &lt;cell line: 1&gt;() -&gt; 1 tf.concat([a,b],axis=2) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: ConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [2,3,4] vs. shape[1] = [4,3,4] [Op:ConcatV2] name: concat . 위 두 코드는 차원이 맞지 않아 오류가 난다. | .",
            "url": "https://ki5n2.github.io/charcoal/2022/03/18/DS.html",
            "relUrl": "/2022/03/18/DS.html",
            "date": " • Mar 18, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "DS 1. 단순선형회귀",
            "content": ". Data Science . lenture: Data Science_1nd week of lectures. | lenture date: 2022-03-07 | lecturer: Guebin choi | study date: 2022-03-16 | author: Kione kim | . . 이번 학기동안 배울 것: DNN(심층신경망), CNN(합성곱신경망), GAN(적대적생성신경망)인데, DNN을 바로 이해하기 어렵다. . | 따라서 다음의 과정을 학습한 후 심층 신경망으로 넘어갈 예정: (선형대수학 $ to$) 회귀분석 $ to$ 로지스틱회귀분석 $ to$ 심층신경망 . | . &#49440;&#54805;&#54924;&#44480; . - 카페 예제 . 온도가 높아지면 아이스아메리카노의 판매량이 증가한다는 사실을 알게 되었다. | 일기예보를 통해, 온도 $ to$ 아이스아메리카노 판매량 예측을 하고 싶다. | . import matplotlib.pyplot as plt import tensorflow as tf import numpy as np . - 자료생성 . x=tf.constant([20.1,22.2,22.7,23.3,24.4,25.1,26.2,27.3,28.4,30.4]) x . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4], dtype=float32)&gt; . x와 y의 관계는 다음과 같이 가정 $${ bf y} approx 10.2 + 2.2{ bf x}$$ . tf.random.set_seed(50000) epsilon = tf.random.normal([10]) y = 10.2 + 2.2*x + epsilon y . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([53.68625 , 60.12511 , 58.93714 , 60.65312 , 64.45385 , 66.9807 , 67.960144, 70.73565 , 72.87779 , 77.54677 ], dtype=float32)&gt; . x . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4], dtype=float32)&gt; . y . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([53.68625 , 60.12511 , 58.93714 , 60.65312 , 64.45385 , 66.9807 , 67.960144, 70.73565 , 72.87779 , 77.54677 ], dtype=float32)&gt; . data = tf.transpose(tf.concat([[x],[y]],0)) data . &lt;tf.Tensor: shape=(10, 2), dtype=float32, numpy= array([[20.1 , 53.68625 ], [22.2 , 60.12511 ], [22.7 , 58.93714 ], [23.3 , 60.65312 ], [24.4 , 64.45385 ], [25.1 , 66.9807 ], [26.2 , 67.960144], [27.3 , 70.73565 ], [28.4 , 72.87779 ], [30.4 , 77.54677 ]], dtype=float32)&gt; . plt.plot(x,y,&#39;.&#39;) plt.plot(x,10.2+2.2*x,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x1a1b1b0d340&gt;] . 파란색 점: 데이터, 주황색 점선: 법칙 | 위 그림을 보니 $x$와 $y$가 선형관계가 있는 것처럼 보인다. 즉 아래의 식을 만족하는 $ beta_0, beta_1$가 있을 것 같다. | $y_{i} approx beta_1 x_{i}+ beta_0$ | . data . &lt;tf.Tensor: shape=(10, 2), dtype=float32, numpy= array([[20.1 , 53.68625 ], [22.2 , 60.12511 ], [22.7 , 58.93714 ], [23.3 , 60.65312 ], [24.4 , 64.45385 ], [25.1 , 66.9807 ], [26.2 , 67.960144], [27.3 , 70.73565 ], [28.4 , 72.87779 ], [30.4 , 77.54677 ]], dtype=float32)&gt; . - 점원 A는 $ beta_0=15, beta_1=2$일 것이라고 주장하였고 점원 B는 $ beta_0=15.5, beta_1=2$일 것이라고 주장하였다. . 점원 A: $( beta_0, beta_1)$ = $(15,2)$ | 점원 B: $( beta_0, beta_1)$ = $(15.5,2)$ | . &#51092;&#52264;&#51228;&#44273;&#54633; . - $y_{i} approx beta_0 + beta_1$을 최소로 하는 $( beta_0, beta_1)$을 찾아보자 . - 잔체제곱합을 통한 점원 A, 점원 B 추정치 비교 . 20.1*2 + 15, 53.68625 . (55.2, 53.68625) . 22.2*2 + 15, 60.12511 . (59.4, 60.12511) . 20.1*2 + 15.5, 53.68625 . (55.7, 53.68625) . 22.2*2 + 15.5, 60.12511 . (59.9, 60.12511) . $i=1$일 때 점원 A의 주장이 더 잘 맞고 $i=2$일 때 점원 B의 주장이 더 잘 맞는다. | . - for 문을 사용하여 $ sum_{i=1}^{10} (y_i - beta_0 - beta_1 x_i)^2$를 계산하여 비교해보자 . sum1=0 for i in range(10): sum1=sum1+(y[i]-15-2*x[i])**2 . sum2=0 for i in range(10): sum2=sum2+(y[i]-15.5-2*x[i])**2 . sum1 . &lt;tf.Tensor: shape=(), dtype=float32, numpy=15.268475&gt; . sum2 . &lt;tf.Tensor: shape=(), dtype=float32, numpy=14.011955&gt; . 점원 B의 추정치의 잔차제곱합이 조금 더 작다 $ to$ 점원 B의 주장이 더 적합하다 | 이 과정을 반복하면 최적의 추정치를 계산해낼 수 있을 것 같다. | . - 그러나 현실적으로 구현하기 어렵다 . : 왜냐하면 잔차제곱합이 0이 되지 않는다면, 무엇이 최적의 추정치인지 알 수 없다. 잔차제곱합이 0이 아니라면 항상 더 적합한 추정치가 있을 수도 있기 때문 . - 수식을 활용하여 찾아볼 수 있다 . $ sum_{i=1}^{10} (y_i - beta_0 - beta_1 x_i)^2$를 최소화하는 $ beta_0, beta_1$을 찾으면 되는데, 이는 아래와 같이 $ beta_0, beta_1$으로 각각 편미분하여 연립하여 풀면 된다. . $ begin{cases} frac{ partial}{ partial beta_0} sum_{i=1}^{10} (y_i - beta_0 - beta_1 x_i)^2=0 frac{ partial}{ partial beta_1} sum_{i=1}^{10} (y_i - beta_0 - beta_1 x_i)^2=0 end{cases}$ . 위 연립방정식을 편미분하면 다음과 같이 된다. . $ begin{cases} sum_{i=1}^{10} -2(y_i - beta_0 - beta_1 x_i)=0 sum_{i=1}^{10} -2x_i(y_i - beta_0 - beta_1 x_i)=0 end{cases}$ . 이를 정리하면 . $$ hat{ beta}_0= bar{y}- hat{ beta}_1 bar{x}$$ . $$ hat{ beta}_1= frac{S_{xy}}{S_{xx}}= frac{ sum_{i=1}^{n}(x_i- bar{x})(y_i- bar{y})}{ sum_{i=1}^{n}(x_i- bar{x})^2}$$ . 최적의 추정치$( hat{ beta}_0, hat{ beta}_1)$를 구할 수 있고 이를 통해 추세선을 그려볼 수 있다 . - 추정치는 다음과 같이 구할 수 있다. . Sxx = sum((x-np.mean(x))**2) Sxx . &lt;tf.Tensor: shape=(), dtype=float32, numpy=87.84898&gt; . Sxy = sum((x-np.mean(x))*(y-np.mean(y))) Sxy . &lt;tf.Tensor: shape=(), dtype=float32, numpy=202.18872&gt; . beta_1_est = Sxy/Sxx beta_1_est . &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.3015487&gt; . beta_0_est = np.mean(y) - beta_1_est*np.mean(x) beta_0_est . &lt;tf.Tensor: shape=(), dtype=float32, numpy=7.8339195&gt; . - 그림을 그려보자 . plt.plot(x,y,&#39;.&#39;) plt.plot(x,beta_0_est + beta_1_est*x,&#39;--&#39;) plt.plot(x,10.2+2.2*x,&#39;--&#39;) # 세상의 법칙 . [&lt;matplotlib.lines.Line2D at 0x1a1b1b5cee0&gt;] . - 샘플수가 커질수록 주황색 선은 점점 초록색 선과 유사해진다. . 이는 매우 좋은 접근법이지만, 확장성이 떨어진다는 치명적 단점이 있다 | . - 매트릭스를 통해 확장성을 개선할 수 있다 . &#47784;&#54805;&#51032; &#47588;&#53944;&#47533;&#49828;&#54868; . - 우리의 모형 . $y_i = beta_0 + beta_1 x_i + epsilon_i, quad i=1,2, dots,10$ . 이를 풀어서 쓰면 . $ begin{cases} y_1 = beta_0 + beta_1 x_1 + epsilon_1 y_2 = beta_0 + beta_1 x_2 + epsilon_2 dots y_{10} = beta_0 + beta_1 x_{10} + epsilon_{10} end{cases}$ . 아래와 같다. . $ begin{bmatrix} y_1 y_2 dots y_{10} end{bmatrix} = begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 dots &amp; dots 1 &amp; x_{10} end{bmatrix} begin{bmatrix} beta_0 beta_1 end{bmatrix} + begin{bmatrix} epsilon_1 epsilon_2 dots epsilon_{10} end{bmatrix} $ . 벡터와 매트릭스 형태로 표현하면 . ${ bf y} = { bf X} { boldsymbol beta} + boldsymbol{ epsilon}$ . - 손실함수의 매트릭스화 . $loss= sum_{i=1}^{n}(y_i- beta_0- beta_1x_i)^2$ . 이를 벡터로 표현하면, . $loss=({ bf y}-{ bf X}{ boldsymbol beta})^ top({ bf y}-{ bf X}{ boldsymbol beta})={ bf y}^ top { bf y} - { bf y}^ top { bf X}{ boldsymbol beta} - { boldsymbol beta}^ top { bf X}^ top { bf y} + { boldsymbol beta}^ top { bf X}^ top { bf X} { boldsymbol beta}$ . - 미분하는 과정의 매트릭스화 . loss를 최소화하는 ${ boldsymbol beta}$를 구해야하므로 loss를 ${ boldsymbol beta}$로 미분한식을 0이라고 놓고 풀면 된다. . $ frac{ partial}{ partial boldsymbol{ beta}} loss = frac{ partial}{ partial boldsymbol{ beta}} { bf y}^ top { bf y} - frac{ partial}{ partial boldsymbol{ beta}} { bf y}^ top { bf X}{ boldsymbol beta} - frac{ partial}{ partial boldsymbol{ beta}} { boldsymbol beta}^ top { bf X}^ top { bf y} + frac{ partial}{ partial boldsymbol{ beta}} { boldsymbol beta}^ top { bf X}^ top { bf X} { boldsymbol beta}$ . $= 0 - { bf X}^ top { bf y}- { bf X}^ top { bf y} + 2{ bf X}^ top { bf X} = - 2{ bf X}^ top { bf y} + 2{ bf X}^ top { bf X}{ boldsymbol beta} $ . 따라서 $ frac{ partial}{ partial boldsymbol{ beta}}loss=0$을 풀면 아래와 같다. . $ 2{ bf X}^ top { bf y} = 2{ bf X}^ top { bf X}{ boldsymbol beta}$ . $ { bf X}^ top { bf X}{ boldsymbol beta} = { bf X}^ top { bf y}$ . $ boldsymbol{ hat beta}= ({ bf X}^ top { bf X})^{-1}{ bf X}^ top { bf y} $ . - 적용 . x=tf.constant([20.1,22.2,22.7,23.3,24.4,25.1,26.2,27.3,28.4,30.4]) x . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4], dtype=float32)&gt; . tf.random.set_seed(50000) epsilon = tf.random.normal([10]) y = 10.2 + 2.2*x + epsilon y . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([53.68625 , 60.12511 , 58.93714 , 60.65312 , 64.45385 , 66.9807 , 67.960144, 70.73565 , 72.87779 , 77.54677 ], dtype=float32)&gt; . - 방법 1 . tf.concat([[[1]*10],[x]],0) . &lt;tf.Tensor: shape=(2, 10), dtype=int32, numpy= array([[ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [20, 22, 22, 23, 24, 25, 26, 27, 28, 30]])&gt; . X = tf.transpose(tf.concat([[[1]*10],[x]],0)) X . &lt;tf.Tensor: shape=(10, 2), dtype=int32, numpy= array([[ 1, 20], [ 1, 22], [ 1, 22], [ 1, 23], [ 1, 24], [ 1, 25], [ 1, 26], [ 1, 27], [ 1, 28], [ 1, 30]])&gt; . - 방법 2 . from tensorflow.python.ops.numpy_ops import np_config np_config.enable_numpy_behavior() . X = tf.concat([[[1.0]*10],[x]],0).T X . &lt;tf.Tensor: shape=(10, 2), dtype=float32, numpy= array([[ 1. , 20.1], [ 1. , 22.2], [ 1. , 22.7], [ 1. , 23.3], [ 1. , 24.4], [ 1. , 25.1], [ 1. , 26.2], [ 1. , 27.3], [ 1. , 28.4], [ 1. , 30.4]], dtype=float32)&gt; . $ boldsymbol{ hat beta}= ({ bf X}^ top { bf X})^{-1}{ bf X}^ top { bf y} $ . - 깨알문법 . 역행렬 tf.linalg.inv사용 2.행렬 간 곱 @ 사용 | tf.linalg.inv(X.T @ X) @X.T @y . &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([7.834038 , 2.3015506], dtype=float32)&gt; . beta_0_est, beta_1_est . (&lt;tf.Tensor: shape=(), dtype=float32, numpy=7.8339195&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.3015487&gt;) . 그런데 값이 다르다...? . | 이유는 텐서플로우가 효율적 계산을 위해 조금 대충 계산하기 때문 . | . - 텐서플로우 내에 내장되어 있는 텐서플로우용 넘파이를 이용하여 다시 계산해보자 . import tensorflow.experimental.numpy as tnp . x=tf.constant([20.1,22.2,22.7,23.3,24.4,25.1,26.2,27.3,28.4,30.4]) x . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4], dtype=float32)&gt; . y = 10.2 + 2.2*x + epsilon y . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([53.68625 , 60.12511 , 58.93714 , 60.65312 , 64.45385 , 66.9807 , 67.960144, 70.73565 , 72.87779 , 77.54677 ], dtype=float32)&gt; . - 공식을 이용한 풀이 . beta1_est = sum((x-np.mean(x))*(y-np.mean(y))) / sum((x-np.mean(x))**2) ## Sxy/Sxx beta0_est = np.mean(y) - beta1_est * np.mean(x) . beta0_est, beta1_est . (&lt;tf.Tensor: shape=(), dtype=float32, numpy=7.8339195&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.3015487&gt;) . - 벡터를 이용한 풀이 . X = tnp.concatenate([[tnp.array([1.0]*10)],[x]],0).T X . &lt;tf.Tensor: shape=(10, 2), dtype=float64, numpy= array([[ 1. , 20.10000038], [ 1. , 22.20000076], [ 1. , 22.70000076], [ 1. , 23.29999924], [ 1. , 24.39999962], [ 1. , 25.10000038], [ 1. , 26.20000076], [ 1. , 27.29999924], [ 1. , 28.39999962], [ 1. , 30.39999962]])&gt; . tf.linalg.inv(X.T @ X) @X.T @ y . &lt;tf.Tensor: shape=(2,), dtype=float64, numpy=array([7.83391429, 2.30154889])&gt; . 거의 유사한 값이 나온다 | . &#44208;&#47200; . 벡터를 이용하여 tf.linalg.inv(X.T @ X) @X.T @ y를 계산하면 바로 $ beta$값이 바로 나온다. .",
            "url": "https://ki5n2.github.io/charcoal/2022/03/16/DS.html",
            "relUrl": "/2022/03/16/DS.html",
            "date": " • Mar 16, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://ki5n2.github.io/charcoal/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ki5n2.github.io/charcoal/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}