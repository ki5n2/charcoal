{
  
    
        "post0": {
            "title": "DS 2. Tensorflow 기본 문법(2), tf.GradientTape()",
            "content": ". Data Science . lenture: Data Science_3-2nd week of lectures. | lenture date: 2022-03-21 | lecturer: Guebin choi | study date: 2022-03-22 | author: Kione kim | . . import tensorflow as tf import numpy as np . tnp . tnp &#49324;&#50857;&#48176;&#44221; . - tf.constant는 쓰기 너무 어려움! 넘파이가 지원하는 편리한 기능을 사용할 수 없음 . 어려운 점 1: .reshape() 메소드 불가능/ tf.reshape()만 가능 . 어려운 점 2: .transpose(), .T 불가능/ tf.transpose()만 가능 . 어려운 점 3: 암묵적 형변환 불가능 . 어려운 점 4: (2,2) @ (2,) 연산 불가능 . 등등 . - 예시1: .reshape() . a=np.array([1,2,3,4]).reshape(2,2) a . array([[1, 2], [3, 4]]) . a=tf.constant([1,2,3,4]).reshape(2,2) . AttributeError Traceback (most recent call last) Input In [3], in &lt;cell line: 1&gt;() -&gt; 1 a=tf.constant([1,2,3,4]).reshape(2,2) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:508, in Tensor.__getattr__(self, name) 504 def __getattr__(self, name): 505 if name in {&#34;T&#34;, &#34;astype&#34;, &#34;ravel&#34;, &#34;transpose&#34;, &#34;reshape&#34;, &#34;clip&#34;, &#34;size&#34;, 506 &#34;tolist&#34;, &#34;data&#34;}: 507 # TODO(wangpeng): Export the enable_numpy_behavior knob --&gt; 508 raise AttributeError(&#34;&#34;&#34; 509 &#39;{}&#39; object has no attribute &#39;{}&#39;. 510 If you are looking for numpy-related methods, please run the following: 511 from tensorflow.python.ops.numpy_ops import np_config 512 np_config.enable_numpy_behavior()&#34;&#34;&#34;.format(type(self).__name__, name)) 513 self.__getattribute__(name) AttributeError: &#39;EagerTensor&#39; object has no attribute &#39;reshape&#39;. If you are looking for numpy-related methods, please run the following: from tensorflow.python.ops.numpy_ops import np_config np_config.enable_numpy_behavior() . tf.reshape(tf.constant([1,2,3,4]),(2,2)) # 이렇게 써야함 . - 예시2: .transpose() . np.array([1,2,3,4]).transpose().reshape(2,2).T . array([[1, 3], [2, 4]]) . tf.constant([1,2,3,4]).transpose() . AttributeError Traceback (most recent call last) Input In [5], in &lt;cell line: 1&gt;() -&gt; 1 tf.constant([1,2,3,4]).transpose() File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:508, in Tensor.__getattr__(self, name) 504 def __getattr__(self, name): 505 if name in {&#34;T&#34;, &#34;astype&#34;, &#34;ravel&#34;, &#34;transpose&#34;, &#34;reshape&#34;, &#34;clip&#34;, &#34;size&#34;, 506 &#34;tolist&#34;, &#34;data&#34;}: 507 # TODO(wangpeng): Export the enable_numpy_behavior knob --&gt; 508 raise AttributeError(&#34;&#34;&#34; 509 &#39;{}&#39; object has no attribute &#39;{}&#39;. 510 If you are looking for numpy-related methods, please run the following: 511 from tensorflow.python.ops.numpy_ops import np_config 512 np_config.enable_numpy_behavior()&#34;&#34;&#34;.format(type(self).__name__, name)) 513 self.__getattribute__(name) AttributeError: &#39;EagerTensor&#39; object has no attribute &#39;transpose&#39;. If you are looking for numpy-related methods, please run the following: from tensorflow.python.ops.numpy_ops import np_config np_config.enable_numpy_behavior() . tf.transpose(tf.constant([1,2,3,4])) # 이렇게 써야함 . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])&gt; . tf.transpose(tf.reshape(tf.transpose(tf.constant([1,2,3,4])),(2,2))) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 3], [2, 4]])&gt; . 쓰기 불편,, | . - 예시3: 암묵적 형변환 . np.array([1,2,3])+np.array([1.1,2.2,3.3]) . array([2.1, 4.2, 6.3]) . tf.constant([1,2,3])+tf.constant([1.1,2.2,3.3]) . InvalidArgumentError Traceback (most recent call last) Input In [9], in &lt;cell line: 1&gt;() -&gt; 1 tf.constant([1,2,3])+tf.constant([1.1,2.2,3.3]) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:AddV2] . 암묵적 형변환 안 됨,, | . - 예시4: .max, .min 등등 넘파이에서 가능한 .max를 사용하려면 tf.constant에서는 tf.reduce_max()를 .min를 사용하려면 tf.reduce_min()를 사용해야함 . tf.reduce_max(tf.transpose(tf.reshape(tf.transpose(tf.constant([1,2,3,4])),(2,2)))) . &lt;tf.Tensor: shape=(), dtype=int32, numpy=4&gt; . tf.reduce_min(tf.transpose(tf.reshape(tf.transpose(tf.constant([1,2,3,4])),(2,2)))) . &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt; . - 예시5: (2,2) @ (2,) 연산 . np.array([[1.0,2.0],[3.0,4.0]]) @ np.array([1,2]) . array([ 5., 11.]) . np.array([1,2]) @ np.array([[1.0,2.0],[3.0,4.0]]) . array([ 7., 10.]) . 차원이 맞지 않아도 넘파이에서는 알아서 잘 계산해줌 | . np.array([[1.0,2.0],[3.0,4.0]]) @ np.array([1,2]).reshape(2,1) . array([[ 5.], [11.]]) . np.array([1,2]).reshape(2,1) @ np.array([[1.0,2.0],[3.0,4.0]]) . ValueError Traceback (most recent call last) Input In [15], in &lt;cell line: 1&gt;() -&gt; 1 np.array([1,2]).reshape(2,1) @ np.array([[1.0,2.0],[3.0,4.0]]) ValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)-&gt;(n?,m?) (size 2 is different from 1) . 헷갈릴 것 같다면 .reshape()를 써서 명시해줄 수 있다 | . tf.constant([[1.0,2.0],[3.0,4.0]]) @ tf.constant([1,2]) . InvalidArgumentError Traceback (most recent call last) Input In [16], in &lt;cell line: 1&gt;() -&gt; 1 tf.constant([[1.0,2.0],[3.0,4.0]]) @ tf.constant([1,2]) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute MatMul as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:MatMul] . 차원이 맞지 않으면 계산을 하지 않는다. | . tnp &#49324;&#50857; . import tensorflow.experimental.numpy as tnp # tnp를 사용하면 넘파이에 익숙한 문법을 모두 쓸 수 있음 tnp.experimental_enable_numpy_behavior() # 기존에 생성된 tf.constant 자료형은 넘파이와 유사하게 동작한다. . tnp.array([1,2,3]) . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])&gt; . tnp.diag([1,1]) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 0], [0, 1]])&gt; . &#53440;&#51077; . type(tf.constant([1,2])),type(tnp.array([1,2])) . (tensorflow.python.framework.ops.EagerTensor, tensorflow.python.framework.ops.EagerTensor) . tnp를 사용해도 타입은 변하지 않는다. 모두 EagerTensor | . - 앞서 본 어려운 점 1인 .reshape()가 사용 가능! . tf.constant([1,2,3,4]).reshape(2,2) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]])&gt; . - 어려운 점 2인 .transpose, .T 도 사용 가능! . tf.constant([1,2,3,4]).reshape(2,2).transpose().T . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]])&gt; . - 어려운 점 3인 암묵적 형변환도 가능! . tf.constant([1,2,3]) + tf.constant([1.1,2.2,3.3]) . &lt;tf.Tensor: shape=(3,), dtype=float64, numpy=array([2.10000002, 4.20000005, 6.29999995])&gt; . - 어려운 점 4인 .max(), .min() 등도 가능! . tf.constant([1,2,3]) +tf.constant([1.1,2.2,3.3]).max() . &lt;tf.Tensor: shape=(3,), dtype=float64, numpy=array([4.29999995, 5.29999995, 6.29999995])&gt; . tf.constant([1,2,3]) + tf.constant([1.1,2.2,3.3]).min() . &lt;tf.Tensor: shape=(3,), dtype=float64, numpy=array([2.10000002, 3.10000002, 4.10000002])&gt; . - 어려운 점 5인 (2,2) @ (2,)의 연산도 가능! . tnp.diag([1,1]) @ tf.constant([1,2]) . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2])&gt; . tf.constant([1,2]) @ tnp.diag([1,1]) . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2])&gt; . 많은 단점을 개선했음!! | . - 하지만 안 되는 것도 있음 . a = np.array([1,2,3]) a . array([1, 2, 3]) . a[0] = 0 a . array([0, 2, 3]) . a=tnp.array([1,2,3]) a . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])&gt; . a[0]=0 a . TypeError Traceback (most recent call last) Input In [31], in &lt;cell line: 1&gt;() -&gt; 1 a[0]=0 2 a TypeError: &#39;tensorflow.python.framework.ops.EagerTensor&#39; object does not support item assignment . 이는 안 됨 | . tf.Variable . &#50696;&#48708;&#54617;&#49845; . a=8 a . 8 . id(a) . 140715972567008 . a=10 a . 10 . id(a) . 140715972567072 . 이는 값을 변경(편집)한 것이 아니라 재할당한 것이다. | . b=10 id(b) . 140715972567072 . 1) tf.constant는 메모리에 그 값을 올리는 것 -&gt; 메모리에 있는 것은 바꿀 수 없음 -&gt; 값을 변경하고자 하면 재할당 해야 함 . 2) tf.Variable은 메모리에 있는 값을 변경(편집)할 수 있음 . . - 선언 . tf.Variable([1,2]) . &lt;tf.Variable &#39;Variable:0&#39; shape=(2,) dtype=int32, numpy=array([1, 2])&gt; . - type . type(tf.Variable([1,2])) . tensorflow.python.ops.resource_variable_ops.ResourceVariable . ResourceVariable 처음 보는 타입 | . - tf.constant() 선언 후 변환 . tf.Variable(tf.constant([1,2])) . &lt;tf.Variable &#39;Variable:0&#39; shape=(2,) dtype=int32, numpy=array([1, 2])&gt; . - np.array() 선언 후 변환 . tf.Variable(np.array([1,2])) . &lt;tf.Variable &#39;Variable:0&#39; shape=(2,) dtype=int32, numpy=array([1, 2])&gt; . - 인덱싱 . a=tf.Variable([1,2,3,4]) a[:2] . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2])&gt; . - 연산 . tf.Variable([1,2]) + tf.Variable([2,1]) . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 3])&gt; . 그런데 살펴보니, 인덱싱과 연산 후에 자료형이 tf.Variable에서 tf.Tensor로 바꼈다. | . a=tf.Variable([1,2]) b=tf.Variable([2,1]) type(a), type(b) . (tensorflow.python.ops.resource_variable_ops.ResourceVariable, tensorflow.python.ops.resource_variable_ops.ResourceVariable) . type(a+b) . tensorflow.python.framework.ops.EagerTensor . tf.Variable()로 만든 후 간단한연산을 하면 그 결과는 tf.constant()로 만든 오브젝트와 동일해짐. | . tf.Variable([1,2]) + tf.Variable([1.1,2.2]) . &lt;tf.Tensor: shape=(2,), dtype=float64, numpy=array([2.10000002, 4.20000005])&gt; . 이는 원래 안 되지만, tnp.experimental_enable_numpy_behavior()를 선언하면 가능함 | . tf.Variable([1,2,3,4]).reshape(2,2) . AttributeError Traceback (most recent call last) Input In [46], in &lt;cell line: 1&gt;() -&gt; 1 tf.Variable([1,2,3,4]).reshape(2,2) AttributeError: &#39;ResourceVariable&#39; object has no attribute &#39;reshape&#39; . 이것은 또 안 됨.. | . tnp의 전부 되는 것은 아니고 일부만 가능 | . - tf.concat . a=tf.Variable([[1,2],[3,4]]) b=tf.Variable([[-1,-2],[-3,-4]]) . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(4, 2), dtype=int32, numpy= array([[ 1, 2], [ 3, 4], [-1, -2], [-3, -4]])&gt; . tf.concat([a,b],axis=1) . &lt;tf.Tensor: shape=(2, 4), dtype=int32, numpy= array([[ 1, 2, -1, -2], [ 3, 4, -3, -4]])&gt; . - tf.stack . tf.stack([a,b],axis=0) . &lt;tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy= array([[[ 1, 2], [ 3, 4]], [[-1, -2], [-3, -4]]])&gt; . tf.stack([a,b],axis=1) . &lt;tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy= array([[[ 1, 2], [-1, -2]], [[ 3, 4], [-3, -4]]])&gt; . - 변수값 변경 가능 . a=tf.Variable([1,2]) a . &lt;tf.Variable &#39;Variable:0&#39; shape=(2,) dtype=int32, numpy=array([1, 2])&gt; . id(a) . 1561676107296 . a.assign_add([-1,2]) a . &lt;tf.Variable &#39;Variable:0&#39; shape=(2,) dtype=int32, numpy=array([0, 4])&gt; . id(a) . 1561676107296 . 위를 살펴보니, 메모리 주소가 같다. 즉 값이 재할당 된 것이 아닌 변경된 것임을 알 수 있다. | . : tf.constant()는 일반메모리에, tf.Variable은 GPU에 . &#48120;&#48516; . :Tensorflow를 사용하는 가장 큰 이유 . 모티브 . - 예제: 컴퓨터를 이용하여 $x=2$에서 $y=3x^2$의 접선의 기울기를 구해보자. . - (손풀이) . $ frac{dy}{dx}=6x$ 이므로, $x=2$를 대입 -&gt; 답 : 12. . - (컴퓨터로 풀이) . 도함수를 어떻게 구할지 모르겠으나 일단 $x=2$에서 접선의 기울기만 계산해보자 . step 1: 답만계산 . x1=2 y1=3*x1**2 . x2=2.000001 y2=3*x2**2 . (y2-y1)/(x2-x1) . 12.000003000266702 . step 2: 함수화 . def f(x): return 3*x**2 . def d(f,x): # python에서는 d(f,x)로 선언 가능 return (f(x+0.000001)-f(x))/0.000001 # f(x+a)-f(x)/a 꼴 . d(f,2) . 12.000003001944037 . d(f,3) . 18.000003002782705 . step 3: lambda 이용 . d(lambda x: 3*x**2,2) . 12.000003001944037 . d(lambda x: 3*x**2,3) . 18.000003002782705 . d(lambda x: x**2,3) . 6.000001000927568 . - 2개의 변수를 가지는 함수에 대한 미분 . def d(f,x): return (f(x+0.000001)-f(x))/0.000001 . def f(x,y): return x**2 + 3*y . d(f,(3,2)) # 미분을 하는 함수 d에 x**2+3*y를 적용시켜 미분시킨 후 x,y에 3,2를 각각 대입하라. . TypeError Traceback (most recent call last) Input In [68], in &lt;cell line: 1&gt;() -&gt; 1 d(f,(3,2)) Input In [66], in d(f, x) 1 def d(f,x): -&gt; 2 return (f(x+0.000001)-f(x))/0.000001 TypeError: can only concatenate tuple (not &#34;float&#34;) to tuple . 오류가 남 | . 이는 확장성이 떨어지기 때문에 다른 방법이 필요함 | . tf.GradientTape() . - 예제1: $x=2$에서 $y=3x^2$의 도함수 값을 구하여라. . x=tf.Variable([2.0]) a=tf.constant([3.0]) . . tf.GradientTape() . &lt;tensorflow.python.eager.backprop.GradientTape at 0x16b9b289130&gt; . 무엇인가 만들어졌음 | . mytape=tf.GradientTape() . dir(mytape) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__enter__&#39;, &#39;__eq__&#39;, &#39;__exit__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;_ensure_recording&#39;, &#39;_persistent&#39;, &#39;_pop_tape&#39;, &#39;_push_tape&#39;, &#39;_recording&#39;, &#39;_tape&#39;, &#39;_tf_api_names&#39;, &#39;_tf_api_names_v1&#39;, &#39;_watch_accessed_variables&#39;, &#39;_watched_variables&#39;, &#39;batch_jacobian&#39;, &#39;gradient&#39;, &#39;jacobian&#39;, &#39;reset&#39;, &#39;stop_recording&#39;, &#39;watch&#39;, &#39;watched_variables&#39;] . dir()을 찍어보니 다음과 같은 게 있음 | . __enter__ | __exit__ | ?mytape.__enter__ . Signature: mytape.__enter__() Docstring: Enters a context inside which operations are recorded on this tape. File: c: users kko anaconda3 envs ds2022 lib site-packages tensorflow python eager backprop.py Type: method . 이는 함수이고 tape를 기록하는 기능을 함 | . ?mytape.__exit__ . Signature: mytape.__exit__(typ, value, traceback) Docstring: Exits the recording context, no further operations are traced. File: c: users kko anaconda3 envs ds2022 lib site-packages tensorflow python eager backprop.py Type: method . 함수인데 ( )안에 None, None, None를 입력해주어야 한다. 기록을 끄는 기능을 함 | . tf.GradientTape() 사용법: mytape.__enter__ 기록할 내용 mytape.__exit__ . x=tf.Variable([2.0]) # 미분하고 싶은 변수는 Variable로 할당 a=tf.constant([3.0]) # a는 상수로, 값을 저장하고 싶은 것은 constant로 할당 . mytape.__enter__() y=a*x**2 mytape.__exit__(None,None,None) . mytape.gradient(y,x) # 변수 x로 y를 미분 . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt; . - 예제2 . x=tf.Variable([2.0]) . mytape=tf.GradientTape() . mytape.__enter__() a=(x/2)*3 # a를 기록할 내용으로 가져왔음 y=a*x**2 mytape.__exit__(None,None,None) . mytape.gradient(y,x) # 변수 x로 y를 미분 . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([18.], dtype=float32)&gt; . a를 기록할 내용에서 지정해준 것 뿐인데 12가 아닌 18이 나왔음 | . 이는 다음의 과정을 통해 나온 결과임 | . $a= frac{3}{2}x$ . $y=ax^2= frac{3}{2}x^3$ . $ frac{dy}{dx}= frac{3}{2}3 x^2$ . 1.5 × 3 × 4 = 18 . 1.5 * 3 * 4 . 18.0 . 즉 y는 $a=3$을 기록한 것이 아니라, $a= frac{3}{2}x$를 기록한 것이다. | . - 테이프의 개념(중요) . - 상황 예시 . 미분계산을 컴퓨터에게 부탁하고 싶다. 예를 들어 $y=3x^2$에 대한 미분계산을 컴퓨터에 부탁 하기 위해서는 노트 및 연습장(=테이프)에 $y=3x^2$이라는 수식을 써서 보여줘야 한다. 이 때 컴퓨터에게 식($y$)이 무엇인지 그리고 무엇으로 미분하고 싶은지($x$)를 명시해야 한다. . - 비유 . (1) mytape = tf.GradientTape(): . tf.GradientTape() 는 컴퓨터에게 전달할 노트 생성 | mytape= 는 생성한 노트의 이름을 mytape이라고 지정 | . (2) mytape.__enter__(): . mytape 라는 노트를 연다. | . (3) a=x/2*3; y=a*x**2: . 컴퓨터에게 보여줄 식(미분하고자 하는 식) | . (4) mytape.__exit__(None,None,None): mytape라는 공책을 닫는다. . mytape 라는 노트를 닫는다. | . (5) mytape.gradient(y,x): $y$를 $x$로 미분한다는 메모를 남겨 컴퓨터에 전달 . - 여기서 가장 중요한 것은 노트를 언제 열고 닫는지이다 . 1) . x=tf.Variable([2.0]) a=x/2*3 # a=x*(3/2) -&gt; a=3 #2 mytape=tf.GradientTape() #3 mytape.__enter__() y=a*x**2 # y=3*x**2, a는 이미 3의 값을 가짐 mytape.__exit__(None,None,None) #4 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt; . 2) . x=tf.Variable([2.0]) #2 mytape=tf.GradientTape() #3 mytape.__enter__() a=x/2*3 y=a*x**2 # a=(3*x)/2로 y=(3*x)/2*x**2 mytape.__exit__(None,None,None) #4 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([18.], dtype=float32)&gt; . 이를 유심히 살펴보니, 코드가 뭔가 깔끔하지가 않음. 중복되는 것도 있어 보임. . | 보다 깔끔하고 효율적인 코드가 필요! -&gt; with문활용 . | . - 참고: x=tf.constant([2]) float형으로 입력하지 않으면 오류!! tf.Variable([2])도 마찬가지 . x=tf.constant([2]) #2 mytape=tf.GradientTape() #3 mytape.__enter__() a=x/2*3 y=a*x**2 # a=(3*x)/2로 y=(3*x)/2*x**2 mytape.__exit__(None,None,None) #4 mytape.gradient(y,x) . WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32 . x=tf.Variable([2]) #2 mytape=tf.GradientTape() #3 mytape.__enter__() a=x/2*3 y=a*x**2 # a=(3*x)/2로 y=(3*x)/2*x**2 mytape.__exit__(None,None,None) #4 mytape.gradient(y,x) . WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32 . with&#47928;&#51012; &#54876;&#50857;&#54620; tf.GradientTape() . with문 사용법: with tf.GradientTape() as mytape: 컴퓨터에게 전달할 수식 1. tf.GradientTape()를 실행하면 오브젝트가 하나 생성되는데 이를 mytape라고 지정한다. 기존에 mytape=tf.GradientTape()을 with tf.GradientTape as mytape으로 지정해준다. 2. with문이 시작되면서 mytape.__enter__()이 실행 3. 컴퓨터에게 전달한 수식 실행 4. with문이 끝나면서 mytape.__exit__(None,None,None)가 실행 . - with문 사용한 예제 풀이 . 1) . x=tf.Variable([2.0]) a=x/2*3 with tf.GradientTape() as mytape: y=a*x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt; . 2) . x=tf.Variable([2.0]) with tf.GradientTape() as mytape: a=x/2*3 y=a*x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([18.], dtype=float32)&gt; . - persistent=True: 계산한 값을 버리지 않는 기능으로 계속해서 출력할 수 있다 . x=tf.Variable([2.0]) a=x/2*3 with tf.GradientTape() as mytape: y=a*x**2 . mytape.gradient(y,x),mytape.gradient(y,x) . RuntimeError Traceback (most recent call last) Input In [115], in &lt;cell line: 1&gt;() -&gt; 1 mytape.gradient(y,x),mytape.gradient(y,x) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python eager backprop.py:1029, in GradientTape.gradient(self, target, sources, output_gradients, unconnected_gradients) 999 &#34;&#34;&#34;Computes the gradient using operations recorded in context of this tape. 1000 1001 Note: Unless you set `persistent=True` a GradientTape can only be used to (...) 1026 called with an unknown value. 1027 &#34;&#34;&#34; 1028 if self._tape is None: -&gt; 1029 raise RuntimeError(&#34;A non-persistent GradientTape can only be used to &#34; 1030 &#34;compute one set of gradients (or jacobians)&#34;) 1031 if self._recording: 1032 if not self._persistent: RuntimeError: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians) . 두 번 실행하면 오류가 난다 | . x=tf.Variable([2.0]) a=x/2*3 with tf.GradientTape(persistent=True) as mytape: y=a*x**2 . mytape.gradient(y,x),mytape.gradient(y,x) . (&lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt;, &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt;) . 오류 해결! | . - 미분계산에 사용할 변수($x$)를 tf.constant로 설정하면 계산이 되지 않는다. . x=tf.constant([2.0]) a=x/2*3 with tf.GradientTape(persistent=True) as mytape: y=a*x**2 mytape.gradient(y,x) . print(mytape.gradient(y,x)) . None . 미분계산에 사용할 변수는 tf.Variable로 설정해야 한다 | . - 자동감시모드 &amp; 수동감시모드 . - 예시 . notename.watch(x):를 사용하면 미분계산에 사용할 변수($x$)를 tf.constant()로 설정하였더라도 계산이 된다. . x=tf.constant([2.0]) a=x/2*3 with tf.GradientTape(persistent=True) as mytape: mytape.watch(x) y=a*x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt; . 계산이 되었음 ! | . tf.Variable(): 자동감시모드 tf.constant(): 감시 X `notename.watch(감시할 변수)`사용: (감시할 변수에 대한) 수동감시모드 . - 자동감시모드(기존) . x=tf.Variable([2.0]) a=x/2*3 with tf.GradientTape(persistent=True) as mytape: y=a*x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt; . - 자동감시모드 off : watch_accessed_variables=False 사용 . x=tf.Variable([2.0]) a=x/2*3 with tf.GradientTape(persistent=True,watch_accessed_variables=False) as mytape: y=a*x**2 mytape.gradient(y,x) . - 수동감시모드 . x=tf.constant([2.0]) a=x/2*3 with tf.GradientTape(persistent=True) as mytape: mytape.watch(x) # 수동감시 y=a*x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt; . - 자동감시모드 -&gt; 자동감시모드 off -&gt; 수동감시 ON . x=tf.Variable([2.0]) a=x/2*3 with tf.GradientTape(persistent=True,watch_accessed_variables=False) as mytape: mytape.watch(x) y=a*x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)&gt; . 가능! | . 헷갈리면 언제나 mytape.watch(변수)를 명시해도 괜찮음! | 오류가 나는 것은 아니니! | . &#52628;&#44032;&#54617;&#49845; . - tf.GradientTape( )를 이용하여 $y=x^2$에서 $x=0$에서의 접선의 기울기를 구하라. . x=tf.constant([0.0]) with tf.GradientTape(persistent=True) as mytape: mytape.watch(x) y=x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)&gt; .",
            "url": "https://ki5n2.github.io/charcoal/2022/03/22/DS.html",
            "relUrl": "/2022/03/22/DS.html",
            "date": " • Mar 22, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "DS 2. Tensorflow 기본 문법(1) - tf.constant",
            "content": ". Data Science . lenture: Data Science_2-2, 3-1nd week of lectures. | lenture date: 2022-03-14, 2022-03-16 | lecturer: Guebin choi | study date: 2022-03-18, 2022-03-20 | author: Kione kim | . . Tensorflow &#49324;&#50857;&#48277; . import tensorflow as tf import numpy as np . tf.config.experimental.list_physical_devices(&#39;GPU&#39;) . [] . NO GPU | . tf.constant . &#50696;&#48708;&#54617;&#49845;: &#51473;&#52393;&#47532;&#49828;&#53944; . [1,[2,3]] . [1, [2, 3]] . _[1][1] . 3 . lst = [[1,2],[3,4]] lst . [[1, 2], [3, 4]] . lst[0][1] . 2 . lst[1][0] . 3 . 1 2 3 4 . print(lst[0][0]) # (1,1) print(lst[0][1]) # (1,2) print(lst[1][0]) # (2,1) print(lst[1][1]) # (2,2) . 1 2 3 4 . 이는 벡터일 뿐인데 매트릭스처럼 보임(매트릭스는 아님) | . - 이를(매트릭스처럼 보이는 것을) 활용하여 행렬을 만들어보자 . $4×2$ . lst = [[1,2],[3,4],[5,6],[7,8]] lst . [[1, 2], [3, 4], [5, 6], [7, 8]] . $4×1$ . lst = [[1],[2],[3],[4]] lst # 길이가 4인 column-vector처럼 보임 . [[1], [2], [3], [4]] . $2×4$ . lst = [[1,2,3,4],[5,6,7,8]] lst . [[1, 2, 3, 4], [5, 6, 7, 8]] . $1×4$ . lst = [[1,2,3,4]] lst # 길이가 4인 row-vector처럼 보임 . [[1, 2, 3, 4]] . - 3차원 . lst = [[[1,2],[3,4]],[[5,6],[7,8]]] # 2×2×2 매트릭스처럼 보임 lst . [[[1, 2], [3, 4]], [[5, 6], [7, 8]]] . print(lst[0][0][0]) print(lst[0][0][1]) print(lst[0][1][0]) print(lst[0][1][1]) # 차원 2 print(lst[1][0][0]) print(lst[1][0][1]) print(lst[1][1][0]) print(lst[1][1][1]) . 1 2 3 4 5 6 7 8 . &#49440;&#50616; . - 스칼라 . _scalar = tf.constant(1) _scalar . &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt; . - 벡터 . [1,2,3] # 리스트 . [1, 2, 3] . _vector = tf.constant([1,2,3]) # 리스트를 tf.constant()함수를 사용하여 벡터로 _vector . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])&gt; . _vector[-1], _vector[-2] . (&lt;tf.Tensor: shape=(), dtype=int32, numpy=3&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;) . - 아래 두 코드는 다름. 두 번째 코드는 의도하지 않은 결과임 . a=tf.constant([1,2,3,4]) a . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])&gt; . a=tf.constant(1,2,3,4) a . &lt;tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 1., 1.])&gt; . tf.constant([ ]) [ ]를 사용해주어야 함 ! | . - 매트릭스 . _mat = tf.constant([[1,2,3],[4,5,6]]) _mat . &lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy= array([[1, 2, 3], [4, 5, 6]])&gt; . 하나의 행렬로 묶을 때는 행렬처음과 끝에 [ ]로 받아주어야 한다. | . _mat[0] . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])&gt; . _mat[0][0] . &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt; . _mat[0,0] . &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt; . _mat[0][0]를 _mat[0,0]와 같이 사용할 수 있다 | . - 첫번째 행을 뽑는 방법 . - 방법1 . _mat[0] . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])&gt; . - 방법2 . _mat[0,:] . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])&gt; . - 첫번째 열을 뽑는 방법 . _mat[:,0] . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 4])&gt; . _mat[:,-1] . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 6])&gt; . 즉 행과 열을 모두 뽑을 수 있는 방법은 방법2이다. 확장성이 있음 | . type(_scalar) . tensorflow.python.framework.ops.EagerTensor . EagerTensor임을 기억 | . type(_vector) . tensorflow.python.framework.ops.EagerTensor . tf.constant&#51032; &#48520;&#54200;&#54620;&#51216; . 1. dtype 모든 원소가 똑같아야함 2. 값을 바꿀 수 없음 3. dtype이 다르면 연산이 불가능 . 2. 값을 바꿀 수 없음 . _mat[0,0] = 10 . TypeError Traceback (most recent call last) Input In [41], in &lt;cell line: 1&gt;() -&gt; 1 _mat[0,0] = 10 TypeError: &#39;tensorflow.python.framework.ops.EagerTensor&#39; object does not support item assignment . 3. dtype이 다르면 연산 불가능 . tf.constant([1,2])+ tf.constant([3,4]) . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6])&gt; . tf.constant([1.1,2])+ tf.constant([3,4]) . InvalidArgumentError Traceback (most recent call last) Input In [43], in &lt;cell line: 1&gt;() -&gt; 1 tf.constant([1.1,2])+ tf.constant([3,4]) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2] . tf.constant([1.1,2]) . &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.1, 2. ], dtype=float32)&gt; . tf.constant([3,4]) . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4])&gt; . 뜯어보니, tf.constant([1.1,2])는 float형이고 tf.constant([3,4])는 int형이다. float과 int가 달라서 계산이 안 된 것,, ? OMG | . - 다음과 같이 해야 한다 . tf.constant([1.1,2])+tf.constant([3.,4.]) . &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.1, 6. ], dtype=float32)&gt; . tf.constant([1.1,2])+tf.constant([3,4.]) . &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.1, 6. ], dtype=float32)&gt; . tf.constant([1.1,2])+tf.constant([3.,4]) . &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.1, 6. ], dtype=float32)&gt; . int형에 있는 하나의 원소에 .을 찍어주면 float형이 된다. | . - 같은 float형이라도 불가능한 경우가 있음 . tf.constant([1.1,2]) . &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.1, 2. ], dtype=float32)&gt; . tf.constant([3.0,4.0],dtype=tf.float64) . &lt;tf.Tensor: shape=(2,), dtype=float64, numpy=array([3., 4.])&gt; . tf.constant([1.1,2])+tf.constant([3.0,4.0],dtype=tf.float64) . InvalidArgumentError Traceback (most recent call last) Input In [56], in &lt;cell line: 1&gt;() -&gt; 1 tf.constant([1.1,2])+tf.constant([3.0,4.0],dtype=tf.float64) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2] . float32와 float64가 달라서 오류,,,? OMG2 | . tf.constant $ to$ &#45336;&#54028;&#51060; . _vector = tf.constant([1,2,3,4]) _vector . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])&gt; . np.array(_vector) # 방법1 . array([1, 2, 3, 4]) . _vector.numpy() . array([1, 2, 3, 4]) . Tensorflow 내에서 numpy를 쓸 수 있다 | . &#50672;&#49328; . - 더하기 . a=tf.constant([1,2,3]) b=tf.constant([4,5,6]) a+b . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 7, 9])&gt; . tf.add(a,b) . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 7, 9])&gt; . - 곱하기 . a=tf.constant([[1,2],[3,4]]) b=tf.constant([[5,6],[7,8]]) a*b . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[ 5, 12], [21, 32]])&gt; . tf.multiply(a,b) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[ 5, 12], [21, 32]])&gt; . 각 원소끼리 곱 | . - 행렬곱 . a=tf.constant([[1,2],[3,4]]) b=tf.constant([[1,0],[0,1]]) a@b . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]])&gt; . tf.matmul(a,b) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]])&gt; . - 역행렬 . a=tf.constant([[1,0],[0,2]]) a . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 0], [0, 2]])&gt; . tf.linalg.inv(a) . InvalidArgumentError Traceback (most recent call last) Input In [69], in &lt;cell line: 1&gt;() -&gt; 1 tf.linalg.inv(a) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python ops gen_linalg_ops.py:1505, in matrix_inverse(input, adjoint, name) 1503 return _result 1504 except _core._NotOkStatusException as e: -&gt; 1505 _ops.raise_from_not_ok_status(e, name) 1506 except _core._FallbackException: 1507 pass File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: Value for attr &#39;T&#39; of int32 is not in the list of allowed values: double, float, half, complex64, complex128 ; NodeDef: {{node MatrixInverse}}; Op&lt;name=MatrixInverse; signature=input:T -&gt; output:T; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]&gt; [Op:MatrixInverse] . 당연히 되어야하는데 오류가 남. 이는 a가 int이지만, 역행렬 값은 0.5(소수값)이 나오기 때문.. OMG3 . | 따라서 다음과 같이 하면 가능.. . | . a=tf.constant([[1.0,0],[0,2]]) a . &lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 0.], [0., 2.]], dtype=float32)&gt; . tf.linalg.inv(a) . &lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1. , 0. ], [0. , 0.5]], dtype=float32)&gt; . a도 float형으로 했기 때문에 가능 | . a @ tf.linalg.inv(a) . &lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 0.], [0., 1.]], dtype=float32)&gt; . - 행렬식, 대각합 . a=tf.constant([[1.0,0],[0,2]]) a . &lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 0.], [0., 2.]], dtype=float32)&gt; . tf.linalg.det(a) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.0&gt; . tf.linalg.trace(a) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=3.0&gt; . - 집계함수 . a=tf.constant([[1,2,3],[4,5,6]]) a . &lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy= array([[1, 2, 3], [4, 5, 6]])&gt; . tf.reduce_sum(a) . &lt;tf.Tensor: shape=(), dtype=int32, numpy=21&gt; . tf.sum(a) # 잘못된 코드1 . AttributeError Traceback (most recent call last) Input In [82], in &lt;cell line: 1&gt;() -&gt; 1 tf.sum(a) AttributeError: module &#39;tensorflow&#39; has no attribute &#39;sum&#39; . a.sum(a) # 잘못된 코드2 . AttributeError Traceback (most recent call last) Input In [56], in &lt;cell line: 1&gt;() -&gt; 1 a.sum(a) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:513, in Tensor.__getattr__(self, name) 505 if name in {&#34;T&#34;, &#34;astype&#34;, &#34;ravel&#34;, &#34;transpose&#34;, &#34;reshape&#34;, &#34;clip&#34;, &#34;size&#34;, 506 &#34;tolist&#34;, &#34;data&#34;}: 507 # TODO(wangpeng): Export the enable_numpy_behavior knob 508 raise AttributeError(&#34;&#34;&#34; 509 &#39;{}&#39; object has no attribute &#39;{}&#39;. 510 If you are looking for numpy-related methods, please run the following: 511 from tensorflow.python.ops.numpy_ops import np_config 512 np_config.enable_numpy_behavior()&#34;&#34;&#34;.format(type(self).__name__, name)) --&gt; 513 self.__getattribute__(name) AttributeError: &#39;tensorflow.python.framework.ops.EagerTensor&#39; object has no attribute &#39;sum&#39; . tf.reduce_max(a) . &lt;tf.Tensor: shape=(), dtype=int32, numpy=6&gt; . tf.reduce_min(a) . &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt; . tf.reduce_mean(a) . &lt;tf.Tensor: shape=(), dtype=int32, numpy=3&gt; . 왜 평균이 3.5가 아닌 3이 나오지? | . - 행렬곱 고급 . _I=tf.constant([[1.0,0.0],[0.0,1.0]]) _I . &lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 0.], [0., 1.]], dtype=float32)&gt; . _x=tf.constant([11,22]) _x . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([11, 22])&gt; . _I @ _x . InvalidArgumentError Traceback (most recent call last) Input In [91], in &lt;cell line: 1&gt;() -&gt; 1 _I @ _x File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute MatMul as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:MatMul] . 오류가 남. | 이유: _x가 길이가 2인 열벡터도 아니고 길이가 2인 행벡터도 아니기 때문, _x는 그저 길이가 2인 벡터임 | . _x @ _I . InvalidArgumentError Traceback (most recent call last) Input In [92], in &lt;cell line: 1&gt;() -&gt; 1 _x @ _I File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute MatMul as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:MatMul] . 이것 또한 마찬가지, 열벡터가 아니기 때문 | . - 다음과 같이 표현해주어야 함 . - 열벡터 선언 . _x=tf.constant([[11],[22]]) _x . &lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy= array([[11], [22]])&gt; . - cf. 행벡터 . _x=tf.constant([[11,22]]) _x . &lt;tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[11, 22]])&gt; . _I @ _x . InvalidArgumentError Traceback (most recent call last) Input In [101], in &lt;cell line: 1&gt;() -&gt; 1 _I @ _x File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute MatMul as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:MatMul] . float형으로 선언해주지 않아서 난 오류 | . _x=tf.constant([[11.0],[22.0]]) _x . &lt;tf.Tensor: shape=(2, 1), dtype=float32, numpy= array([[11.], [22.]], dtype=float32)&gt; . _I @ _x . &lt;tf.Tensor: shape=(2, 1), dtype=float32, numpy= array([[11.], [22.]], dtype=float32)&gt; . - 행벡터 선언 tf.constant([[ , ]]) . _x=tf.constant([[11.0,22.0]]) _x . &lt;tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[11., 22.]], dtype=float32)&gt; . _x @ _I . &lt;tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[11., 22.]], dtype=float32)&gt; . &#54805;&#53468;&#48320;&#54872; . - 기본 . a=tf.constant([1,2,3,4]) a . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])&gt; . 이는 길이가 4인 벡터 | . tf.reshape(a,(2,2)) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]])&gt; . tf.reshape(a,(4,1)) . &lt;tf.Tensor: shape=(4, 1), dtype=int32, numpy= array([[1], [2], [3], [4]])&gt; . tf.reshape(a,(1,4)) . &lt;tf.Tensor: shape=(1, 4), dtype=int32, numpy=array([[1, 2, 3, 4]])&gt; . - 응용 -1이용 : -1은 자동 연산하여 값을 채워주는 기능 . a=tf.constant([0,1,2,3,4,5,6,7,8,9,10,11]) a . &lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])&gt; . tf.reshape(a,(4,3)) # 기본 . &lt;tf.Tensor: shape=(4, 3), dtype=int32, numpy= array([[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8], [ 9, 10, 11]])&gt; . tf.reshape(a,(4,-1)) # 응용 . &lt;tf.Tensor: shape=(4, 3), dtype=int32, numpy= array([[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8], [ 9, 10, 11]])&gt; . tf.reshape(a,(2,2,3)) # 기본 . &lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]]])&gt; . tf.reshape(a,(2,2,-1)) # 응용 . &lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]]])&gt; . tf.reshape(a,(3,2,2)) # 기본 . &lt;tf.Tensor: shape=(3, 2, 2), dtype=int32, numpy= array([[[ 0, 1], [ 2, 3]], [[ 4, 5], [ 6, 7]], [[ 8, 9], [10, 11]]])&gt; . tf.reshape(a,(3,2,-1)) . &lt;tf.Tensor: shape=(3, 2, 2), dtype=int32, numpy= array([[[ 0, 1], [ 2, 3]], [[ 4, 5], [ 6, 7]], [[ 8, 9], [10, 11]]])&gt; . tf.reshape(a,(2,-1)) . &lt;tf.Tensor: shape=(2, 6), dtype=int32, numpy= array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11]])&gt; . $2×6$ 행렬로 만들어줌, 즉, 3차원으로 만들고 싶을 땐 두 번째 값까지는 채워줘야 함 | . - reshape한 것을 다시 reshape 해줄 수 있음 . - reshape한 것을 1차원으로 다시 만들어보자 . b=tf.reshape(a,(2,2,-1)) b . &lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]]])&gt; . tf.reshape(b,12) # 기본 . &lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])&gt; . tf.reshape(b,-1) # 응용 . &lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])&gt; . &#49440;&#50616;&#44256;&#44553; . - 대각행렬선언 . - 넘파이로 먼저 만들고 tf.constant( )를 사용하여 자료형 변환 . np.diag([1,2,3]) . array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]) . tf.constant(np.diag([1,2,3])) . &lt;tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[1, 0, 0], [0, 2, 0], [0, 0, 3]])&gt; . - 1으로만 이루어진 텐서 만들기 . tf.ones((3,4)) . &lt;tf.Tensor: shape=(3, 4), dtype=float32, numpy= array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]], dtype=float32)&gt; . tf.ones([3,4]) . &lt;tf.Tensor: shape=(3, 4), dtype=float32, numpy= array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]], dtype=float32)&gt; . tf.reshape([1]*12,(3,4)) . &lt;tf.Tensor: shape=(3, 4), dtype=int32, numpy= array([[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]])&gt; . tf.reshape(tf.constant([1]*12),(3,4)) . &lt;tf.Tensor: shape=(3, 4), dtype=int32, numpy= array([[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]])&gt; . 같은 결과 | . - 0으로만 이루어진 텐서 만들기 . tf.zeros([3,3]) . &lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]], dtype=float32)&gt; . tf.zeros((3,3)) . &lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]], dtype=float32)&gt; . - 리스트로 변환 후 텐서로 변환하지 않고 바로 텐서로 바꾸기 : 즉, a $ to$ list $ to$ tensor - X a $ to$ tensor - O . range(12) . range(0, 12) . a=range(0,12) a? . Type: range String form: range(0, 12) Length: 12 Docstring: range(stop) -&gt; range object range(start, stop[, step]) -&gt; range object Return an object that produces a sequence of integers from start (inclusive) to stop (exclusive) by step. range(i, j) produces i, i+1, i+2, ..., j-1. start defaults to 0, and stop is omitted! range(4) produces 0, 1, 2, 3. These are exactly the valid indices for a list of 4 elements. When step is given, it specifies the increment (or decrement). . range? 가 무엇인지는 모르겠지만, 일단 리스트로 바꿔보자. | . list(a) . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] . list 형태로 변환되었다. | . - 동일한 논리로 range 가 무엇인지는 모르겠지만, tf.constant를 이용하여 텐서형태로 바꿔보자. (tf.constant가 텐서로 변환해주는 기능) . tf.constant(range(0,12)) . &lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])&gt; . tf.constant(range(1,12)) # 1부터 시작 . &lt;tf.Tensor: shape=(11,), dtype=int32, numpy=array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])&gt; . tf.constant(range(2,6)) . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([2, 3, 4, 5])&gt; . tf.constant(range(2,21,2)) # 2칸씩 점프 . &lt;tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 2, 4, 6, 8, 10, 12, 14, 16, 18, 20])&gt; . tf.constant(range(2,21,3)) # 3칸씩 점프 . &lt;tf.Tensor: shape=(7,), dtype=int32, numpy=array([ 2, 5, 8, 11, 14, 17, 20])&gt; . - 등간격 수열 만들기 . tf.linspace(0,1,14) # 0 ~ 1 까지 길이가 14인 수열 만들기 . &lt;tf.Tensor: shape=(14,), dtype=float64, numpy= array([0. , 0.07692308, 0.15384615, 0.23076923, 0.30769231, 0.38461538, 0.46153846, 0.53846154, 0.61538462, 0.69230769, 0.76923077, 0.84615385, 0.92307692, 1. ])&gt; . tf.linspace(-1,20,14) # -1 ~ 20 까지 길이가 14인 수열 . &lt;tf.Tensor: shape=(14,), dtype=float64, numpy= array([-1. , 0.61538462, 2.23076923, 3.84615385, 5.46153846, 7.07692308, 8.69230769, 10.30769231, 11.92307692, 13.53846154, 15.15384615, 16.76923077, 18.38461538, 20. ])&gt; . tf.linspace([0,-1],[14,20],14) # 첫 열: 0~14까지, 두 번째 열: -1~20까지 길이가 14인 수열 . &lt;tf.Tensor: shape=(14, 2), dtype=float64, numpy= array([[ 0. , -1. ], [ 1.07692308, 0.61538462], [ 2.15384615, 2.23076923], [ 3.23076923, 3.84615385], [ 4.30769231, 5.46153846], [ 5.38461538, 7.07692308], [ 6.46153846, 8.69230769], [ 7.53846154, 10.30769231], [ 8.61538462, 11.92307692], [ 9.69230769, 13.53846154], [10.76923077, 15.15384615], [11.84615385, 16.76923077], [12.92307692, 18.38461538], [14. , 20. ]])&gt; . - $14×2$가 아닌 $2×14$ 행렬은? . : axis=1사용 . tf.linspace([0,-1],[1,20],14,axis=1) . &lt;tf.Tensor: shape=(2, 14), dtype=float64, numpy= array([[ 0. , 0.07692308, 0.15384615, 0.23076923, 0.30769231, 0.38461538, 0.46153846, 0.53846154, 0.61538462, 0.69230769, 0.76923077, 0.84615385, 0.92307692, 1. ], [-1. , 0.61538462, 2.23076923, 3.84615385, 5.46153846, 7.07692308, 8.69230769, 10.30769231, 11.92307692, 13.53846154, 15.15384615, 16.76923077, 18.38461538, 20. ]])&gt; . tf.linspace([0,-1],[1,20],14,axis=0) . &lt;tf.Tensor: shape=(14, 2), dtype=float64, numpy= array([[ 0. , -1. ], [ 0.07692308, 0.61538462], [ 0.15384615, 2.23076923], [ 0.23076923, 3.84615385], [ 0.30769231, 5.46153846], [ 0.38461538, 7.07692308], [ 0.46153846, 8.69230769], [ 0.53846154, 10.30769231], [ 0.61538462, 11.92307692], [ 0.69230769, 13.53846154], [ 0.76923077, 15.15384615], [ 0.84615385, 16.76923077], [ 0.92307692, 18.38461538], [ 1. , 20. ]])&gt; . - 랜덤 . tf.random.normal([10]) . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([-2.031805 , 0.0878811 , -0.08389507, -0.4712213 , 1.7228402 , 1.5234696 , -0.45930204, 0.27446908, 0.6777201 , 1.2311221 ], dtype=float32)&gt; . tf.random.normal(10) . InvalidArgumentError Traceback (most recent call last) Input In [131], in &lt;cell line: 1&gt;() -&gt; 1 tf.random.normal(10) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: shape must be a vector of {int32,int64}, got shape [] [Op:RandomStandardNormal] . 위와 같이 하면 오류가 남 | . tf.random.normal([3,3]) . &lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[-0.67909116, 1.6647867 , -1.1921434 ], [-0.41828915, -1.007226 , -0.37517777], [-0.35723418, -0.90447557, -0.21201086]], dtype=float32)&gt; . tf.random.uniform([3,3]) . &lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[0.49846053, 0.53244936, 0.37250876], [0.5088717 , 0.01882815, 0.50129974], [0.8890096 , 0.7716527 , 0.68743026]], dtype=float32)&gt; . - numpy를 이용한 자료형 변환 . a=np.random.randn(10) a . array([ 1.42470939, -0.43431904, 0.35631914, -0.83401698, 0.98403914, 0.03123622, 0.3625249 , 0.45672775, 0.51236327, 0.74739683]) . list(a) # 일단 리스트로 변환해 봄 . [1.4247093944590954, -0.4343190394693054, 0.35631913687969213, -0.8340169822900257, 0.9840391372400604, 0.031236220641082953, 0.36252489894658657, 0.4567277510989872, 0.5123632705088501, 0.7473968310235103] . tf.constant(a) . &lt;tf.Tensor: shape=(10,), dtype=float64, numpy= array([ 1.42470939, -0.43431904, 0.35631914, -0.83401698, 0.98403914, 0.03123622, 0.3625249 , 0.45672775, 0.51236327, 0.74739683])&gt; . - tf.random이 numpy에 있는 모든 기능을 구현하는 것은 아님. . np.random.randn(10) . array([-0.37923556, 1.89366845, -0.60768019, 0.89680048, -0.11687065, -0.67507322, 3.45690649, 0.13774121, 0.5305251 , -0.37030568]) . tf.random.randn([10]) . AttributeError Traceback (most recent call last) Input In [143], in &lt;cell line: 1&gt;() -&gt; 1 tf.random.randn([10]) AttributeError: module &#39;tensorflow._api.v2.random&#39; has no attribute &#39;randn&#39; . tf.concat . tf.concat 사용법: 축 지정이 매우 헷갈리기 때문에 외우는 게 필요함 python은 0부터 시작하기 때문에 첫 번째 축이 0을 의미, 두 번째 축이 1을 의미, 세 번째 축이 2를 의미한다. (2차원에선) 함수 축을 그릴 때 가로를 그린 후 세로를 그리기 때문에 첫 번째 축이 가로, 두 번째 축이 세로를 의미한다. (2차원에선) 따라서 axis=0은 가로로 쌓는다는 것(아래로 계속해서)을 의미하고 axis=1은 세로로 쌓는다는 것(옆으로 계속해서)을 의미한다. 3차원부터는 앞서 정리한 것처럼 첫 번째 축-0, 두 번째 축-1, 세 번째 축-2 으로 외우는 것이 좋다. . - $2×1$ 벡터와 $2×1$ 벡터를 concat해서 $2×2$ 벡터로 만든다 . a=tf.constant([[1],[2]]) b=tf.constant([[3],[4]]) . a,b . (&lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy= array([[1], [2]])&gt;, &lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy= array([[3], [4]])&gt;) . tf.concat([a,b]) . TypeError Traceback (most recent call last) Input In [151], in &lt;cell line: 1&gt;() -&gt; 1 tf.concat([a,b]) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util dispatch.py:1076, in add_dispatch_support.&lt;locals&gt;.decorator.&lt;locals&gt;.op_dispatch_handler(*args, **kwargs) 1074 if iterable_params is not None: 1075 args, kwargs = replace_iterable_params(args, kwargs, iterable_params) -&gt; 1076 result = api_dispatcher.Dispatch(args, kwargs) 1077 if result is not NotImplemented: 1078 return result TypeError: Missing required positional argument . - concat을 사용할 때는 축을 반드시 지정해주어야 한다. 그렇지 않으면 위와 같이 오류가 뜬다. . tf.concat([a,b],axis=1) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 3], [2, 4]])&gt; . - $2×1$ 벡터와 $2×1$ 벡터를 concat해서 $4×1$ 벡터로 만든다 . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(4, 1), dtype=int32, numpy= array([[1], [2], [3], [4]])&gt; . - $1×2$ 벡터와 $1×2$ 벡터를 concat해서 $2×2$ 벡터로 만든다 . a=tf.constant([1,2]) b=tf.constant([3,4]) a,b . (&lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2])&gt;, &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4])&gt;) . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])&gt; . 의도하지 않은 결과가 나타나는 이유? : 전체 축에 대한 [ ]를 입력해주지 않았기 때문....... | . a=tf.constant([[1,2]]) b=tf.constant([[3,4]]) a,b . (&lt;tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[1, 2]])&gt;, &lt;tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[3, 4]])&gt;) . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]])&gt; . - $1×2$ 벡터와 $1×2$ 벡터를 concat해서 $1×4$ 벡터로 만든다 . tf.concat([a,b],axis=1) . &lt;tf.Tensor: shape=(1, 4), dtype=int32, numpy=array([[1, 2, 3, 4]])&gt; . axis=0은 아래로 쌓이고 axis=1은 옆으로 쌓인다고 기억하자. | . - 3차원으로 확장해보자 : 첫 번째 축이 무엇인지 파악하는 것이 중요함 ! 다음 예제에서 첫 번째 축은 $2×3$행렬이 두 개 있는 3차원 축을 의미함 . a=tf.reshape(tf.constant(range(12)),(2,2,3)) b=-a a,b . (&lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]]])&gt;, &lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy= array([[[ 0, -1, -2], [ -3, -4, -5]], [[ -6, -7, -8], [ -9, -10, -11]]])&gt;) . - $2×2×3$ 벡터와 $2×2×3$ 벡터를 concat해서 $4×2×3$ 벡터로 만든다 . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(4, 2, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]], [[ 0, -1, -2], [ -3, -4, -5]], [[ -6, -7, -8], [ -9, -10, -11]]])&gt; . 합치고자 하는 것이 첫 번째 축이기 때문에 axis=0을 이용한다 | . - $2×2×3$ 벡터와 $2×2×3$ 벡터를 concat해서 $2×4×3$ 벡터로 만든다 . tf.concat([a,b],axis=1) . &lt;tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5], [ 0, -1, -2], [ -3, -4, -5]], [[ 6, 7, 8], [ 9, 10, 11], [ -6, -7, -8], [ -9, -10, -11]]])&gt; . 합치고자 하는 것이 두 번째 축이기 때문에 axis=1을 이용한다 | . - $2×2×3$ 벡터와 $2×2×3$ 벡터를 concat해서 $2×2×6$ 벡터로 만든다 . tf.concat([a,b],axis=2) . &lt;tf.Tensor: shape=(2, 2, 6), dtype=int32, numpy= array([[[ 0, 1, 2, 0, -1, -2], [ 3, 4, 5, -3, -4, -5]], [[ 6, 7, 8, -6, -7, -8], [ 9, 10, 11, -9, -10, -11]]])&gt; . 합치고자 하는 것이 세 번째 축이기 때문에 axis=2를 이용한다. | . - 다른 가능한 방법 . tf.concat([a,b],axis=-1) . &lt;tf.Tensor: shape=(2, 2, 6), dtype=int32, numpy= array([[[ 0, 1, 2, 0, -1, -2], [ 3, 4, 5, -3, -4, -5]], [[ 6, 7, 8, -6, -7, -8], [ 9, 10, 11, -9, -10, -11]]])&gt; . 이는 axis=2와 같다. 이는 -1이 뒤에서 첫번째 숫자를 의미하고 2가 뒤에서 첫번째 숫자(마지막 숫자)이기 때문이다 | . tf.concat([a,b],axis=1) . &lt;tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5], [ 0, -1, -2], [ -3, -4, -5]], [[ 6, 7, 8], [ 9, 10, 11], [ -6, -7, -8], [ -9, -10, -11]]])&gt; . tf.concat([a,b],axis=-2) . &lt;tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy= array([[[ 0, 1, 2], [ 3, 4, 5], [ 0, -1, -2], [ -3, -4, -5]], [[ 6, 7, 8], [ 9, 10, 11], [ -6, -7, -8], [ -9, -10, -11]]])&gt; . 마찬가지로 위 두 코드는 같은 결과를 나타낸다. | . - $(4,)$와 $(4,)$ concat $(8,)$ . a=tf.constant([1,2,3,4]) b=-a a,b . (&lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])&gt;, &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4])&gt;) . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(8,), dtype=int32, numpy=array([ 1, 2, 3, 4, -1, -2, -3, -4])&gt; . tf.concat([a,b],axis=1) . InvalidArgumentError Traceback (most recent call last) Input In [191], in &lt;cell line: 1&gt;() -&gt; 1 tf.concat([a,b],axis=1) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: ConcatOp : Expected concatenating dimensions in the range [-1, 1), but got 1 [Op:ConcatV2] name: concat . axis=0 으로 하면 $2×4$벡터가 만들어져야 하는 거 아닌가? | 즉, axis=1로 해야 길이가 $8$인 벡터가 만들어지는 거 아닌가? | 그런데 심지어 axis=1은 오류까지 뜬다?! | . 이유: $(4,),(4,),(8,)$은 길이가 각각 4,4,8인 튜플(1차원)이기에 애초에 축이 1개만 존재했기 때문이다. 즉 축이 2개가 존재하지 않기에 axis=1은 오류가 나고 축이 하나만 존재(1차원 형태)하기에 axis=0만 가능하다. 따라서 $2×4$ 또는 $4×2$(2차원 형태)는 애초에 불가능하다. | . tf.concat은 dimension(차원)을 변환시킬 수 없다. | . 즉, one dimension $ to$ 결과 one, two dimension $ to$ 결과 two, three dimension $ to$ 결과 three . dimension(차원)을 변환시키려면 다음과 같이 tf.stack을 사용해야 한다. . tf.stack . - $(4)$ 벡터와 $(4)$ 벡터를 concat해서 $(4,2)$ 벡터로 만든다 . $(4, )$ stack $(4, )$ $ to$ $(4,2)$ : 두 번째 축을 비어있다고 인식 | . a=tf.stack([1,2,3,4]) b=-a a,b . (&lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])&gt;, &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4])&gt;) . tf.stack? . Signature: tf.stack(values, axis=0, name=&#39;stack&#39;) Docstring: Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor. See also `tf.concat`, `tf.tile`, `tf.repeat`. Packs the list of tensors in `values` into a tensor with rank one higher than each tensor in `values`, by packing them along the `axis` dimension. Given a list of length `N` of tensors of shape `(A, B, C)`; if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`. if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`. Etc. For example: &gt;&gt;&gt; x = tf.constant([1, 4]) &gt;&gt;&gt; y = tf.constant([2, 5]) &gt;&gt;&gt; z = tf.constant([3, 6]) &gt;&gt;&gt; tf.stack([x, y, z]) &lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy= array([[1, 4], [2, 5], [3, 6]], dtype=int32)&gt; &gt;&gt;&gt; tf.stack([x, y, z], axis=1) &lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy= array([[1, 2, 3], [4, 5, 6]], dtype=int32)&gt; This is the opposite of unstack. The numpy equivalent is `np.stack` &gt;&gt;&gt; np.array_equal(np.stack([x, y, z]), tf.stack([x, y, z])) True Args: values: A list of `Tensor` objects with the same shape and type. axis: An `int`. The axis to stack along. Defaults to the first dimension. Negative values wrap around, so the valid range is `[-(R+1), R+1)`. name: A name for this operation (optional). Returns: output: A stacked `Tensor` with the same type as `values`. Raises: ValueError: If `axis` is out of the range [-(R+1), R+1). File: c: users kko anaconda3 envs ds2022 lib site-packages tensorflow python ops array_ops.py Type: function . tf.stack()은 default가 axis=0이다 | . tf.stack([a,b]) . &lt;tf.Tensor: shape=(2, 4), dtype=int32, numpy= array([[ 1, 2, 3, 4], [-1, -2, -3, -4]])&gt; . tf.stack([a,b],axis=0) . &lt;tf.Tensor: shape=(2, 4), dtype=int32, numpy= array([[ 1, 2, 3, 4], [-1, -2, -3, -4]])&gt; . 따라서 위 두 코드가 같다 | . tf.stack([a,b],axis=1) . &lt;tf.Tensor: shape=(4, 2), dtype=int32, numpy= array([[ 1, -1], [ 2, -2], [ 3, -3], [ 4, -4]])&gt; . - $(4)$ 벡터와 $(4)$ 벡터를 concat해서 $(4,2)$ 벡터로 만든다 . $(4, )$ stack $(4, )$ $ to$ $(4,2)$ : 두 번째 축을 비어있다고 인식 | . tf.stack([a,b],axis=0) . &lt;tf.Tensor: shape=(2, 4), dtype=int32, numpy= array([[ 1, 2, 3, 4], [-1, -2, -3, -4]])&gt; . - (2,3,4,5) stack (2,3,4,5) $ to$ (2,2,3,4,5) : 첫 번째 축이 비어있다고 인식 . a=tf.reshape(tf.constant(range(2*3*4*5)),(2,3,4,5)) b=-a a,b . (&lt;tf.Tensor: shape=(2, 3, 4, 5), dtype=int32, numpy= array([[[[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [ 10, 11, 12, 13, 14], [ 15, 16, 17, 18, 19]], [[ 20, 21, 22, 23, 24], [ 25, 26, 27, 28, 29], [ 30, 31, 32, 33, 34], [ 35, 36, 37, 38, 39]], [[ 40, 41, 42, 43, 44], [ 45, 46, 47, 48, 49], [ 50, 51, 52, 53, 54], [ 55, 56, 57, 58, 59]]], [[[ 60, 61, 62, 63, 64], [ 65, 66, 67, 68, 69], [ 70, 71, 72, 73, 74], [ 75, 76, 77, 78, 79]], [[ 80, 81, 82, 83, 84], [ 85, 86, 87, 88, 89], [ 90, 91, 92, 93, 94], [ 95, 96, 97, 98, 99]], [[100, 101, 102, 103, 104], [105, 106, 107, 108, 109], [110, 111, 112, 113, 114], [115, 116, 117, 118, 119]]]])&gt;, &lt;tf.Tensor: shape=(2, 3, 4, 5), dtype=int32, numpy= array([[[[ 0, -1, -2, -3, -4], [ -5, -6, -7, -8, -9], [ -10, -11, -12, -13, -14], [ -15, -16, -17, -18, -19]], [[ -20, -21, -22, -23, -24], [ -25, -26, -27, -28, -29], [ -30, -31, -32, -33, -34], [ -35, -36, -37, -38, -39]], [[ -40, -41, -42, -43, -44], [ -45, -46, -47, -48, -49], [ -50, -51, -52, -53, -54], [ -55, -56, -57, -58, -59]]], [[[ -60, -61, -62, -63, -64], [ -65, -66, -67, -68, -69], [ -70, -71, -72, -73, -74], [ -75, -76, -77, -78, -79]], [[ -80, -81, -82, -83, -84], [ -85, -86, -87, -88, -89], [ -90, -91, -92, -93, -94], [ -95, -96, -97, -98, -99]], [[-100, -101, -102, -103, -104], [-105, -106, -107, -108, -109], [-110, -111, -112, -113, -114], [-115, -116, -117, -118, -119]]]])&gt;) . tf.stack([a,b],axis=0) . &lt;tf.Tensor: shape=(2, 2, 3, 4, 5), dtype=int32, numpy= array([[[[[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [ 10, 11, 12, 13, 14], [ 15, 16, 17, 18, 19]], [[ 20, 21, 22, 23, 24], [ 25, 26, 27, 28, 29], [ 30, 31, 32, 33, 34], [ 35, 36, 37, 38, 39]], [[ 40, 41, 42, 43, 44], [ 45, 46, 47, 48, 49], [ 50, 51, 52, 53, 54], [ 55, 56, 57, 58, 59]]], [[[ 60, 61, 62, 63, 64], [ 65, 66, 67, 68, 69], [ 70, 71, 72, 73, 74], [ 75, 76, 77, 78, 79]], [[ 80, 81, 82, 83, 84], [ 85, 86, 87, 88, 89], [ 90, 91, 92, 93, 94], [ 95, 96, 97, 98, 99]], [[ 100, 101, 102, 103, 104], [ 105, 106, 107, 108, 109], [ 110, 111, 112, 113, 114], [ 115, 116, 117, 118, 119]]]], [[[[ 0, -1, -2, -3, -4], [ -5, -6, -7, -8, -9], [ -10, -11, -12, -13, -14], [ -15, -16, -17, -18, -19]], [[ -20, -21, -22, -23, -24], [ -25, -26, -27, -28, -29], [ -30, -31, -32, -33, -34], [ -35, -36, -37, -38, -39]], [[ -40, -41, -42, -43, -44], [ -45, -46, -47, -48, -49], [ -50, -51, -52, -53, -54], [ -55, -56, -57, -58, -59]]], [[[ -60, -61, -62, -63, -64], [ -65, -66, -67, -68, -69], [ -70, -71, -72, -73, -74], [ -75, -76, -77, -78, -79]], [[ -80, -81, -82, -83, -84], [ -85, -86, -87, -88, -89], [ -90, -91, -92, -93, -94], [ -95, -96, -97, -98, -99]], [[-100, -101, -102, -103, -104], [-105, -106, -107, -108, -109], [-110, -111, -112, -113, -114], [-115, -116, -117, -118, -119]]]]])&gt; . - (2,3,4,5) stack (2,3,4,5) . 두 번째 축이 비어있다고 인식 | (2,?,3,4,5) stack (2,?,3,4,5) $ to$ (2,2,3,4,5) | . tf.stack([a,b],axis=1) . &lt;tf.Tensor: shape=(2, 2, 3, 4, 5), dtype=int32, numpy= array([[[[[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [ 10, 11, 12, 13, 14], [ 15, 16, 17, 18, 19]], [[ 20, 21, 22, 23, 24], [ 25, 26, 27, 28, 29], [ 30, 31, 32, 33, 34], [ 35, 36, 37, 38, 39]], [[ 40, 41, 42, 43, 44], [ 45, 46, 47, 48, 49], [ 50, 51, 52, 53, 54], [ 55, 56, 57, 58, 59]]], [[[ 0, -1, -2, -3, -4], [ -5, -6, -7, -8, -9], [ -10, -11, -12, -13, -14], [ -15, -16, -17, -18, -19]], [[ -20, -21, -22, -23, -24], [ -25, -26, -27, -28, -29], [ -30, -31, -32, -33, -34], [ -35, -36, -37, -38, -39]], [[ -40, -41, -42, -43, -44], [ -45, -46, -47, -48, -49], [ -50, -51, -52, -53, -54], [ -55, -56, -57, -58, -59]]]], [[[[ 60, 61, 62, 63, 64], [ 65, 66, 67, 68, 69], [ 70, 71, 72, 73, 74], [ 75, 76, 77, 78, 79]], [[ 80, 81, 82, 83, 84], [ 85, 86, 87, 88, 89], [ 90, 91, 92, 93, 94], [ 95, 96, 97, 98, 99]], [[ 100, 101, 102, 103, 104], [ 105, 106, 107, 108, 109], [ 110, 111, 112, 113, 114], [ 115, 116, 117, 118, 119]]], [[[ -60, -61, -62, -63, -64], [ -65, -66, -67, -68, -69], [ -70, -71, -72, -73, -74], [ -75, -76, -77, -78, -79]], [[ -80, -81, -82, -83, -84], [ -85, -86, -87, -88, -89], [ -90, -91, -92, -93, -94], [ -95, -96, -97, -98, -99]], [[-100, -101, -102, -103, -104], [-105, -106, -107, -108, -109], [-110, -111, -112, -113, -114], [-115, -116, -117, -118, -119]]]]])&gt; . - (2,3,4,5) stack (2,3,4,5) . 마지막 축이 비어있다고 인식 | (2,3,4,5,?) stack (2,3,4,5,?) $ to$ (2,3,4,5,2) | . tf.stack([a,b],axis=-1) . &lt;tf.Tensor: shape=(2, 3, 4, 5, 2), dtype=int32, numpy= array([[[[[ 0, 0], [ 1, -1], [ 2, -2], [ 3, -3], [ 4, -4]], [[ 5, -5], [ 6, -6], [ 7, -7], [ 8, -8], [ 9, -9]], [[ 10, -10], [ 11, -11], [ 12, -12], [ 13, -13], [ 14, -14]], [[ 15, -15], [ 16, -16], [ 17, -17], [ 18, -18], [ 19, -19]]], [[[ 20, -20], [ 21, -21], [ 22, -22], [ 23, -23], [ 24, -24]], [[ 25, -25], [ 26, -26], [ 27, -27], [ 28, -28], [ 29, -29]], [[ 30, -30], [ 31, -31], [ 32, -32], [ 33, -33], [ 34, -34]], [[ 35, -35], [ 36, -36], [ 37, -37], [ 38, -38], [ 39, -39]]], [[[ 40, -40], [ 41, -41], [ 42, -42], [ 43, -43], [ 44, -44]], [[ 45, -45], [ 46, -46], [ 47, -47], [ 48, -48], [ 49, -49]], [[ 50, -50], [ 51, -51], [ 52, -52], [ 53, -53], [ 54, -54]], [[ 55, -55], [ 56, -56], [ 57, -57], [ 58, -58], [ 59, -59]]]], [[[[ 60, -60], [ 61, -61], [ 62, -62], [ 63, -63], [ 64, -64]], [[ 65, -65], [ 66, -66], [ 67, -67], [ 68, -68], [ 69, -69]], [[ 70, -70], [ 71, -71], [ 72, -72], [ 73, -73], [ 74, -74]], [[ 75, -75], [ 76, -76], [ 77, -77], [ 78, -78], [ 79, -79]]], [[[ 80, -80], [ 81, -81], [ 82, -82], [ 83, -83], [ 84, -84]], [[ 85, -85], [ 86, -86], [ 87, -87], [ 88, -88], [ 89, -89]], [[ 90, -90], [ 91, -91], [ 92, -92], [ 93, -93], [ 94, -94]], [[ 95, -95], [ 96, -96], [ 97, -97], [ 98, -98], [ 99, -99]]], [[[ 100, -100], [ 101, -101], [ 102, -102], [ 103, -103], [ 104, -104]], [[ 105, -105], [ 106, -106], [ 107, -107], [ 108, -108], [ 109, -109]], [[ 110, -110], [ 111, -111], [ 112, -112], [ 113, -113], [ 114, -114]], [[ 115, -115], [ 116, -116], [ 117, -117], [ 118, -118], [ 119, -119]]]]])&gt; . 3&#44060;&#51032; array&#44032; &#51080;&#51012; &#44221;&#50864; . - 예제1: (2,3,4), (2,3,4), (2,3,4) 1) (2,3,4), (2,3,4), (2,3,4) -&gt; (6,3,4) . a=tf.reshape(tf.constant(range(2*3*4)),(2,3,4)) b=-a c=2*a . a, b, c 모두 3차원이고 나타내고자 하는 것도 3차원이니 차원이 늘어나는 것은 아니다 -&gt; tf.stack가 아닌 tf.concat을 사용 . tf.concat([a,b,c],axis=0) . &lt;tf.Tensor: shape=(6, 3, 4), dtype=int32, numpy= array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[ 12, 13, 14, 15], [ 16, 17, 18, 19], [ 20, 21, 22, 23]], [[ 0, -1, -2, -3], [ -4, -5, -6, -7], [ -8, -9, -10, -11]], [[-12, -13, -14, -15], [-16, -17, -18, -19], [-20, -21, -22, -23]], [[ 0, 2, 4, 6], [ 8, 10, 12, 14], [ 16, 18, 20, 22]], [[ 24, 26, 28, 30], [ 32, 34, 36, 38], [ 40, 42, 44, 46]]])&gt; . 6×3×4가 되었음 | . - 2. (2,3,4), (2,3,4), (2,3,4) -&gt; (2,9,4) . tf.concat([a,b,c],axis=1) . &lt;tf.Tensor: shape=(2, 9, 4), dtype=int32, numpy= array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [ 0, -1, -2, -3], [ -4, -5, -6, -7], [ -8, -9, -10, -11], [ 0, 2, 4, 6], [ 8, 10, 12, 14], [ 16, 18, 20, 22]], [[ 12, 13, 14, 15], [ 16, 17, 18, 19], [ 20, 21, 22, 23], [-12, -13, -14, -15], [-16, -17, -18, -19], [-20, -21, -22, -23], [ 24, 26, 28, 30], [ 32, 34, 36, 38], [ 40, 42, 44, 46]]])&gt; . - 3. (2,3,4), (2,3,4), (2,3,4) -&gt; (2,3,12) . tf.concat([a,b,c],axis=2) . &lt;tf.Tensor: shape=(2, 3, 12), dtype=int32, numpy= array([[[ 0, 1, 2, 3, 0, -1, -2, -3, 0, 2, 4, 6], [ 4, 5, 6, 7, -4, -5, -6, -7, 8, 10, 12, 14], [ 8, 9, 10, 11, -8, -9, -10, -11, 16, 18, 20, 22]], [[ 12, 13, 14, 15, -12, -13, -14, -15, 24, 26, 28, 30], [ 16, 17, 18, 19, -16, -17, -18, -19, 32, 34, 36, 38], [ 20, 21, 22, 23, -20, -21, -22, -23, 40, 42, 44, 46]]])&gt; . - 예제2: (2,3,4), (2,3,4), (2,3,4) 1) (2,3,4), (2,3,4), (2,3,4) -&gt; (3,2,3,4) -&gt; axis=0 . a, b, c 모두 3차원이지만 나타내고자 하는 것은 4차원이니 차원이 늘어난다 -&gt; tf.stack 사용 . tf.stack([a,b,c],axis=0) . &lt;tf.Tensor: shape=(3, 2, 3, 4), dtype=int32, numpy= array([[[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[ 12, 13, 14, 15], [ 16, 17, 18, 19], [ 20, 21, 22, 23]]], [[[ 0, -1, -2, -3], [ -4, -5, -6, -7], [ -8, -9, -10, -11]], [[-12, -13, -14, -15], [-16, -17, -18, -19], [-20, -21, -22, -23]]], [[[ 0, 2, 4, 6], [ 8, 10, 12, 14], [ 16, 18, 20, 22]], [[ 24, 26, 28, 30], [ 32, 34, 36, 38], [ 40, 42, 44, 46]]]])&gt; . 2) (2,3,4), (2,3,4), (2,3,4) -&gt; (2,3,3,4) -&gt; axis=1 . tf.stack([a,b,c],axis=1) . &lt;tf.Tensor: shape=(2, 3, 3, 4), dtype=int32, numpy= array([[[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[ 0, -1, -2, -3], [ -4, -5, -6, -7], [ -8, -9, -10, -11]], [[ 0, 2, 4, 6], [ 8, 10, 12, 14], [ 16, 18, 20, 22]]], [[[ 12, 13, 14, 15], [ 16, 17, 18, 19], [ 20, 21, 22, 23]], [[-12, -13, -14, -15], [-16, -17, -18, -19], [-20, -21, -22, -23]], [[ 24, 26, 28, 30], [ 32, 34, 36, 38], [ 40, 42, 44, 46]]]])&gt; . 3) (2,3,4), (2,3,4), (2,3,4) -&gt; (2,3,3,4) -&gt; axis=2 . tf.stack([a,b,c],axis=2) . &lt;tf.Tensor: shape=(2, 3, 3, 4), dtype=int32, numpy= array([[[[ 0, 1, 2, 3], [ 0, -1, -2, -3], [ 0, 2, 4, 6]], [[ 4, 5, 6, 7], [ -4, -5, -6, -7], [ 8, 10, 12, 14]], [[ 8, 9, 10, 11], [ -8, -9, -10, -11], [ 16, 18, 20, 22]]], [[[ 12, 13, 14, 15], [-12, -13, -14, -15], [ 24, 26, 28, 30]], [[ 16, 17, 18, 19], [-16, -17, -18, -19], [ 32, 34, 36, 38]], [[ 20, 21, 22, 23], [-20, -21, -22, -23], [ 40, 42, 44, 46]]]])&gt; . 4) (2,3,4), (2,3,4), (2,3,4) -&gt; (2,3,4,3) -&gt; axis=3 . tf.stack([a,b,c],axis=3) . &lt;tf.Tensor: shape=(2, 3, 4, 3), dtype=int32, numpy= array([[[[ 0, 0, 0], [ 1, -1, 2], [ 2, -2, 4], [ 3, -3, 6]], [[ 4, -4, 8], [ 5, -5, 10], [ 6, -6, 12], [ 7, -7, 14]], [[ 8, -8, 16], [ 9, -9, 18], [ 10, -10, 20], [ 11, -11, 22]]], [[[ 12, -12, 24], [ 13, -13, 26], [ 14, -14, 28], [ 15, -15, 30]], [[ 16, -16, 32], [ 17, -17, 34], [ 18, -18, 36], [ 19, -19, 38]], [[ 20, -20, 40], [ 21, -21, 42], [ 22, -22, 44], [ 23, -23, 46]]]])&gt; . - 예제3: (2,3,4), (4,3,4) -&gt; (6,3,4) . a=tf.reshape(tf.constant(range(2*3*4)),(2,3,4)) b=tf.reshape(-tf.constant(range(4*3*4)),(4,3,4)) . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(6, 3, 4), dtype=int32, numpy= array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[ 12, 13, 14, 15], [ 16, 17, 18, 19], [ 20, 21, 22, 23]], [[ 0, -1, -2, -3], [ -4, -5, -6, -7], [ -8, -9, -10, -11]], [[-12, -13, -14, -15], [-16, -17, -18, -19], [-20, -21, -22, -23]], [[-24, -25, -26, -27], [-28, -29, -30, -31], [-32, -33, -34, -35]], [[-36, -37, -38, -39], [-40, -41, -42, -43], [-44, -45, -46, -47]]])&gt; . tf.concat([a,b],axis=1) . InvalidArgumentError Traceback (most recent call last) Input In [22], in &lt;cell line: 1&gt;() -&gt; 1 tf.concat([a,b],axis=1) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: ConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [2,3,4] vs. shape[1] = [4,3,4] [Op:ConcatV2] name: concat . tf.concat([a,b],axis=2) . InvalidArgumentError Traceback (most recent call last) Input In [23], in &lt;cell line: 1&gt;() -&gt; 1 tf.concat([a,b],axis=2) File ~ anaconda3 envs ds2022 lib site-packages tensorflow python util traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~ anaconda3 envs ds2022 lib site-packages tensorflow python framework ops.py:7186, in raise_from_not_ok_status(e, name) 7184 def raise_from_not_ok_status(e, name): 7185 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7186 raise core._status_to_exception(e) from None InvalidArgumentError: ConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [2,3,4] vs. shape[1] = [4,3,4] [Op:ConcatV2] name: concat . 위 두 코드는 차원이 맞지 않아 오류가 난다. | .",
            "url": "https://ki5n2.github.io/charcoal/2022/03/18/DS.html",
            "relUrl": "/2022/03/18/DS.html",
            "date": " • Mar 18, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "DS 1. 단순선형회귀",
            "content": ". Data Science . lenture: Data Science_1nd week of lectures. | lenture date: 2022-03-07 | lecturer: Guebin choi | study date: 2022-03-16 | author: Kione kim | . . 이번 학기동안 배울 것: DNN(심층신경망), CNN(합성곱신경망), GAN(적대적생성신경망)인데, DNN을 바로 이해하기 어렵다. . | 따라서 다음의 과정을 학습한 후 심층 신경망으로 넘어갈 예정: (선형대수학 $ to$) 회귀분석 $ to$ 로지스틱회귀분석 $ to$ 심층신경망 . | . &#49440;&#54805;&#54924;&#44480; . - 카페 예제 . 온도가 높아지면 아이스아메리카노의 판매량이 증가한다는 사실을 알게 되었다. | 일기예보를 통해, 온도 $ to$ 아이스아메리카노 판매량 예측을 하고 싶다. | . import matplotlib.pyplot as plt import tensorflow as tf import numpy as np . - 자료생성 . x=tf.constant([20.1,22.2,22.7,23.3,24.4,25.1,26.2,27.3,28.4,30.4]) x . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4], dtype=float32)&gt; . x와 y의 관계는 다음과 같이 가정 $${ bf y} approx 10.2 + 2.2{ bf x}$$ . tf.random.set_seed(50000) epsilon = tf.random.normal([10]) y = 10.2 + 2.2*x + epsilon y . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([53.68625 , 60.12511 , 58.93714 , 60.65312 , 64.45385 , 66.9807 , 67.960144, 70.73565 , 72.87779 , 77.54677 ], dtype=float32)&gt; . x . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4], dtype=float32)&gt; . y . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([53.68625 , 60.12511 , 58.93714 , 60.65312 , 64.45385 , 66.9807 , 67.960144, 70.73565 , 72.87779 , 77.54677 ], dtype=float32)&gt; . data = tf.transpose(tf.concat([[x],[y]],0)) data . &lt;tf.Tensor: shape=(10, 2), dtype=float32, numpy= array([[20.1 , 53.68625 ], [22.2 , 60.12511 ], [22.7 , 58.93714 ], [23.3 , 60.65312 ], [24.4 , 64.45385 ], [25.1 , 66.9807 ], [26.2 , 67.960144], [27.3 , 70.73565 ], [28.4 , 72.87779 ], [30.4 , 77.54677 ]], dtype=float32)&gt; . plt.plot(x,y,&#39;.&#39;) plt.plot(x,10.2+2.2*x,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x1a1b1b0d340&gt;] . 파란색 점: 데이터, 주황색 점선: 법칙 | 위 그림을 보니 $x$와 $y$가 선형관계가 있는 것처럼 보인다. 즉 아래의 식을 만족하는 $ beta_0, beta_1$가 있을 것 같다. | $y_{i} approx beta_1 x_{i}+ beta_0$ | . data . &lt;tf.Tensor: shape=(10, 2), dtype=float32, numpy= array([[20.1 , 53.68625 ], [22.2 , 60.12511 ], [22.7 , 58.93714 ], [23.3 , 60.65312 ], [24.4 , 64.45385 ], [25.1 , 66.9807 ], [26.2 , 67.960144], [27.3 , 70.73565 ], [28.4 , 72.87779 ], [30.4 , 77.54677 ]], dtype=float32)&gt; . - 점원 A는 $ beta_0=15, beta_1=2$일 것이라고 주장하였고 점원 B는 $ beta_0=15.5, beta_1=2$일 것이라고 주장하였다. . 점원 A: $( beta_0, beta_1)$ = $(15,2)$ | 점원 B: $( beta_0, beta_1)$ = $(15.5,2)$ | . &#51092;&#52264;&#51228;&#44273;&#54633; . - $y_{i} approx beta_0 + beta_1$을 최소로 하는 $( beta_0, beta_1)$을 찾아보자 . - 잔체제곱합을 통한 점원 A, 점원 B 추정치 비교 . 20.1*2 + 15, 53.68625 . (55.2, 53.68625) . 22.2*2 + 15, 60.12511 . (59.4, 60.12511) . 20.1*2 + 15.5, 53.68625 . (55.7, 53.68625) . 22.2*2 + 15.5, 60.12511 . (59.9, 60.12511) . $i=1$일 때 점원 A의 주장이 더 잘 맞고 $i=2$일 때 점원 B의 주장이 더 잘 맞는다. | . - for 문을 사용하여 $ sum_{i=1}^{10} (y_i - beta_0 - beta_1 x_i)^2$를 계산하여 비교해보자 . sum1=0 for i in range(10): sum1=sum1+(y[i]-15-2*x[i])**2 . sum2=0 for i in range(10): sum2=sum2+(y[i]-15.5-2*x[i])**2 . sum1 . &lt;tf.Tensor: shape=(), dtype=float32, numpy=15.268475&gt; . sum2 . &lt;tf.Tensor: shape=(), dtype=float32, numpy=14.011955&gt; . 점원 B의 추정치의 잔차제곱합이 조금 더 작다 $ to$ 점원 B의 주장이 더 적합하다 | 이 과정을 반복하면 최적의 추정치를 계산해낼 수 있을 것 같다. | . - 그러나 현실적으로 구현하기 어렵다 . : 왜냐하면 잔차제곱합이 0이 되지 않는다면, 무엇이 최적의 추정치인지 알 수 없다. 잔차제곱합이 0이 아니라면 항상 더 적합한 추정치가 있을 수도 있기 때문 . - 수식을 활용하여 찾아볼 수 있다 . $ sum_{i=1}^{10} (y_i - beta_0 - beta_1 x_i)^2$를 최소화하는 $ beta_0, beta_1$을 찾으면 되는데, 이는 아래와 같이 $ beta_0, beta_1$으로 각각 편미분하여 연립하여 풀면 된다. . $ begin{cases} frac{ partial}{ partial beta_0} sum_{i=1}^{10} (y_i - beta_0 - beta_1 x_i)^2=0 frac{ partial}{ partial beta_1} sum_{i=1}^{10} (y_i - beta_0 - beta_1 x_i)^2=0 end{cases}$ . 위 연립방정식을 편미분하면 다음과 같이 된다. . $ begin{cases} sum_{i=1}^{10} -2(y_i - beta_0 - beta_1 x_i)=0 sum_{i=1}^{10} -2x_i(y_i - beta_0 - beta_1 x_i)=0 end{cases}$ . 이를 정리하면 . $$ hat{ beta}_0= bar{y}- hat{ beta}_1 bar{x}$$ . $$ hat{ beta}_1= frac{S_{xy}}{S_{xx}}= frac{ sum_{i=1}^{n}(x_i- bar{x})(y_i- bar{y})}{ sum_{i=1}^{n}(x_i- bar{x})^2}$$ . 최적의 추정치$( hat{ beta}_0, hat{ beta}_1)$를 구할 수 있고 이를 통해 추세선을 그려볼 수 있다 . - 추정치는 다음과 같이 구할 수 있다. . Sxx = sum((x-np.mean(x))**2) Sxx . &lt;tf.Tensor: shape=(), dtype=float32, numpy=87.84898&gt; . Sxy = sum((x-np.mean(x))*(y-np.mean(y))) Sxy . &lt;tf.Tensor: shape=(), dtype=float32, numpy=202.18872&gt; . beta_1_est = Sxy/Sxx beta_1_est . &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.3015487&gt; . beta_0_est = np.mean(y) - beta_1_est*np.mean(x) beta_0_est . &lt;tf.Tensor: shape=(), dtype=float32, numpy=7.8339195&gt; . - 그림을 그려보자 . plt.plot(x,y,&#39;.&#39;) plt.plot(x,beta_0_est + beta_1_est*x,&#39;--&#39;) plt.plot(x,10.2+2.2*x,&#39;--&#39;) # 세상의 법칙 . [&lt;matplotlib.lines.Line2D at 0x1a1b1b5cee0&gt;] . - 샘플수가 커질수록 주황색 선은 점점 초록색 선과 유사해진다. . 이는 매우 좋은 접근법이지만, 확장성이 떨어진다는 치명적 단점이 있다 | . - 매트릭스를 통해 확장성을 개선할 수 있다 . &#47784;&#54805;&#51032; &#47588;&#53944;&#47533;&#49828;&#54868; . - 우리의 모형 . $y_i = beta_0 + beta_1 x_i + epsilon_i, quad i=1,2, dots,10$ . 이를 풀어서 쓰면 . $ begin{cases} y_1 = beta_0 + beta_1 x_1 + epsilon_1 y_2 = beta_0 + beta_1 x_2 + epsilon_2 dots y_{10} = beta_0 + beta_1 x_{10} + epsilon_{10} end{cases}$ . 아래와 같다. . $ begin{bmatrix} y_1 y_2 dots y_{10} end{bmatrix} = begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 dots &amp; dots 1 &amp; x_{10} end{bmatrix} begin{bmatrix} beta_0 beta_1 end{bmatrix} + begin{bmatrix} epsilon_1 epsilon_2 dots epsilon_{10} end{bmatrix} $ . 벡터와 매트릭스 형태로 표현하면 . ${ bf y} = { bf X} { boldsymbol beta} + boldsymbol{ epsilon}$ . - 손실함수의 매트릭스화 . $loss= sum_{i=1}^{n}(y_i- beta_0- beta_1x_i)^2$ . 이를 벡터로 표현하면, . $loss=({ bf y}-{ bf X}{ boldsymbol beta})^ top({ bf y}-{ bf X}{ boldsymbol beta})={ bf y}^ top { bf y} - { bf y}^ top { bf X}{ boldsymbol beta} - { boldsymbol beta}^ top { bf X}^ top { bf y} + { boldsymbol beta}^ top { bf X}^ top { bf X} { boldsymbol beta}$ . - 미분하는 과정의 매트릭스화 . loss를 최소화하는 ${ boldsymbol beta}$를 구해야하므로 loss를 ${ boldsymbol beta}$로 미분한식을 0이라고 놓고 풀면 된다. . $ frac{ partial}{ partial boldsymbol{ beta}} loss = frac{ partial}{ partial boldsymbol{ beta}} { bf y}^ top { bf y} - frac{ partial}{ partial boldsymbol{ beta}} { bf y}^ top { bf X}{ boldsymbol beta} - frac{ partial}{ partial boldsymbol{ beta}} { boldsymbol beta}^ top { bf X}^ top { bf y} + frac{ partial}{ partial boldsymbol{ beta}} { boldsymbol beta}^ top { bf X}^ top { bf X} { boldsymbol beta}$ . $= 0 - { bf X}^ top { bf y}- { bf X}^ top { bf y} + 2{ bf X}^ top { bf X} = - 2{ bf X}^ top { bf y} + 2{ bf X}^ top { bf X}{ boldsymbol beta} $ . 따라서 $ frac{ partial}{ partial boldsymbol{ beta}}loss=0$을 풀면 아래와 같다. . $ 2{ bf X}^ top { bf y} = 2{ bf X}^ top { bf X}{ boldsymbol beta}$ . $ { bf X}^ top { bf X}{ boldsymbol beta} = { bf X}^ top { bf y}$ . $ boldsymbol{ hat beta}= ({ bf X}^ top { bf X})^{-1}{ bf X}^ top { bf y} $ . - 적용 . x=tf.constant([20.1,22.2,22.7,23.3,24.4,25.1,26.2,27.3,28.4,30.4]) x . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4], dtype=float32)&gt; . tf.random.set_seed(50000) epsilon = tf.random.normal([10]) y = 10.2 + 2.2*x + epsilon y . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([53.68625 , 60.12511 , 58.93714 , 60.65312 , 64.45385 , 66.9807 , 67.960144, 70.73565 , 72.87779 , 77.54677 ], dtype=float32)&gt; . - 방법 1 . tf.concat([[[1]*10],[x]],0) . &lt;tf.Tensor: shape=(2, 10), dtype=int32, numpy= array([[ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [20, 22, 22, 23, 24, 25, 26, 27, 28, 30]])&gt; . X = tf.transpose(tf.concat([[[1]*10],[x]],0)) X . &lt;tf.Tensor: shape=(10, 2), dtype=int32, numpy= array([[ 1, 20], [ 1, 22], [ 1, 22], [ 1, 23], [ 1, 24], [ 1, 25], [ 1, 26], [ 1, 27], [ 1, 28], [ 1, 30]])&gt; . - 방법 2 . from tensorflow.python.ops.numpy_ops import np_config np_config.enable_numpy_behavior() . X = tf.concat([[[1.0]*10],[x]],0).T X . &lt;tf.Tensor: shape=(10, 2), dtype=float32, numpy= array([[ 1. , 20.1], [ 1. , 22.2], [ 1. , 22.7], [ 1. , 23.3], [ 1. , 24.4], [ 1. , 25.1], [ 1. , 26.2], [ 1. , 27.3], [ 1. , 28.4], [ 1. , 30.4]], dtype=float32)&gt; . $ boldsymbol{ hat beta}= ({ bf X}^ top { bf X})^{-1}{ bf X}^ top { bf y} $ . - 깨알문법 . 역행렬 tf.linalg.inv사용 2.행렬 간 곱 @ 사용 | tf.linalg.inv(X.T @ X) @X.T @y . &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([7.834038 , 2.3015506], dtype=float32)&gt; . beta_0_est, beta_1_est . (&lt;tf.Tensor: shape=(), dtype=float32, numpy=7.8339195&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.3015487&gt;) . 그런데 값이 다르다...? . | 이유는 텐서플로우가 효율적 계산을 위해 조금 대충 계산하기 때문 . | . - 텐서플로우 내에 내장되어 있는 텐서플로우용 넘파이를 이용하여 다시 계산해보자 . import tensorflow.experimental.numpy as tnp . x=tf.constant([20.1,22.2,22.7,23.3,24.4,25.1,26.2,27.3,28.4,30.4]) x . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4], dtype=float32)&gt; . y = 10.2 + 2.2*x + epsilon y . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([53.68625 , 60.12511 , 58.93714 , 60.65312 , 64.45385 , 66.9807 , 67.960144, 70.73565 , 72.87779 , 77.54677 ], dtype=float32)&gt; . - 공식을 이용한 풀이 . beta1_est = sum((x-np.mean(x))*(y-np.mean(y))) / sum((x-np.mean(x))**2) ## Sxy/Sxx beta0_est = np.mean(y) - beta1_est * np.mean(x) . beta0_est, beta1_est . (&lt;tf.Tensor: shape=(), dtype=float32, numpy=7.8339195&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.3015487&gt;) . - 벡터를 이용한 풀이 . X = tnp.concatenate([[tnp.array([1.0]*10)],[x]],0).T X . &lt;tf.Tensor: shape=(10, 2), dtype=float64, numpy= array([[ 1. , 20.10000038], [ 1. , 22.20000076], [ 1. , 22.70000076], [ 1. , 23.29999924], [ 1. , 24.39999962], [ 1. , 25.10000038], [ 1. , 26.20000076], [ 1. , 27.29999924], [ 1. , 28.39999962], [ 1. , 30.39999962]])&gt; . tf.linalg.inv(X.T @ X) @X.T @ y . &lt;tf.Tensor: shape=(2,), dtype=float64, numpy=array([7.83391429, 2.30154889])&gt; . 거의 유사한 값이 나온다 | . &#44208;&#47200; . 벡터를 이용하여 tf.linalg.inv(X.T @ X) @X.T @ y를 계산하면 바로 $ beta$값이 바로 나온다. .",
            "url": "https://ki5n2.github.io/charcoal/2022/03/16/DS.html",
            "relUrl": "/2022/03/16/DS.html",
            "date": " • Mar 16, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://ki5n2.github.io/charcoal/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ki5n2.github.io/charcoal/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}