{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e91ad2-4552-485f-a06e-a8ef69a8b0d4",
   "metadata": {},
   "source": [
    "# DS 10. 우도함수& 최대우도추정량\n",
    "\n",
    "> \"작성완료\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- [python, Data Science]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d00fd1-b15c-4bef-8b91-04cb17c597a9",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Science\n",
    "- lenture: Data Science_9-1nd week of lectures.\n",
    "- lenture date: 2022-04-27\n",
    "- lecturer: Guebin choi\n",
    "- study date: 2022-05-02, 2022-05-03\n",
    "- author: Kione kim\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a2fff5-eb0d-4a94-82e5-71b0a33b7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import tensorflow.experimental.numpy as tnp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "222a89bf-d3d0-481a-ab21-bdc62106060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tnp.experimental_enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d4af24-0c47-46f0-aa33-51377e299168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78095799-33ff-4fc7-970b-86605ce77381",
   "metadata": {},
   "source": [
    "## 우도함수(가능도함수)와 최대우도(가능도)추정량"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc9539-2017-417b-ad83-538af5f0a20c",
   "metadata": {},
   "source": [
    "**(예제)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a779ecdf-6d4a-481e-9697-d92700ccf8a2",
   "metadata": {},
   "source": [
    "$X_i \\overset{iid}{\\sim} Ber(p)$에서 얻은 샘플이 아래와 같다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f6a129e-33d6-46df-b165-496ac2c35651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[0,1,0,1] \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c286c-30c4-4c39-85b9-6a2d70ddb47e",
   "metadata": {},
   "source": [
    "`(질문1)` $p$는 얼마일까? \n",
    "- 0.5이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c96ec0-25b0-4538-b30c-8798105707ec",
   "metadata": {},
   "source": [
    "왜 그렇게 답할 수 있을까? \n",
    "- $p$가 0.5라고 주장할 수 있는 이론적 근거 또는 논리체계가 무엇일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fce649-38db-4305-a696-a9d3f0f718ae",
   "metadata": {},
   "source": [
    "`(추측)` $p=0.1$ 이라 가정하자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e0ee6-59a0-419a-ae1c-9decd4876ae7",
   "metadata": {},
   "source": [
    "위 가정하에서 $(x_1,x_2,x_3,x_4)=(0,1,0,1)$의 샘플이 얻어질 확률은 아래와 같다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3edc0b2-1002-4455-bab7-16301f551eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008100000000000001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9 * 0.1 * 0.9 * 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230c0b9b-c659-4823-b9a8-78ea802a528b",
   "metadata": {},
   "source": [
    "`(추측)` $p=0.2$ 이라 가정하자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d21332e-a97d-4c36-95d1-8920f52c99b4",
   "metadata": {},
   "source": [
    "위 가정하에서 $(x_1,x_2,x_3,x_4)=(0,1,0,1)$의 샘플이 얻어질 확률은 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "946f225d-7e9d-4519-bbea-c12cf94bebca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025600000000000008"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8 * 0.2 * 0.8 * 0.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d869fd-7606-4010-b901-d2431b231595",
   "metadata": {},
   "source": [
    "`(질문2)` $p=0.1$일까 $p=0.2$일까? \n",
    "- $p=0.2$이다.\n",
    "- 왜? $p=0.2$일 확률(?)이 더 크다..!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c628b757-805b-4240-ad70-c506c3a3e576",
   "metadata": {},
   "source": [
    "***(여기서 잠깐) 확률이라는 말을 함부로 쓸 수 없다.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eb204c-8d2f-4bac-91a8-7d27a4611b60",
   "metadata": {},
   "source": [
    "`-` $0.0256$은 $p=0.2$일 경우 샘플 $(0,1,0,1)$이 얻어질 확률일 뿐 $p=0.2$일 확률을 말하는 것이 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72da761-0d9f-42ce-a64a-b2beb420dfc0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8de3b695-b591-47c7-9a93-6bcd85ed8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "_plist = np.linspace(0.499,0.501,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff2614-cb27-4e16-b0e9-f7913cfc993f",
   "metadata": {},
   "source": [
    "$p=0.499$일 경우 샘플 $(x_1,x_2,x_3,x_4)=(0,1,0,1)$이 얻어질 확률은 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f9f3630-a575-47f6-a0e9-420f2373f959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06249950000099999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-0.499)*0.499*(1-0.499)*0.499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e30dad4-f5bc-46d8-9836-19dc04c7d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_prob = [(1-p)*p*(1-p)*p for p in _plist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bb00cc2-c04b-4c30-9472-822b57a741df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06249950000099999,\n",
       " 0.06249950200099,\n",
       " 0.06249950399697206,\n",
       " 0.06249950598894615,\n",
       " 0.062499507976912276]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_prob[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd3e1f-5fcc-4817-85b9-f90be9ee27e6",
   "metadata": {},
   "source": [
    "- 이는 \n",
    "\n",
    "$p=0.499$일 경우 샘플 $(x_1,x_2,x_3,x_4)=(0,1,0,1)$이 얻어질 확률\n",
    "\n",
    "$p=0.49902$일 경우 샘플 $(x_1,x_2,x_3,x_4)=(0,1,0,1)$이 얻어질 확률\n",
    "\n",
    "$p=0.49904$일 경우 샘플 $(x_1,x_2,x_3,x_4)=(0,1,0,1)$이 얻어질 확률\n",
    "\n",
    "$p=0.49906$일 경우 샘플 $(x_1,x_2,x_3,x_4)=(0,1,0,1)$이 얻어질 확률\n",
    "\n",
    "$p=0.49908$일 경우 샘플 $(x_1,x_2,x_3,x_4)=(0,1,0,1)$이 얻어질 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad34c19-9388-4b43-b106-17be44866028",
   "metadata": {},
   "source": [
    "`-` `p=0.2인 확률`이라는 개념이 성립하려면 아래코드에서 `sum([(1-p)*p*(1-p)*p for p in _plist])`이 1보다 작거나 같아야 한다. (그런데 1보다 크다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "885e58fb-0f6e-402c-acbd-f3b4515b2dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.49983299986714"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_plist = np.linspace(0.499,0.501,1000) \n",
    "sum([(1-p)*p*(1-p)*p for p in _plist])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8adbfe0-ee76-41bd-a92e-62de67d9fc78",
   "metadata": {},
   "source": [
    "`-` 확률이라는 말을 쓸 수 없지만 확률의 느낌은 있음 -> `가능도`(가능한 정도, 그럴 듯한 정도)라는 말을 쓰자. \n",
    "- 0.0256 $=$ $p$가 0.2일 경우 샘플 (0,1,0,1)이 얻어질 확률 $=$ $p$가 0.2일 가능도 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a4aaa8-8ed2-47fa-8516-1e32d779a506",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf2367e-2fb0-44e1-ac74-c43253a4c00d",
   "metadata": {},
   "source": [
    "`-` 다시 질문2로 돌아가자!\n",
    "- 질문2: $p=0.1$일까 $p=0.2$일까? \n",
    "- $p=0.2$이다. $p=0.2$인 가능도가 더 크기 때문!\n",
    "- 질문3: $p=0.2$일까 $p=0.3$일까? \n",
    "- $p=0.3$이다. $p=0.3$인 가능도가 더 크기 때문!\n",
    "- 질문4: ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff51427-a4ed-4878-817c-bc4eed2e254c",
   "metadata": {},
   "source": [
    "`-` 궁극적 질문: $p$값이 무엇일까? \n",
    "- $p$를 입력으로 하면 `가능도`가 계산되는 함수를 만들자.\n",
    "- 그 함수를 최대화하는 $p$를 찾자.\n",
    "- 찾은 $p$가 궁극적 질문에 대한 답이 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a2a69-37cf-4093-ba46-42bdc4dac9c4",
   "metadata": {},
   "source": [
    "`-` 잠깐 용어정리 \n",
    "1. `가능도함수` $=$ `우도함수` $=$ `likelihood function` $:=$ `L(p)`\n",
    "2. `함수를 최대화하는 p` $=$ `p의 maximum likelihood estimator` $=$ `p의 MLE` $:=$ $\\hat{p}^{mle}$ $=$ $\\text{argmax}_p L(p)$ $=$ $\\hat{p}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e716115b-b615-4d9a-8410-c25f1ba0a02d",
   "metadata": {},
   "source": [
    "`-` 예제 풀이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb855e97-df3f-41d7-8a01-0c6f65cf9d0a",
   "metadata": {},
   "source": [
    "`-` 가능도함수 정의 \n",
    "- $L(p)$: `p의 가능도함수` $=$ `p가 모수일때 샘플 (0,1,0,1)이 얻어질 확률` = $p$가 모수일때 $x_1$이 0일 확률 $\\times \\dots \\times$ $p$가 모수일때 $x_4$가 1일 확률 \n",
    "- $L(p)=\\prod_{i=1}^{4} f(x_i;p)= \\prod_{i=1}^{4}p^{x_i}(1-p)^{1-x_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad118c-8471-4e21-8ca6-079e9ccddaf2",
   "metadata": {},
   "source": [
    "`-` 일반화: $X_1,\\dots,X_n \\overset{iid}{\\sim} Ber(p)$ 일때 $p$의 likelihood function은 $\\prod_{i=1}^{n}p^{x_i}(1-p)^{1-x_i}$ 라고 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125f000-40fe-4c06-a14c-4c66ed27b57e",
   "metadata": {},
   "source": [
    "`-` 더 일반화: $x_1,\\dots,x_n$이 pdf가 $f(x)$인 분포에서 뽑힌 서로 독립인 샘플일때 likelihood function은 $\\prod_{i=1}^{n}f(x_i)$라고 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f25a27-cd62-4779-910d-deb295773f3e",
   "metadata": {},
   "source": [
    "`-` 이 예제의 경우 $p$의 최대우도추정량을 구하면 \n",
    "\n",
    "$$\\hat{p}^{mle} = \\text{argmax}_p L(p) = \\text{argmax}_p  \\big\\{ p^2(1-p)^2 \\big\\}= \\frac{1}{2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dabe0e1-d07a-4217-add8-c1fd2bfdb95c",
   "metadata": {},
   "source": [
    "## 중간고사 1번"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d034718-00d0-40ca-8873-88cac28299aa",
   "metadata": {},
   "source": [
    "`(1)` $N(\\mu,\\sigma)$에서 얻은 샘플이 아래와 같다고 할때 $\\mu,\\sigma$의 MLE를 구하여라. \n",
    "```\n",
    "<tf.Tensor: shape=(10000,), dtype=float64, numpy=\n",
    "array([ 4.12539849,  5.46696729,  5.27243374, ...,  2.89712332,\n",
    "        5.01072291, -1.13050477])>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510c8e93-188b-4b5f-a475-1aebfa4ab03f",
   "metadata": {},
   "source": [
    "`(2)` $Ber(p)$에서 얻은 샘플이 아래와 같다고 할 때 $p$의 MLE를 구하여라. \n",
    "```\n",
    "<tf.Tensor: shape=(10000,), dtype=int64, numpy=array([1, 1, 1, ..., 0, 0, 1])>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930de46-d1d9-43b4-a633-866d76652133",
   "metadata": {},
   "source": [
    "`(3)` $y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$,  $\\epsilon_i \\overset{iid}{\\sim} N(0,1)$ 일때 $(\\beta_0,\\beta_1)$의 MLE를 구하여라. (회귀모형)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e2c24e-116f-49d7-89c9-a9aba634f808",
   "metadata": {},
   "source": [
    "(풀이) 우도함수(가능도함수)\n",
    "\n",
    "\n",
    "$$L(\\beta_0,\\beta_1)=\\prod_{i=1}^{n}f(y_i), \\quad f(y_i)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}(y_i-\\mu_i)^2}, \\quad \\mu_i=\\beta_0+\\beta_1 x_i$$\n",
    "\n",
    "를 최대화하는 $\\beta_0,\\beta_1$을 구하면된다. \n",
    "\n",
    "그런데 이것은 아래를 최소화하는 $\\beta_0,\\beta_1$을 구하는 것과 같다. \n",
    "\n",
    "$$-\\log L(\\beta_0,\\beta_1) = \\sum_{i=1}^{n}(y_i-\\beta_0-\\beta_1x_i)^2$$\n",
    "\n",
    "위의 식은 SSE와 같다. 결국 오차항이 정규분포를 따르는 회귀모형의 MLE는 MSE(SSE를 최소화하는 것은 MSE를 최소화하는 것과 같으므로)를 최소화하는 $\\beta_0,\\beta_1$을 구하면 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e977823c-a029-43ef-afd3-db3c3c6ccf41",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 중간고사 1-(3)의 다른 풀이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94d26fcf-9714-446f-be49-794f55183b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= tf.constant(np.arange(1,10001)/10000)\n",
    "y= tnp.random.randn(10000) + (0.5 + 2*x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42b441b0-13fc-4036-8481-72098d608766",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta0= tf.Variable(1.0)\n",
    "beta1= tf.Variable(1.0) \n",
    "for i in range(2000):\n",
    "    with tf.GradientTape() as tape: \n",
    "        #minus_log_likelihood = tf.reduce_sum((y-beta0-beta1*x)**2)\n",
    "        loss =  tf.reduce_sum((y-beta0-beta1*x)**2)\n",
    "    slope1, slope2 = tape.gradient(loss,[beta0,beta1]) \n",
    "    beta0.assign_sub(slope1* 0.1/10000) # N=10000 \n",
    "    beta1.assign_sub(slope2* 0.1/10000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c3c3690-5080-4638-aa87-3752879ce871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.50996685>,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.9944571>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta0,beta1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eb7a64-635f-43d5-a446-f595d0fc6061",
   "metadata": {},
   "source": [
    "- 그렇다면 손실함수를 항상 `-로그가능도함수`로 선택해도 될까?\n",
    "- 손실함수를 선택하는 기준이 `-로그가능도함수`만 존재하는 것은 아니지만 대부분 괜찮다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83353970-30e7-4563-b1e2-e87040a4100b",
   "metadata": {},
   "source": [
    "`(4)` 출제되지 않은 중간고사 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b18b916-4479-4c83-8af3-e20e36b6ada7",
   "metadata": {},
   "source": [
    "아래의 모형을 생각하자. \n",
    "- $Y_i \\overset{iid}{\\sim} Ber(\\pi_i)$\n",
    "- $\\pi_i = \\frac{exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}=\\frac{\\exp(-1+5x_i)}{1+\\exp(-1+5x_i)}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2515575-164c-46b3-81a4-cfd2c60035e4",
   "metadata": {},
   "source": [
    "아래는 위의 모형에서 얻은 샘플이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a300e753-166a-42b9-8c36-aa2060ae14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tnp.linspace(-1,1,2000)\n",
    "pi = tnp.exp(-1+5*x) / (1+tnp.exp(-1+5*x))\n",
    "y = np.random.binomial(1,pi)\n",
    "y = tf.constant(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4834852-0fdc-43c6-8b0a-37587c44f73d",
   "metadata": {},
   "source": [
    "함수 $L(w_0,w_1)$을 최대화하는 $(w_0,w_1)$를 `tf.GradeintTape()`를 활용하여 추정하라. (경사하강법 혹은 경사상승법을 사용하고 $(w_0,w_1)$의 초기값은 모두 0.1로 설정할 것)\n",
    "\n",
    "$$L(w_0,w_1)=\\prod_{i=1}^{n}f(y_i), \\quad f(x_i)={\\pi_i}^{y_i}(1-\\pi_i)^{1-y_i},\\quad \\pi_i=\\text{sigmoid}(w_0+w_1x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5874bec-f663-4557-b9f4-bcb9d5874ea5",
   "metadata": {},
   "source": [
    "`-` 풀이1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f4343a5-bd40-411f-bc72-540d3db616aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0hat = tf.Variable(1.0) \n",
    "w1hat = tf.Variable(1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c4194a9-a914-4819-a0a5-3a5fe1f5b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000): \n",
    "    with tf.GradientTape() as tape: \n",
    "        pihat = tnp.exp(w0hat+w1hat*x) / (1+tnp.exp(w0hat+w1hat*x))\n",
    "        pdf = pihat**y * (1-pihat)**(1-y) \n",
    "        logL = tf.reduce_mean(tnp.log(pdf)) \n",
    "    slope1,slope2 = tape.gradient(logL,[w0hat,w1hat])\n",
    "    w0hat.assign_add(slope1*0.1) \n",
    "    w1hat.assign_add(slope2*0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cc2ed18-2970-4415-b40f-762b89c05f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-0.7932627>,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=4.2817187>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0hat,w1hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb65b83d-7ff2-4105-8d29-4284f8f3e089",
   "metadata": {},
   "source": [
    "#### 해석: 로지스틱에서 가능도함수와 BCEloss의 관계 \n",
    ": -log 가능도함수×1/n = BCEloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e903f9-87dd-445d-8bdf-c14d345dfbb1",
   "metadata": {},
   "source": [
    "$L(w_0,w_1)$를 최대화하는 $w_0,w_1$은 아래를 최소화하는 $w_0,w_1$와 같다. \n",
    "\n",
    "$$-\\log L(w_0,w_1) = - \\sum_{i=1}^{n}\\big(y_i \\log(\\pi_i) + (1-y_i)\\log(1-\\pi_i)\\big)$$\n",
    "\n",
    "이것은 최적의 $w_0,w_1$을 $\\hat{w}_0,\\hat{w}_1$이라고 하면 $\\hat{\\pi}_i=\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\hat{y}_i$이 되고 따라서 위의 식은 $n\\times$$BCEloss$의 형태임을 쉽게 알 수 있다. \n",
    "\n",
    "결국 로지스틱 모형에서 $(w_0,w_1)$의 MLE를 구하기 위해서는 BCEloss를 최소화하는 $(w_0,w_1)$을 구하면 된다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e2967-5fe6-46b1-9be7-d8f54946d597",
   "metadata": {},
   "source": [
    "`-` 풀이2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45f25652-200f-4a9a-acbf-82d03188ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0hat = tf.Variable(1.0) \n",
    "w1hat = tf.Variable(1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91fb0b68-d90f-4e64-a48e-014250325806",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000): \n",
    "    with tf.GradientTape() as tape: \n",
    "        yhat = tnp.exp(w0hat+w1hat *x) / (1+tnp.exp(w0hat+w1hat *x))\n",
    "        loss = tf.losses.binary_crossentropy(y,yhat)\n",
    "    slope1,slope2 = tape.gradient(loss,[w0hat,w1hat])\n",
    "    w0hat.assign_sub(slope1*0.1) \n",
    "    w1hat.assign_sub(slope2*0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "beb83c95-c62b-44ad-8670-dc79d9c1903c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-0.8875934>,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=4.3785415>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0hat,w1hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e48b07-5bbd-43e8-8cb8-1cdac2dde8b5",
   "metadata": {},
   "source": [
    "### 손실함수의 설계 (선택) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17207f3e-008d-4465-b17f-3403dfafaf1d",
   "metadata": {},
   "source": [
    "`-` 회귀분석이든 로지스틱이든 손실함수는 minus_log_likelihood 로 선택한다. \n",
    "- 그런데 (오차항이 정규분포인) 회귀분석 일때는 minus_log_likelihood 가 MSEloss가 되고 \n",
    "- 로지스틱일때는 minus_log_likelihood 가 BCEloss가 된다 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106b89b7-b4af-4a9a-bffa-3a691dc76dc0",
   "metadata": {},
   "source": [
    "`-` minus_log_likelihood가 손실함수를 선택하는 유일한 기준은 아니다. (참고만)\n",
    "- 오차항이 대칭이고 서로독립이며 등분산 가정을 만족하는 어떠한 분포에서의 회귀모형이 있다고 하자. 이 회귀모형에서 $\\hat{\\beta}$은 여전히 MSEloss를 최소화하는 $\\beta$를 구함으로써 얻을 수 있다. \n",
    "- 이 경우 MSEloss를 쓰는 이론적근거? $\\hat{\\beta}$이 BLUE가 되기 때문임 (가우스-마코프정리)\n",
    "\n",
    "`cf.`BLUE(최량선형비편향추정량): \n",
    "Best: 분산이 적고\n",
    "Linear: 선형이며\n",
    "Unbiased: 편향이 없는\n",
    "Estimator 이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
