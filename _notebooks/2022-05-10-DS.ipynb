{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "719fe6f0-52eb-4794-a064-f33d1ecdd242",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# DS 13. 디양한 평가지표, fashion_mnist(Flatten, Maxpooling layer 이용)\n",
    "\n",
    "> \"작성완료\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- [python, Data Science]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e414640-4155-43ac-819d-682126e62aef",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Science\n",
    "- lenture: Data Science_10-2nd week of lectures.\n",
    "- lenture date: 2022-05-09\n",
    "- lecturer: Guebin choi\n",
    "- study date: 2022-05-10\n",
    "- author: Kione kim\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8f23db-b6d1-40f1-90b2-105c6863454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.experimental.numpy as tnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb5be07-f49c-4960-93a0-b1e178436207",
   "metadata": {},
   "outputs": [],
   "source": [
    "tnp.experimental_enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c1db3a-4529-4b5b-b4b8-78ae18c58b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c965ad-451f-4151-aa03-86f4a6972a10",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 평가지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7028b-c7cb-4dc2-98fa-e770d755dd5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 다양한 평가지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa81c92-f14c-4a28-9b0d-3a02c7cdd17a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 여러가지 평가지표들: https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values\n",
    "- 이걸 다 암기하는건 불가능. \n",
    "- 몇 개만 뽑아서 암기하고 왜 쓰는지 생각해보고 넘어가자!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c8da82-616a-417e-87ea-de948e59327e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### confusion matrix의 이해 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af314e0-a86b-4500-9424-36726a7d6ac1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 표1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31508b5f-e06b-4d0c-96f1-71a46769270a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| |퇴사(예측)|안나감(예측)|\n",
    "|:-:|:-:|:-:|\n",
    "|퇴사(실제)|TP|FN|\n",
    "|안나감(실제)| FP| TN|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b0093-c5dc-430c-be78-fb5b52651473",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 표2 (교수님 정리) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c18ea9-fc2f-441a-883b-2c615bdc22fd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| |퇴사(예측)|안나감(예측)|\n",
    "|:-:|:-:|:-:|\n",
    "|퇴사(실제)|$(y,\\hat{y})= $ (O,O)|$(y,\\hat{y})= $(O,X)|\n",
    "|안나감(실제)| $(y,\\hat{y})= $(X,O)| $(y,\\hat{y})= $(X,X)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b2779-026b-4aee-97aa-41f37fcbaed6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 표3 (교수님 정리) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7774cc2-1140-4560-95ac-10292bae5d30",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| |퇴사(예측)|안나감(예측)|\n",
    "|:-:|:-:|:-:|\n",
    "|퇴사(실제)|TP, $\\# O/O$ |FN, $\\#O/X$|\n",
    "|안나감(실제)| FP, $\\#X/O$| TN, $\\#X/X$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b7b555-9cf1-403c-8a1a-2c5d6f714910",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 암기법: (1) 두 번째 글자를 그대로 쓴다 (2) 첫글자가 T이면 분류 성공, 첫글자가 F이면 분류 실패"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa748230-4715-42bb-826d-3a112df448c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 표4 (위키 참고) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c974733c-52c2-42bf-977e-1849aebbac80",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| |퇴사(예측)|안나감(예측)| |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|퇴사(실제)| TP, $\\# O/O$ |FN, $\\# O/X$| Sensitivity(민감도)=Recall(재현율)=$\\frac{TP}{TP+FN}$=$\\frac{\\#O/O}{\\# O/O+ \\#O/X}$|\n",
    "|안나감(실제)| FP, $\\# X/O$| TN, $\\# X/X$| |\n",
    "| |Precision(프리시즌)=$\\frac{TP}{TP+FP}$=$\\frac{\\# O/O}{\\# O/O+\\# X/O}$| |Accuracy(애큐러시)=$\\frac{TP+TN}{total}$=$\\frac{\\#O/O+\\# X/X}{total}$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5629c13-8cba-4dd4-a258-1006ec3d1b62",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 상황극 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25968ce-dc79-45c4-9d95-c05fde46debb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 연구원 A가 입사하여 \"퇴사자 예측시스템\"의 개발에 들어갔다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e82680d-5b77-4951-91f6-6877608bf397",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 대부분의 사람이 퇴사하지 않고 회사에 잘 다닌다고 하자. 즉 1000명이 있으면 10명정도 퇴사한다고 하자,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa4e505-99b6-4ccc-97ce-ee48a9ebdf53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 평가지표 1: Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ff3975-74c2-468b-b4c0-9358a929ad94",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 정의: Accuracy(애큐러시)=$\\frac{TP+TN}{total}$=$\\frac{\\#O/O+ \\#X/X}{total}$\n",
    "- 한국어로 정확도, 정분류율이라고 한다. \n",
    "- 한국어보다 영어로 외우는게 좋다. (한국어 헷갈림 + Keras에서 옵션도 영어로 넣기 때문) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf8b37f-5c7d-4f02-b462-aa67ec8f7b93",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 상확극 시점1: `accuracy`로는 불충분한가?\n",
    "- 회사: 퇴사자 예측프로그램 개발해\n",
    "- 연구원 A: 귀찮은데 다 안나간다고 하자! -> accuracy가 99% 이니까! \n",
    "\n",
    ": 모델에 사용한 파라메터 = 0. 애큐러시 = 99! 학습할 파라메터 수가 적음에도 애큐러시가 굉장히 높음 ! 이거 엄청 좋은 모형이다? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f083e42b-abeb-4c3f-b81a-15c63e1c8235",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 평가지표2: Sensitivity(민감도), Recall(재현율), True Positive Rate(TPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db24c7b-3618-4e38-851d-151c9de692bb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 정의: Sensitivity(민감도)=Recall(재현율)=$\\frac{TP}{TP+FN}$=$\\frac{\\# O/O}{\\# O/O+\\# O/X}$\n",
    "- 분모: 실제 O인 관측치 수\n",
    "- 분자: 실제 O를 O라고 예측한 관측치 수 \n",
    "\n",
    "뜻: 실제 O를 O라고 예측한 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f13fa24-c1e2-4696-92c7-83077a0b15c7",
   "metadata": {},
   "source": [
    "`-` 상황극 적용:\n",
    "- 분모: 실제 나간 사람들의 수\n",
    "- 분자: 실제 나간 사람들 중 내가 나갈 것이라고 예측한 관측치 수\n",
    "\n",
    "뜻: 실제 나간 사람들이 나갈 것이라고 예측에 성공한 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8720b5c-5325-476a-aff1-65f64cf4105f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 상황극 시점2: `recall`의 필요성\n",
    "- 인사팀: 실제 퇴사자를 퇴사자로 예측해야 의미가 있음! 우리는 퇴사할것 같은 10명을 찍어달란 의미였음! \n",
    "- 연구원 A: 가볍고(=파라메터 적고) 잘 맞추는 모형을 만들어 달라는 거 아니였나요?!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf3376a-78bd-4f5e-9a94-0b0fb85c2722",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 인사팀: (고민중..) 생각해보니 이 경우에서 애큐러시는 의미가 없네. 실제 나간 사람 중 연구원이 나간다고 한 사람이 몇 명인지 카운트 하는게 더 의미가 있겠다. 우리는 앞으로 리컬(혹은 민감도)를 보겠다! \n",
    "\n",
    "예시1: 실제로 퇴사한 10명중 연구원 A가 퇴사한다고 예측한 사람이 5명이면 리컬이 50%이다.\n",
    "\n",
    "예시2: 연구원 A가 아무도 나가지 않는다고 예측한 경우, 실제 퇴사한 10명중에서 연구원 A가 퇴사한다고 예측한 사람은 0명이므로 이 경우 리컬 0%이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03404ae-913d-4ba9-b898-1466c4880c5e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 결론: 우리(인사팀)가 필요한건 recall이니 앞으로 recall을 가져와주세요! accuracy는 큰 의미없어요. 그래도 명색이 모델이니 accuracy는 90은 넘었으면 좋겠네요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced07768-9a8b-483f-8869-c9a898cc5054",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 평가지표3: Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c598b56-c74c-4c2b-b311-edc603b80e73",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 정의: Precision(프리시즌)=$\\frac{TP}{TP+FP}$=$\\frac{\\# O/O}{\\# O/O+\\# X/O}$\n",
    "- 분모: O라고 예측한 관측치\n",
    "- 분자: O라고 예측한 관측치 중 진짜 O인 관측치 \n",
    "\n",
    "뜻: O라고 예측한 관측치 중 진짜 O인 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4196413-3d16-4350-9207-1dfe3765d58e",
   "metadata": {},
   "source": [
    "`-` 상황극 적용:\n",
    "- 분모: 퇴사할 것이라고 예측한 관측치 수\n",
    "- 분자: 퇴사할 것이라고 예측한 관측치 중 실제 퇴사한 관측치 수\n",
    "\n",
    "뜻: 퇴사할 것이라고 예측한 관측치 중 실제 퇴사한 관측치의 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8270074f-282e-4d2b-ab71-62c3e466d43e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 상황극 시점3: `recall`만으로 불충분한 이유, `percision`의 필요성\n",
    "\n",
    "- 연구원 A: (에휴..) 귀찮은데 그냥 조금만 수틀리면 다 나갈것 같다고 해야겠다 -> 100 명이 나간다고 했음 -> 실제로 연구원 A가 찍은 100명중 10명이 다 나감!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ca2647-1fe1-4af7-95f4-edc045ed397f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "이 경우 애큐러시는 91%, 리컬은 100% (퇴사자 10명을 모두 맞췄으므로) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612c9687-2b5c-4409-b0d1-470291bf8fba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 인사팀: (화가 많이 남) 멀쩡한 사람까지 다 퇴사할 것 같다고 하면 어떡해요? 연구원 A가 나간다고 한 100명 중에 실제로 10명만 나갔어요. \n",
    "\n",
    "- 인사팀: 마치 총으로 과녁 중앙에 맞춰 달라고 했더니 기관총을 가져와서 한번 긁은것이랑 뭐가 달라요? 맞추는게 문제가 아니고 `precision`이 너무 낮아요. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10827a60-f84a-42e5-9a79-45bc1df39af4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 연구원 A: accuracy가 90% 이상, recall은 높을수록 좋은 모형을 만들어달라고 하셨잖아요 !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29350a8-bf89-4c81-bd09-6b2f3f1ea609",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 인사팀: (고민중..) 앞으로 recall과 함께 precision도 같이 제출하세요. precision은 당신이 나간다고 한 사람중에 실제 나간사람의 비율을 의미해요. 이 경우는 $\\frac{10}{100}$이니까 precision이 10%입니다. (속마음: recall 올리겠다고 무작정 너무 많이 예측하지 말란 말이야!) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e85b4c-ae56-49f5-8b28-c06aa7ba3b92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 평가지표 4: F1 score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ba8647-faca-4b5f-8a64-d03158b1037f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 정의: recall과 precision의 조화평균 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b51a55-779c-475e-b324-d4ad4ee16833",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 상황극 시점4: recall, precision을 모두 고려 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8c9280-da9c-444c-b11b-a325149097c5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 연구원 A: recall/precision을 같이 내는건 좋은데요, 둘은 `trade off`의 관계에 있습니다. 물론 둘 다 올리는 모형이 있다면 좋지만 그게 쉽지 않아요. 보통은 precision을 올리려면 recall이 희생되는 면이 있고요, recall을 올리려고 하면 precision이 다소 떨어집니다. 즉 반비례 관계에 있어요!\n",
    "\n",
    "- 연구원 A: 평가기준이 애매하다는 의미입니다. 모형1,2가 있는데 모형1은 모형2보다 precision이 약간 좋고 대신 recall이 떨어진다면 모형1이 좋은 것입니까? 아니면 모형2가 좋은 것입니까? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b2d4ef-a2eb-4a47-a966-4a3db018d951",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 인사팀: 그렇다면 둘을 평균내서 `F1score`를 계산해서 제출해주세요. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d353c6a-a88a-4d32-be52-5cbd55c59fd9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 평가지표 5: Specificity(특이도), False Positive Rate(FPR) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d837886-b6f3-4c70-9daa-2e522f155d5d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 정의: \n",
    "\n",
    "1. Specificity(특이도)=$\\frac{TN}{FP+TN}$=$\\frac{\\# X/X}{\\# X/O+\\# X/X}$\n",
    "\n",
    "2. False Positive Rate (FPR) = 1-Specificity(특이도) = $\\frac{FP}{FP+TN}$=$\\frac{\\# X/O}{\\# X/O+\\# X/X}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642d9d07-64d1-42ed-8135-aa737360a195",
   "metadata": {},
   "source": [
    "`-` 상황극 적용:\n",
    "1. Specificity(특이도)\n",
    "- 분모: 실제로 퇴사하지 않은 사람들의 수\n",
    "- 분자: 실제로 퇴사하지 않은 사람들 중 내가 퇴사하지 않을 것이라고 예측한 사람들의 수\n",
    "\n",
    "뜻: 실제로 퇴사하지 않은 사람들 중 내가 퇴사하지 않을 것이라고 예측한 비율\n",
    "\n",
    "2. FPR\n",
    "- 분모: 실제로 퇴사하지 않은 사람들의 수\n",
    "- 분자: 실제로 퇴사하지 않은 사람들 중 내가 퇴사할 것이라고 예측한 사람들의 수\n",
    "\n",
    "뜻: 실제로 퇴사하지 않은 사람들 중 내가 퇴사할 것이라고 잘못 예측한 비율(오해한 비율)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a22f787-d44d-46e9-8921-c8b24b84cbb0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 의미: **FPR = 오해해서 미안해, recall(=TPR)을 올리려고 보니 어쩔 수 없었어**\n",
    "- specificity는 퇴사하지 않은 사람을 퇴사하지 않을 것이라고 찾아낸 비율인데, 이는 별로 중요하지 않다. \n",
    "- FPR은 recall을 올리기 위해서 `실제로는 회사 잘 다니고 있는 사람 중 연구원 A가 나갈 것 같다고 예측한 사람들`의 비율이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3374b8-0dd6-4a49-89cf-5576cad2404e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "즉 오해한 비율, 오해해서 미안한 사람의 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a60f14-435e-4024-8436-f41e7d9bcf84",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### ROC curve "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e89f8d7-26d8-4a13-8711-697e4d7e5b38",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 정의: $x$축=`FPR`, $y$축=`TPR(recall)` 을 그린 커브 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205131d-c3d1-4c0b-abf6-82af595fad08",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 의미: \n",
    "- 결국 \"FPR(오해 비율) vs recall\"을 그린 곡선이 ROC커브이다. \n",
    "- 생각해보면 오해하는 사람이 많을수록 당연히 recall은 올라간다. 따라서 우상향하는 곡선이다. \n",
    "- 오해한 사람이 매우 적은데 recall이 우수하면 매우 좋은 모형이다. 그래서 초반부터 ROC값이 급격하게 올라가면 좋은 모형이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51342376-2665-455b-bce9-a7a734432670",
   "metadata": {},
   "source": [
    "## fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b3e4e-dd19-4651-bc2b-97426d2f9296",
   "metadata": {},
   "source": [
    "`-` 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5535e9d1-d46f-463a-bc92-7b0038680d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c92450-362f-4ec0-a3ff-60a680d490e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc34d8bb-91a7-4bae-90d2-f6e07153fe17",
   "metadata": {},
   "source": [
    "- 색상 이미지의 경우 차원은 가로 × 세로 × 3 이다.\n",
    "- 따라서 이 이미지의 차원 (28,28)는 흑백이미지를 뜻한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "459ff39e-5af4-4cd0-9ee1-90ac9ca8f823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25291700c70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4918597f-493f-4953-af80-3ae996a70882",
   "metadata": {},
   "source": [
    "- 컬러 이미지 처럼 보이지만, 흑백 이미지이다. \n",
    "- 밝을수록 노란색, 어두울수록 남색으로 표현한 것이다. (colormap이 viridis일 뿐임)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee15d1e-c4db-4029-b3f5-bb3ebe884da8",
   "metadata": {},
   "source": [
    "`-` 확장형태\n",
    "\n",
    ": 일반적으로 분석할 이미지는 칼라이미지가 많을 것이므로 아래와 같이 자료형을 정리하는 것이 좋다. 이는 일반적인 이미지 자료를 분석하는 정석적인 처리방법이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c2f9321-194d-4ad6-848b-9735af1d299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(x_train.reshape(-1,28,28,1),dtype=tf.float64)\n",
    "y = tf.keras.utils.to_categorical(y_train)\n",
    "XX = tf.constant(x_test.reshape(-1,28,28,1),dtype=tf.float64)\n",
    "yy = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252ec85-3a1f-4a80-9def-441eb46119c2",
   "metadata": {},
   "source": [
    "- 분석할 이미지는 흑백이미지이므로 채널을 1로 설정해주는 것이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8417de6a-ddf4-4005-97ce-603620a9e41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([60000, 28, 28, 1]), TensorShape([10000, 28, 28, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, XX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7b6f48-38b3-416a-9854-ecf08ad75448",
   "metadata": {},
   "source": [
    "- keras에서 이미지 자료의 형태는 (관측치수,픽셀,픽셀,채널)이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2791fbc3-5ded-444c-9ff6-b90628b98735",
   "metadata": {},
   "source": [
    "- 이미지 자료를 위와 같이 설정해주면 모든 이미지 자료를 분석할 수 있지 않을까?\n",
    "- 그런데, dnn에 넣고 분석하려면 shape을 결국 바꿔주어야 한다. \n",
    "- 이를 안 하는 방법이 없을까? -> `Flatten()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df974b7-b89b-4636-92aa-b53bd1d2c103",
   "metadata": {},
   "source": [
    "### X의 차원이 (관측치수,픽셀,픽셀,채널)일 경우 DNN 쓰기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b33537a-48c9-419d-be3c-8bd5bb9d8bb3",
   "metadata": {},
   "source": [
    "#### 예제1: X -> Dense(30,relu) -> Dense(10,softmax):=> y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1466c55a-39d1-488a-93a3-9bcb6b79258d",
   "metadata": {},
   "source": [
    "`-` 이러한 아키텍처를 통해 분석하기 위해서는 X의 shape을 미리 바꿔야 했었다. 바꾸지 않고 분석하는 방법은 없을까? -> `tf.keras.layers.Flatten()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60201763-dea3-40f5-a1af-4934f9321c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "flttn = tf.keras.layers.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "950eec31-5d3e-4b04-b683-6328bee81ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__call__'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dir(flttn)) & {'__call__'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1316d-7ea7-4957-a884-138b5c1fe39c",
   "metadata": {},
   "source": [
    "- 함수 또는 클래스임 -> ( ) 사용 가능!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83b7357c-55f1-4498-9df7-6b770a145092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 784), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flttn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b41353c-9d4a-4ce3-99a9-c19178b28b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([60000, 28, 28, 1]), TensorShape([60000, 784]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, flttn(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b4187-6276-4239-bd15-df066817c6a5",
   "metadata": {},
   "source": [
    "- shape을 보니 60000 × 784임!\n",
    "- 이는 X.shape을 관측치수 × p의 꼴로 펼쳐준 것임!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ab73f48-ef54-4057-9da0-f8091732649a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 784), dtype=float64, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.reshape(-1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e129f583-c1bd-464f-88a6-452f433937c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 784), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flttn(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f313e001-bba1-4a24-b4de-17b01098b34e",
   "metadata": {},
   "source": [
    "- 위 두 코드 차이점은?\n",
    "\n",
    ": flttn(X)는 layer임! -> net에 넣을 수 있음!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9141b-5e10-4fc5-a430-236cdba0a620",
   "metadata": {},
   "source": [
    "`-` 이를 응용하여 네트워크를 설계해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0e69b40-68d6-4f84-88f0-2d4a8ab0fe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 2.2841 - accuracy: 0.4553\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.0848 - accuracy: 0.5713\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9705 - accuracy: 0.6047\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.8716 - accuracy: 0.6564\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.8061 - accuracy: 0.6791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b6289fbb80>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = tf.keras.Sequential()\n",
    "net1.add(tf.keras.layers.Flatten())\n",
    "net1.add(tf.keras.layers.Dense(30,activation='relu'))\n",
    "net1.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "net1.compile(loss=tf.keras.losses.categorical_crossentropy,optimizer='adam',metrics=['accuracy'])\n",
    "net1.fit(X,y,epochs=5) # batch_size를 입력해주지 않으면 알아서 확률적 경사하강법의 적당한 배치사이즈로 설정해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df820ded-ea39-4f01-8c8d-e15d10b72354",
   "metadata": {},
   "source": [
    "- tf.keras.layer.Flatten( )은 펼쳐주는 역할!의 레이어임!\n",
    "- 즉, n×p 매트릭스 형태로 변환해주는 레이어이다!\n",
    "- 만약 net1.add(tf.keras.layer.Flatten( ))를 실행해주지 않으면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba0ea429-b204-45b9-abe2-8db01c04b56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 10) and (32, 28, 28, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m net1\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      5\u001b[0m net1\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mcategorical_crossentropy,optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mnet1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds2022\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 10) and (32, 28, 28, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "net1 = tf.keras.Sequential()\n",
    "# net1.add(tf.keras.layers.Flatten())\n",
    "net1.add(tf.keras.layers.Dense(30,activation='relu'))\n",
    "net1.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "net1.compile(loss=tf.keras.losses.categorical_crossentropy,optimizer='adam')\n",
    "net1.fit(X,y,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e588f5-a5eb-4564-9b71-e7bc6d1bb69a",
   "metadata": {},
   "source": [
    "- 오류가 남"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63954617-839e-4cdb-9acf-83b5ecfa8f65",
   "metadata": {},
   "source": [
    "`-` layer 뜯어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6af93d2a-8d07-4198-8d3e-f8da4cfb9e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.flatten.Flatten at 0x1b6282e2730>,\n",
       " <keras.layers.core.dense.Dense at 0x1b62890a460>,\n",
       " <keras.layers.core.dense.Dense at 0x1b626c094f0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "845dba40-da71-4718-bb20-5a8e65318c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 784)\n",
      "(60000, 30)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(net1.layers[0](X).shape)\n",
    "print(net1.layers[1](net1.layers[0](X)).shape)\n",
    "print(net1.layers[2](net1.layers[1](net1.layers[0](X))).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80f5014-93ad-4fa1-8bd6-1acf77a94d51",
   "metadata": {},
   "source": [
    "- 레이어를 나온 후의 shape을 찍어 보니, Flatten을 타고 나온 결과 60000 × 784가 나왔다! 나머지 레이어에서의 출력 결과 또한 의도한대로 되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fa7ca89-d298-4b3c-ad97-eec6e9e2ef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 30), dtype=float32, numpy=\n",
       "array([[   0.     ,    0.     ,    0.     , ...,    0.     ,    0.     ,\n",
       "           0.     ],\n",
       "       [   0.     , 1111.7175 ,    0.     , ...,    0.     ,    0.     ,\n",
       "           0.     ],\n",
       "       [   0.     ,    0.     ,    0.     , ...,    0.     ,    0.     ,\n",
       "           0.     ],\n",
       "       ...,\n",
       "       [   0.     ,    0.     ,    0.     , ...,    0.     ,    0.     ,\n",
       "           0.     ],\n",
       "       [   0.     ,  240.60222,    0.     , ...,    0.     ,    0.     ,\n",
       "           0.     ],\n",
       "       [   0.     ,    0.     ,    0.     , ...,    0.     ,    0.     ,\n",
       "           0.     ]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.layers[1](net1.layers[0](X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d22f7b-2e2f-474c-b0c5-1eb34c21faa3",
   "metadata": {},
   "source": [
    "- relu를 타고 나왔기 때문에 0의 값이 많다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c49efc45-127a-46c0-a761-6ed2009d1e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 10), dtype=float32, numpy=\n",
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.53224944e-04, 1.27687756e-18, 9.99805629e-01],\n",
       "       [9.98700023e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.64780371e-22, 0.00000000e+00],\n",
       "       [7.18253255e-02, 3.41812056e-03, 2.89588362e-01, ...,\n",
       "        5.41791087e-03, 1.40066501e-02, 3.49816936e-03],\n",
       "       ...,\n",
       "       [1.69291079e-01, 3.15987207e-02, 2.03959553e-05, ...,\n",
       "        1.77893799e-05, 1.51306521e-02, 1.03107515e-04],\n",
       "       [6.34180486e-01, 1.64767727e-30, 3.41732531e-16, ...,\n",
       "        0.00000000e+00, 3.40139786e-06, 5.25017871e-26],\n",
       "       [5.51031237e-26, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.32433908e-09, 4.89504025e-15, 1.53012114e-14]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.layers[2](net1.layers[1](net1.layers[0](X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142f0467-12a9-4e51-a9d3-31537ac2bb72",
   "metadata": {},
   "source": [
    "- softmax를 타고 나왔기 때문에 0~1까지의 확률이 나왔다.(학습이 잘 된 경우)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e1d4ba-574b-4a29-b998-886d8a7420d5",
   "metadata": {},
   "source": [
    "`-` string 오브젝트로 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcdc3734-1b6c-4476-bf28-b830bbc54960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.9415 - categorical_crossentropy: 2.9415\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6852 - categorical_crossentropy: 1.6852\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2547 - categorical_crossentropy: 1.2547\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0457 - categorical_crossentropy: 1.0457\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.9515 - categorical_crossentropy: 0.9515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b628ac7910>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = tf.keras.Sequential()\n",
    "net1.add(tf.keras.layers.Flatten())\n",
    "net1.add(tf.keras.layers.Dense(30,activation='relu'))\n",
    "net1.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "net1.compile(loss=tf.keras.losses.categorical_crossentropy,optimizer='adam',metrics=[tf.metrics.categorical_crossentropy])\n",
    "net1.fit(X,y,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec74e59f-4869-4f30-aa04-7b7d6b07e8dd",
   "metadata": {},
   "source": [
    "- 분류할 클래스가 여러개일 경우 `tf.metrics.categorical_crossentropy`을 사용하고\n",
    "- string 오브젝트로 'accuracy'를 입력해주면 클래스가 여러개일 경우 자동으로 `tf.metrics.categorical_crossentropy`로 설정된다.\n",
    "- 그렇다면, 그냥 'accuracy'로 입력해주는 것이 헷갈일 일이 없겠음!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5807213-37fe-46c7-849a-7677bbefbcb2",
   "metadata": {},
   "source": [
    "`-` Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1df57269-ff2d-4156-a7f5-9a3c28964e47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 864, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 957, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 438, in update_state\n        self.build(y_pred, y_true)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 358, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 484, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 484, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 503, in _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\metrics.py\", line 4262, in get\n        return deserialize(str(identifier))\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\metrics.py\", line 4218, in deserialize\n        return deserialize_keras_object(\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 709, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: recall. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m net1\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      5\u001b[0m net1\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mcategorical_crossentropy,optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m \u001b[43mnet1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds2022\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 864, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\training.py\", line 957, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 438, in update_state\n        self.build(y_pred, y_true)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 358, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 484, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 484, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 503, in _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\metrics.py\", line 4262, in get\n        return deserialize(str(identifier))\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\metrics.py\", line 4218, in deserialize\n        return deserialize_keras_object(\n    File \"C:\\Users\\kko\\anaconda3\\envs\\ds2022\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 709, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: recall. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "net1 = tf.keras.Sequential()\n",
    "net1.add(tf.keras.layers.Flatten())\n",
    "net1.add(tf.keras.layers.Dense(30,activation='relu'))\n",
    "net1.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "net1.compile(loss=tf.keras.losses.categorical_crossentropy,optimizer='adam',metrics=['accuracy', 'recall'])\n",
    "net1.fit(X,y,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9caed501-933c-485d-aa55-ab5e81b34012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 5s 2ms/step - loss: 2.2795 - accuracy: 0.3939 - recall: 0.2884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b629149eb0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = tf.keras.Sequential()\n",
    "net1.add(tf.keras.layers.Flatten())\n",
    "net1.add(tf.keras.layers.Dense(30,activation='relu'))\n",
    "net1.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "net1.compile(loss=tf.keras.losses.categorical_crossentropy,optimizer='adam',metrics=['accuracy', 'Recall'])\n",
    "net1.fit(X,y,epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa0036b-0865-4ecf-8d14-899db9546b4a",
   "metadata": {},
   "source": [
    "- recall은 안 되고 Recall은 된다..?\n",
    "\n",
    "교훈: tf.metrics.categorical_crossentropy처럼 잘 안 외워지는 부분 정도만 알아두고, Recall과 같이 헷갈리는 부분은 직접 선언해주면 된다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a27bbe06-6126-4860-a441-cee71e4bd4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 5s 2ms/step - loss: 2.5869 - accuracy: 0.3948 - recall: 0.2819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b62d445040>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = tf.keras.Sequential()\n",
    "net1.add(tf.keras.layers.Flatten())\n",
    "net1.add(tf.keras.layers.Dense(30,activation='relu'))\n",
    "net1.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "net1.compile(loss=tf.keras.losses.categorical_crossentropy,optimizer='adam',metrics=['accuracy', tf.keras.metrics.Recall()])\n",
    "net1.fit(X,y,epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e11f45-5e40-4c9d-82f4-39b453a51a64",
   "metadata": {},
   "source": [
    "- tf.keras.metrics.Recall( ): 괄호까지 넣어주어야 함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03511da1-b891-45d3-8495-f33907455721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4971 - accuracy: 0.4748 - recall: 0.3586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4971224069595337, 0.47484999895095825, 0.35856667160987854]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.evaluate(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4110563f-3de3-4f7f-9e4e-ec1031a4a832",
   "metadata": {},
   "source": [
    "- recall까지 계산해줌!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c454ed-f079-425b-a03e-33cd6501ef76",
   "metadata": {},
   "source": [
    "#### 예제2: X -> Dense(500,relu) -> Dense(500,relu) -> Dense(10,softmax):=>y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961667f-db1b-4102-a78f-93a3d95e1b21",
   "metadata": {},
   "source": [
    "`-` 다른모형 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c49ba167-7cb9-4aaa-aa68-69cd51c4fc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 22s 11ms/step - loss: 1.9533 - accuracy: 0.7419\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.6708 - accuracy: 0.7839\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.5933 - accuracy: 0.8010\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.5053 - accuracy: 0.8298\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.4626 - accuracy: 0.8416\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4467 - accuracy: 0.8452\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.4279 - accuracy: 0.8503\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.4246 - accuracy: 0.8516\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.4086 - accuracy: 0.8567\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.4000 - accuracy: 0.8585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b634d997c0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = tf.keras.Sequential()\n",
    "net2.add(tf.keras.layers.Flatten())\n",
    "net2.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net2.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net2.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "net2.compile(loss=tf.losses.categorical_crossentropy, optimizer='adam',metrics=['accuracy'])\n",
    "net2.fit(X,y,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "faef095b-5f2c-4126-9212-9372efab9f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4793 - accuracy: 0.8470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47927021980285645, 0.847000002861023]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.evaluate(XX,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3e730c2-cc9a-47e8-9516-385cc781aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_25 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 500)               392500    \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12d03de-37e2-4c3c-9cd7-ec2e0d04feea",
   "metadata": {},
   "source": [
    "- 파라메터수가 대략 64만개임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aef61ff-6327-4716-9b4d-5f560b789f0c",
   "metadata": {},
   "source": [
    "`-` accuracy를 더 높여보자!   \n",
    ": layer 추가(깊은 신경망)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a1a067cb-e9d8-4d14-8be3-3d4d9dd9aeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 43s 22ms/step - loss: 1.0159 - accuracy: 0.7892\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 0.4521 - accuracy: 0.8380\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 40s 22ms/step - loss: 0.4176 - accuracy: 0.8511\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 0.3929 - accuracy: 0.8587\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.3801 - accuracy: 0.8664\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.3611 - accuracy: 0.8717\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.3538 - accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.3379 - accuracy: 0.8792\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.3266 - accuracy: 0.8843\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.3319 - accuracy: 0.8819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b636a116d0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net3 = tf.keras.Sequential()\n",
    "net3.add(tf.keras.layers.Flatten())\n",
    "net3.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net3.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net3.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net3.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net3.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "net3.compile(loss=tf.losses.categorical_crossentropy, optimizer='adam',metrics=['accuracy'])\n",
    "net3.fit(X,y,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2b047ffd-b6f2-4a14-a314-8ab123a3e721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4150 - accuracy: 0.8580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41498270630836487, 0.8579999804496765]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net3.evaluate(XX,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "04038940-a6cb-4b46-99f7-25ea24597f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_26 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 500)               392500    \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,149,010\n",
      "Trainable params: 1,149,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f38846-d83d-4ffc-8780-e1537bc36518",
   "metadata": {},
   "source": [
    "- 음..? 앞서 net2의 파라메터수보다 50만개 정도가 더 많음에도 accuracy 차이는 거의 없음..!\n",
    "- 레이어를 늘리기보다 다른 방법을 강구해보자...!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e544d5-9a4f-408c-8e99-d14a3e551ace",
   "metadata": {},
   "source": [
    "`-` 레이어 종류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f20a1803-1d08-4708-a090-3be95a81f8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AbstractRNNCell',\n",
       " 'Activation',\n",
       " 'ActivityRegularization',\n",
       " 'Add',\n",
       " 'AdditiveAttention',\n",
       " 'AlphaDropout',\n",
       " 'Attention',\n",
       " 'Average',\n",
       " 'AveragePooling1D',\n",
       " 'AveragePooling2D',\n",
       " 'AveragePooling3D',\n",
       " 'AvgPool1D',\n",
       " 'AvgPool2D',\n",
       " 'AvgPool3D',\n",
       " 'BatchNormalization',\n",
       " 'Bidirectional',\n",
       " 'CategoryEncoding',\n",
       " 'CenterCrop',\n",
       " 'Concatenate',\n",
       " 'Conv1D',\n",
       " 'Conv1DTranspose',\n",
       " 'Conv2D',\n",
       " 'Conv2DTranspose',\n",
       " 'Conv3D',\n",
       " 'Conv3DTranspose',\n",
       " 'ConvLSTM1D',\n",
       " 'ConvLSTM2D',\n",
       " 'ConvLSTM3D',\n",
       " 'Convolution1D',\n",
       " 'Convolution1DTranspose',\n",
       " 'Convolution2D',\n",
       " 'Convolution2DTranspose',\n",
       " 'Convolution3D',\n",
       " 'Convolution3DTranspose',\n",
       " 'Cropping1D',\n",
       " 'Cropping2D',\n",
       " 'Cropping3D',\n",
       " 'Dense',\n",
       " 'DenseFeatures',\n",
       " 'DepthwiseConv1D',\n",
       " 'DepthwiseConv2D',\n",
       " 'Discretization',\n",
       " 'Dot',\n",
       " 'Dropout',\n",
       " 'ELU',\n",
       " 'Embedding',\n",
       " 'Flatten',\n",
       " 'GRU',\n",
       " 'GRUCell',\n",
       " 'GaussianDropout',\n",
       " 'GaussianNoise',\n",
       " 'GlobalAveragePooling1D',\n",
       " 'GlobalAveragePooling2D',\n",
       " 'GlobalAveragePooling3D',\n",
       " 'GlobalAvgPool1D',\n",
       " 'GlobalAvgPool2D',\n",
       " 'GlobalAvgPool3D',\n",
       " 'GlobalMaxPool1D',\n",
       " 'GlobalMaxPool2D',\n",
       " 'GlobalMaxPool3D',\n",
       " 'GlobalMaxPooling1D',\n",
       " 'GlobalMaxPooling2D',\n",
       " 'GlobalMaxPooling3D',\n",
       " 'Hashing',\n",
       " 'Input',\n",
       " 'InputLayer',\n",
       " 'InputSpec',\n",
       " 'IntegerLookup',\n",
       " 'LSTM',\n",
       " 'LSTMCell',\n",
       " 'Lambda',\n",
       " 'Layer',\n",
       " 'LayerNormalization',\n",
       " 'LeakyReLU',\n",
       " 'LocallyConnected1D',\n",
       " 'LocallyConnected2D',\n",
       " 'Masking',\n",
       " 'MaxPool1D',\n",
       " 'MaxPool2D',\n",
       " 'MaxPool3D',\n",
       " 'MaxPooling1D',\n",
       " 'MaxPooling2D',\n",
       " 'MaxPooling3D',\n",
       " 'Maximum',\n",
       " 'Minimum',\n",
       " 'MultiHeadAttention',\n",
       " 'Multiply',\n",
       " 'Normalization',\n",
       " 'PReLU',\n",
       " 'Permute',\n",
       " 'RNN',\n",
       " 'RandomContrast',\n",
       " 'RandomCrop',\n",
       " 'RandomFlip',\n",
       " 'RandomHeight',\n",
       " 'RandomRotation',\n",
       " 'RandomTranslation',\n",
       " 'RandomWidth',\n",
       " 'RandomZoom',\n",
       " 'ReLU',\n",
       " 'RepeatVector',\n",
       " 'Rescaling',\n",
       " 'Reshape',\n",
       " 'Resizing',\n",
       " 'SeparableConv1D',\n",
       " 'SeparableConv2D',\n",
       " 'SeparableConvolution1D',\n",
       " 'SeparableConvolution2D',\n",
       " 'SimpleRNN',\n",
       " 'SimpleRNNCell',\n",
       " 'Softmax',\n",
       " 'SpatialDropout1D',\n",
       " 'SpatialDropout2D',\n",
       " 'SpatialDropout3D',\n",
       " 'StackedRNNCells',\n",
       " 'StringLookup',\n",
       " 'Subtract',\n",
       " 'TextVectorization',\n",
       " 'ThresholdedReLU',\n",
       " 'TimeDistributed',\n",
       " 'UpSampling1D',\n",
       " 'UpSampling2D',\n",
       " 'UpSampling3D',\n",
       " 'Wrapper',\n",
       " 'ZeroPadding1D',\n",
       " 'ZeroPadding2D',\n",
       " 'ZeroPadding3D',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_sys',\n",
       " 'add',\n",
       " 'average',\n",
       " 'concatenate',\n",
       " 'deserialize',\n",
       " 'dot',\n",
       " 'experimental',\n",
       " 'maximum',\n",
       " 'minimum',\n",
       " 'multiply',\n",
       " 'serialize',\n",
       " 'subtract']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf.keras.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca811b6b-d0e5-449c-991d-60d0b8120810",
   "metadata": {},
   "source": [
    "- 매우 많은데, 이 중 `Convolution2D`와 `MaxPool2D`이 많이 사용됨!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5dc4c3a4-74aa-4a61-81fc-895531fe3be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1883095743600, 1883095743600)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(tf.keras.layers.MaxPool2D), id(tf.keras.layers.MaxPooling2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1d9de7-4e0a-4cd0-9d9b-3ef13c7fe0a6",
   "metadata": {},
   "source": [
    "- 같은 것임!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac10315-b17a-4dc1-8321-c17a45d0de70",
   "metadata": {},
   "source": [
    "#### Maxpooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd71ba0-9927-4c33-8519-0f766a0daf80",
   "metadata": {},
   "source": [
    "`-` 예비학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd22389-6213-47cb-8b25-3a06589a4eaf",
   "metadata": {},
   "source": [
    "`-` 테스트1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7d853e4c-7ab6-488f-8307-7dc7cd168a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = tf.keras.layers.MaxPool2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95ff513c-508e-490a-ab08-bea6e02584f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2, 1), dtype=int32, numpy=\n",
       "array([[[[0],\n",
       "         [1]],\n",
       "\n",
       "        [[2],\n",
       "         [3]]]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX = tnp.arange(1*2*2*1).reshape(1,2,2,1)\n",
    "XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63abe419-e7f2-45a6-838b-8eafa89d09dc",
   "metadata": {},
   "source": [
    "- 보기가 불편, 차원이 (1,2,2,1)로 되어 있으니 그런 것 같음\n",
    "- 차원을 (1,2,2)로(채널 제외) 바꿔보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0361f4e-6f76-47ee-aff1-6e5ba804fb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
       "array([[[0, 1],\n",
       "        [2, 3]]])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX.reshape(1,2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f30d146-08b9-4c12-8e88-360cfd7a42db",
   "metadata": {},
   "source": [
    "- 이제 보기 편함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4293b1c-203e-4716-bbd5-8098a6c9d9cc",
   "metadata": {},
   "source": [
    "- 흑백이미지가 위와 같은 형태로 존재한다고 생각"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b15f33e-3675-44c8-9662-9896b3015ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 1), dtype=int32, numpy=array([[[[3]]]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6723370-ac53-47f5-a034-aa9b433a8f2b",
   "metadata": {},
   "source": [
    "- 3이 나왔음. 3은 제일 큰 수임, 가장 큰 수가 나오는 것일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2fb4b9-92c7-4161-8185-9a9f80218489",
   "metadata": {},
   "source": [
    "`-` 테스트2: 더 큰 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bbeb443-4114-46bb-a670-51609586fdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX = tnp.arange(1*4*4*1).reshape(1,4,4,1)\n",
    "XXX.reshape(1,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50d43410-6feb-46bd-b37b-cb3946e2929b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2, 1), dtype=int32, numpy=\n",
       "array([[[[ 5],\n",
       "         [ 7]],\n",
       "\n",
       "        [[13],\n",
       "         [15]]]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ff2e5d-0178-4299-921d-e9cadbe7fec9",
   "metadata": {},
   "source": [
    "- ...?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6ca21-6c9e-40ac-8d6f-4690a0f4a4f6",
   "metadata": {},
   "source": [
    "- 차원이 (1,2,2,1)로 되어 있으니 보기가 불편, (1,2,2)로 바꿔서 다시 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0535a33-b593-4994-b7b2-3d5673fbe83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
       "array([[[ 5,  7],\n",
       "        [13, 15]]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX).reshape(1,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85bf85e4-8a62-4b27-b714-261de7b99571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX.reshape(1,4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a554fad6-f986-49be-8ff0-fa8a92224a6a",
   "metadata": {},
   "source": [
    "- 이는 2×2행렬이 4개 있는 것으로 볼 수 있는데, 각 행렬중 가장 큰 값이 나온 것임!\n",
    "- (0,1,4,5) 중 가장 큰 값 5, (2,3,6,7) 중 가장 큰 값 7, (8,9,12,13) 중 가장 큰 값 13 (10,11,14,15) 중 가장 큰 값 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d704c6ef-0d9c-4e54-8ab2-ea78d5677e78",
   "metadata": {},
   "source": [
    "`-` 테스트3: 더 큰 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a41a4da-7f4b-44ce-8d29-2fd6763fcb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6, 6), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23],\n",
       "        [24, 25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34, 35]]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX=tnp.arange(1*6*6*1).reshape(1,6,6,1)\n",
    "XXX.reshape(1,6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f90e368-b7dc-47e0-be5f-b1acdad32dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3, 1), dtype=int32, numpy=\n",
       "array([[[[ 7],\n",
       "         [ 9],\n",
       "         [11]],\n",
       "\n",
       "        [[19],\n",
       "         [21],\n",
       "         [23]],\n",
       "\n",
       "        [[31],\n",
       "         [33],\n",
       "         [35]]]])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "966387c7-9f08-4e31-b052-7a864729e989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3), dtype=int32, numpy=\n",
       "array([[[ 7,  9, 11],\n",
       "        [19, 21, 23],\n",
       "        [31, 33, 35]]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX).reshape(1,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e69d8ea1-0ebc-4e2a-87e9-7b1379d45da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6, 6), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23],\n",
       "        [24, 25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34, 35]]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX.reshape(1,6,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58edb46-90bc-4eb7-8d2d-bc21832f3f21",
   "metadata": {},
   "source": [
    "- 이 또한 2×2 행렬에서 가장 큰 값들임\n",
    "- 의문: 왜 2×2 행렬에서 가장 큰 값이지?\n",
    ": 디폴트가 (2,2)이기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a991a7-98af-40ee-b2ec-a884a8542e62",
   "metadata": {},
   "source": [
    "`-` 테스트4: 행렬확장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd94a1b8-0e72-43fc-b815-890156f33cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3=tf.keras.layers.MaxPool2D(pool_size=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d897eaf1-d750-4d0e-9775-857eea3aa6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2, 1), dtype=int32, numpy=\n",
       "array([[[[14],\n",
       "         [17]],\n",
       "\n",
       "        [[32],\n",
       "         [35]]]])>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp3(XXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89418947-0d74-4c2e-a2c6-83fbf4118d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
       "array([[[14, 17],\n",
       "        [32, 35]]])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp3(XXX).reshape(1,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d96a854-b2a6-437a-ac8f-adeec819d586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6, 6), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23],\n",
       "        [24, 25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34, 35]]])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX.reshape(1,6,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9b754-a10c-4ce3-b68a-ff2f123f9b9c",
   "metadata": {},
   "source": [
    "- 이는 3×3 행렬에서 가장 큰 값들임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce22261b-1d58-46b8-bc87-f49217c5fae7",
   "metadata": {},
   "source": [
    "- 교훈: 시선의 확장, Flatten과 Maxpooling 등과 같은 다른 layer들을 조합으로 사용해보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cb0a8b-4694-4bb3-ae8b-ecc5318457d6",
   "metadata": {},
   "source": [
    "`-` 테스트 5: obs가 여러개일 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3019758-88c8-45d4-8d9c-6e6bb0f8f73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 4), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]],\n",
       "\n",
       "       [[16, 17, 18, 19],\n",
       "        [20, 21, 22, 23],\n",
       "        [24, 25, 26, 27],\n",
       "        [28, 29, 30, 31]]])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX=tnp.arange(2*4*4*1).reshape(2,4,4,1)\n",
    "XXX.reshape(2,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29826bad-fe4e-4ab9-bb31-8795fb24d968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
       "array([[[ 5,  7],\n",
       "        [13, 15]],\n",
       "\n",
       "       [[21, 23],\n",
       "        [29, 31]]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX).reshape(2,2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b04da9-9d98-417e-9f98-00fe899428ef",
   "metadata": {},
   "source": [
    "- 각 obs 별로 적용이 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e00c7ad-2bf0-40eb-962b-06f696d664ff",
   "metadata": {},
   "source": [
    "`-` 테스트6: 채널증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5edc9fcf-95f6-46d8-97cd-cfcbfcd797b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4, 3), dtype=int32, numpy=\n",
       "array([[[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14],\n",
       "         [15, 16, 17],\n",
       "         [18, 19, 20],\n",
       "         [21, 22, 23]],\n",
       "\n",
       "        [[24, 25, 26],\n",
       "         [27, 28, 29],\n",
       "         [30, 31, 32],\n",
       "         [33, 34, 35]],\n",
       "\n",
       "        [[36, 37, 38],\n",
       "         [39, 40, 41],\n",
       "         [42, 43, 44],\n",
       "         [45, 46, 47]]]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX=tnp.arange(1*4*4*3).reshape(1,4,4,3)\n",
    "XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9ac571a-3b18-4846-b343-9e545c02b691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 4), dtype=int32, numpy=\n",
       " array([[ 0,  3,  6,  9],\n",
       "        [12, 15, 18, 21],\n",
       "        [24, 27, 30, 33],\n",
       "        [36, 39, 42, 45]])>,\n",
       " <tf.Tensor: shape=(1, 4, 4), dtype=int32, numpy=\n",
       " array([[[ 0,  3,  6,  9],\n",
       "         [12, 15, 18, 21],\n",
       "         [24, 27, 30, 33],\n",
       "         [36, 39, 42, 45]]])>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX[0,:,:,0], XXX[:,:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0382b93c-340a-4983-b81e-01f884098dd1",
   "metadata": {},
   "source": [
    "- obs에 하나이기 때문에 위는 같은 코드임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bc58a12-573b-4f7b-8ea9-834afcd67c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 4, 4), dtype=int32, numpy=\n",
       " array([[[ 0,  3,  6,  9],\n",
       "         [12, 15, 18, 21],\n",
       "         [24, 27, 30, 33],\n",
       "         [36, 39, 42, 45]]])>,\n",
       " <tf.Tensor: shape=(1, 4, 4), dtype=int32, numpy=\n",
       " array([[[ 0,  3,  6,  9],\n",
       "         [12, 15, 18, 21],\n",
       "         [24, 27, 30, 33],\n",
       "         [36, 39, 42, 45]]])>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX[:,:,:,0], XXX[...,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd509654-442a-4125-8aa5-876e9bf072ee",
   "metadata": {},
   "source": [
    "- `XXX[:,:,:,0]을 XXX{...,0]`로 생략해서 표현가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "327ceaf3-5744-4053-ab56-7f81f394b68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 4, 4), dtype=int32, numpy=\n",
       " array([[[ 0,  3,  6,  9],\n",
       "         [12, 15, 18, 21],\n",
       "         [24, 27, 30, 33],\n",
       "         [36, 39, 42, 45]]])>,\n",
       " <tf.Tensor: shape=(1, 4, 4), dtype=int32, numpy=\n",
       " array([[[ 1,  4,  7, 10],\n",
       "         [13, 16, 19, 22],\n",
       "         [25, 28, 31, 34],\n",
       "         [37, 40, 43, 46]]])>,\n",
       " <tf.Tensor: shape=(1, 4, 4), dtype=int32, numpy=\n",
       " array([[[ 2,  5,  8, 11],\n",
       "         [14, 17, 20, 23],\n",
       "         [26, 29, 32, 35],\n",
       "         [38, 41, 44, 47]]])>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX1 = XXX[...,0] # 채널1\n",
    "XXX2 = XXX[...,1] # 채널2\n",
    "XXX3 = XXX[...,2] # 채널3\n",
    "XXX1, XXX2, XXX3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3215d816-34cf-4369-8cd7-4a44cdac8dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2, 3), dtype=int32, numpy=\n",
       "array([[[[15, 16, 17],\n",
       "         [21, 22, 23]],\n",
       "\n",
       "        [[39, 40, 41],\n",
       "         [45, 46, 47]]]])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84362806-cf2a-4e45-8a8d-e1e1e123585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "YYY1 = mp(XXX)[...,0]\n",
    "YYY2 = mp(XXX)[...,1]\n",
    "YYY3 = mp(XXX)[...,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a83d4863-4f6c-4e43-9618-60373f29b898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
       " array([[[15, 21],\n",
       "         [39, 45]]])>,\n",
       " <tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
       " array([[[16, 22],\n",
       "         [40, 46]]])>,\n",
       " <tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
       " array([[[17, 23],\n",
       "         [41, 47]]])>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YYY1, YYY2, YYY3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5969d6c4-d118-4bf4-af91-e84232ddaec4",
   "metadata": {},
   "source": [
    "- 채널별로 적용!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc5fbc-fc25-4b27-a4f9-9551432937a1",
   "metadata": {},
   "source": [
    "`-` 테스트7: 숫자가 안 맞을 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67d15ce8-f2f8-49ea-ac14-288b396ba254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 5), dtype=int32, numpy=\n",
       "array([[[  0,  -1,  -2,  -3,  -4],\n",
       "        [ -5,  -6,  -7,  -8,  -9],\n",
       "        [-10, -11, -12, -13, -14],\n",
       "        [-15, -16, -17, -18, -19],\n",
       "        [-20, -21, -22, -23, -24]]])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX = -tnp.arange(1*5*5*1).reshape(1,5,5,1)\n",
    "XXX.reshape(1,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c9a338c-3744-40b0-80b9-115803ecdb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2, 1), dtype=int32, numpy=\n",
       "array([[[[  0],\n",
       "         [ -2]],\n",
       "\n",
       "        [[-10],\n",
       "         [-12]]]])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5220d0db-ef7f-4328-99d1-cf786e9a6bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
       "array([[[  0,  -2],\n",
       "        [-10, -12]]])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX).reshape(1,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0ae18de7-c19e-4d34-9c94-656cc05ab7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 5), dtype=int32, numpy=\n",
       "array([[[  0,  -1,  -2,  -3,  -4],\n",
       "        [ -5,  -6,  -7,  -8,  -9],\n",
       "        [-10, -11, -12, -13, -14],\n",
       "        [-15, -16, -17, -18, -19],\n",
       "        [-20, -21, -22, -23, -24]]])>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX.reshape(1,5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b889d554-9537-425b-9f8c-d97da4377056",
   "metadata": {},
   "source": [
    "- 남는 숫자는 버림! (디폴트 설정이 남는 경우 버리게끔 되어있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae9e2df9-70f2-4f59-b9a3-285bc9bec9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = tf.keras.layers.MaxPool2D(padding=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "baa840d9-6ac7-48f7-ab3e-2373afaf7a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 5), dtype=int32, numpy=\n",
       "array([[[  0,  -1,  -2,  -3,  -4],\n",
       "        [ -5,  -6,  -7,  -8,  -9],\n",
       "        [-10, -11, -12, -13, -14],\n",
       "        [-15, -16, -17, -18, -19],\n",
       "        [-20, -21, -22, -23, -24]]])>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX = -tnp.arange(1*5*5*1).reshape(1,5,5,1)\n",
    "XXX.reshape(1,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3429d389-3ff0-4368-89b1-f33381b4bf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3, 1), dtype=int32, numpy=\n",
       "array([[[[  0],\n",
       "         [ -2],\n",
       "         [ -4]],\n",
       "\n",
       "        [[-10],\n",
       "         [-12],\n",
       "         [-14]],\n",
       "\n",
       "        [[-20],\n",
       "         [-22],\n",
       "         [-24]]]])>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99671e86-25ab-4d50-93ef-8085c1455bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3), dtype=int32, numpy=\n",
       "array([[[  0,  -2,  -4],\n",
       "        [-10, -12, -14],\n",
       "        [-20, -22, -24]]])>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX).reshape(1,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34a4c2da-db14-4731-8720-d98fe32c0df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 5), dtype=int32, numpy=\n",
       "array([[[  0,  -1,  -2,  -3,  -4],\n",
       "        [ -5,  -6,  -7,  -8,  -9],\n",
       "        [-10, -11, -12, -13, -14],\n",
       "        [-15, -16, -17, -18, -19],\n",
       "        [-20, -21, -22, -23, -24]]])>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX.reshape(1,5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6883c9-2e3d-4c66-88e3-2b40d015a57d",
   "metadata": {},
   "source": [
    "- 숫자 남으면 버리지 않고 남는 숫자(들)로 계산하여 적용\n",
    "- 참고로 디폴트값은 tf.keras.layers.MaxPool2D(padding=\"valid\")임 ! -> 남는 숫자 버리는 경우"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
